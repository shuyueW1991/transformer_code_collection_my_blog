{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3167cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b95e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_basic_tokenization = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097527d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def data_collate(batch_dataset):\n",
    "    arr = np.array(batch_dataset)\n",
    "    inputs = tokenizer(text = arr.tolist(), padding = 'max_length', max_length = 512, truncation=True, return_tensors = 'pt')\n",
    "    return inputs\n",
    "\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, src, tokenizer):\n",
    "        #src = sentences \n",
    "        self.src = src\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.src[idx]\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8dc0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"cnn_dailymail\", \"2.0.0\", split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b316049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_data(text):\n",
    "    #remove last line\n",
    "    text = re.sub(r\"Copyright \\d{4} Reuters. All rights reserved.*\", \"\", text)\n",
    "    \n",
    "    #replace \\'\n",
    "    text = text.replace(\"\\'\", \"\")\n",
    "    \n",
    "    #replace 's\n",
    "    text = re.sub(r\"'s\\b'\", \"\", text)\n",
    "    \n",
    "    #remove extra white space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce068486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287113/287113 [00:44<00:00, 6431.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "train_data = []\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    filter_d = filter_data(data[i]['article'])\n",
    "    train_data.append(filter_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3836ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37db5f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CreateDataset(train_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78d49450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e104db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "507287ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model \n",
    "class TransformerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, ntokens, ninp, nhead, nhid, nlayers, dropout = 0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layer = TransformerEncoderLayer(ninp, nhead, nhid, dropout, batch_first = True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, nlayers)\n",
    "        self.encoder = nn.Embedding(ntokens, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntokens)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        \n",
    "        '''\n",
    "        We generate the mask to prevent the transformer from seeing future tokens\n",
    "        Square matrix is created with elements below the diagonal = 0\n",
    "        Conver the mask to float, all zeros are replaced with -inf(indicating no access to elements) \n",
    "        and 1 with 0.0(this apporation does not changes the magnitude but influences the output)\n",
    "        '''\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        \n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25bfcdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9e6d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mps_device = torch.device(\"mps\")\n",
    "\n",
    "ntokens = tokenizer.vocab_size \n",
    "emsize = 512\n",
    "nhid = 100\n",
    "nlayers = 5\n",
    "nhead = 4 \n",
    "dropout = 0.2 \n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97a33388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('pos_encoder',\n",
       "               PositionalEncoding(\n",
       "                 (dropout): Dropout(p=0.2, inplace=False)\n",
       "               )),\n",
       "              ('transformer_encoder',\n",
       "               TransformerEncoder(\n",
       "                 (layers): ModuleList(\n",
       "                   (0-4): 5 x TransformerEncoderLayer(\n",
       "                     (self_attn): MultiheadAttention(\n",
       "                       (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (linear1): Linear(in_features=512, out_features=100, bias=True)\n",
       "                     (dropout): Dropout(p=0.2, inplace=False)\n",
       "                     (linear2): Linear(in_features=100, out_features=512, bias=True)\n",
       "                     (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (dropout1): Dropout(p=0.2, inplace=False)\n",
       "                     (dropout2): Dropout(p=0.2, inplace=False)\n",
       "                   )\n",
       "                 )\n",
       "               )),\n",
       "              ('encoder', Embedding(30522, 512)),\n",
       "              ('decoder',\n",
       "               Linear(in_features=512, out_features=30522, bias=True))]),\n",
       " 'model_type': 'Transformer',\n",
       " 'ninp': 512}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "018c6f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    learning_rate = 0.1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    #gradient_checkpointing=True, # transformer models dont have this feature \n",
    "    #fp16=True, # can only be done with CUDA \n",
    "    output_dir = \"./model_output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b9f722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_pt_utils import get_parameter_names\n",
    "\n",
    "decay_parameters = get_parameter_names(model, [nn.LayerNorm])\n",
    "decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if n in decay_parameters],\n",
    "        \"weight_decay\": training_args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if n not in decay_parameters],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    \"betas\": (training_args.adam_beta1, training_args.adam_beta2),\n",
    "    \"eps\": training_args.adam_epsilon,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ebc8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(optimizer_grouped_parameters,\n",
    "                        lr = training_args.learning_rate,\n",
    "                        betas=(training_args.adam_beta1, training_args.adam_beta2),\n",
    "                        eps=training_args.adam_epsilon,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d98dcc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba53db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_data, batch_size=training_args.per_device_train_batch_size, collate_fn = data_collate)\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, dataloader = accelerator.prepare(model, optim, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7853ee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [1:40:26, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6139479.5000, device='mps:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46428it [46:31, 16.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, ntokens), batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(mps_device))\n\u001b[1;32m     28\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m---> 30\u001b[0m accelerator\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m training_args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     33\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:2151\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2151\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "total_loss = 0\n",
    "# epochs = 30\n",
    "epochs = 2 # make it small justement pour gouter\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, batch in tqdm(enumerate(dataloader, start=1)):\n",
    "        #prepare input\n",
    "        input = batch['input_ids']\n",
    "        src_mask = model.generate_square_subsequent_mask(batch['input_ids'].size(1))\n",
    "\n",
    "        #genearate mask for random values\n",
    "        rand_value = torch.rand(batch.input_ids.shape)\n",
    "\n",
    "        rand_mask = (rand_value.to(mps_device) < 0.15) * (input != 101) * (input != 102) * (input != 0)\n",
    "\n",
    "        #store masked index\n",
    "        mask_idx=(rand_mask.flatten() == True).nonzero().view(-1)\n",
    "\n",
    "        input = input.flatten()\n",
    "        input[mask_idx] = 103\n",
    "        input = input.view(batch['input_ids'].size())\n",
    "\n",
    "        out = model(input.to(mps_device), src_mask.to(mps_device))\n",
    "\n",
    "        loss = criterion(out.view(-1, ntokens), batch['input_ids'].view(-1).to(mps_device))\n",
    "        total_loss += loss\n",
    "\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        if step % training_args.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "    print(total_loss/(len(dataloader)*epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bff31",
   "metadata": {},
   "source": [
    "save it, peut-etre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3294c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"model.pt\"\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f407e",
   "metadata": {},
   "source": [
    "inference..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
