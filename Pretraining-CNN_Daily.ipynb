{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec81444",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "057b8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c46d3b",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f8af1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_basic_tokenization = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569fb334",
   "metadata": {},
   "source": [
    "## Collation\n",
    "Collation in the context of machine learning typically refers to the process of gathering and organizing data into a structured format suitable for analysis. This involves:\n",
    "\n",
    "Data Collection: Gathering data from various sources.\n",
    "Data Cleaning: Ensuring data consistency, accuracy, and completeness.\n",
    "Data Integration: Combining data from different sources into a unified dataset.\n",
    "Data Transformation: Converting data into a suitable format for analysis (e.g., numerical, categorical).\n",
    "\n",
    "In essence, collation is a critical preprocessing step in machine learning that lays the foundation for building effective models.\n",
    "\n",
    "Used as function in DataLoader option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b9f2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def data_collate(batch_dataset):\n",
    "    arr = np.array(batch_dataset)\n",
    "    inputs = tokenizer(text = arr.tolist(), padding = 'max_length', max_length = 512, truncation=True, return_tensors = 'pt')\n",
    "    # padding: How to handle sequences that are shorter than the maximum length.\n",
    "    # Options:\n",
    "    # 'max_length': Pad sequences to the maximum length with a padding token.\n",
    "    # 'longest': Pad sequences to the length of the longest sequence in the batch.\n",
    "    # 'do_not_pad': Do not pad sequences.\n",
    "\n",
    "    # return_tensors: The format of the output tensors.\n",
    "    # Options:\n",
    "    # 'pt': Return PyTorch tensors.\n",
    "    # 'tf': Return TensorFlow tensors.\n",
    "    # 'np': Return NumPy arrays.\n",
    "    return inputs\n",
    "\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, src, tokenizer):\n",
    "        #src = sentences \n",
    "        self.src = src\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.src[idx]\n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b030f",
   "metadata": {},
   "source": [
    "## Select the dataset to load in <datasets> package.\n",
    "\n",
    "You can find a list of available datasets on the Hugging Face Datasets Hub: https://huggingface.co/datasets\n",
    "\n",
    "You can browse through the list of datasets, filter by task, dataset type, and more. Each dataset has a unique identifier (e.g. *cnn_dailymail*) that you can use with the load_dataset function.\n",
    "\n",
    "Alternatively, you can use the list_datasets function from the datasets library to get a list of available datasets:\n",
    "\n",
    "```python\n",
    "from datasets import list_datasets\n",
    "available_datasets = list_datasets()\n",
    "print(available_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7adc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/p0r9tg_n12vf_384ghbm53z80000gn/T/ipykernel_9318/3946909885.py:2: FutureWarning: list_datasets is deprecated and will be removed in the next major version of datasets. Use 'huggingface_hub.list_datasets' instead.\n",
      "  available_datasets = list_datasets()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['amirveyseh/acronym_identification',\n",
       " 'ade-benchmark-corpus/ade_corpus_v2',\n",
       " 'UCLNLP/adversarial_qa',\n",
       " 'Yale-LILY/aeslc',\n",
       " 'nwu-ctext/afrikaans_ner_corpus',\n",
       " 'fancyzhx/ag_news',\n",
       " 'allenai/ai2_arc',\n",
       " 'google/air_dialogue',\n",
       " 'komari6/ajgt_twitter_ar',\n",
       " 'legacy-datasets/allegro_reviews',\n",
       " 'tblard/allocine',\n",
       " 'mutiyama/alt',\n",
       " 'fancyzhx/amazon_polarity',\n",
       " 'defunct-datasets/amazon_reviews_multi',\n",
       " 'defunct-datasets/amazon_us_reviews',\n",
       " 'sewon/ambig_qa',\n",
       " 'nala-cub/americas_nli',\n",
       " 'legacy-datasets/ami',\n",
       " 'gavinxing/amttl',\n",
       " 'facebook/anli',\n",
       " 'sealuzh/app_reviews',\n",
       " 'deepmind/aqua_rat',\n",
       " 'google-research-datasets/aquamuse',\n",
       " 'bigIR/ar_cov19',\n",
       " 'hadyelsahar/ar_res_reviews',\n",
       " 'iabufarha/ar_sarcasm',\n",
       " 'abuelkhair-corpus/arabic_billion_words',\n",
       " 'QCRI/arabic_pos_dialect',\n",
       " 'halabi2016/arabic_speech_corpus',\n",
       " 'hsseinmz/arcd',\n",
       " 'ramybaly/arsentd_lev',\n",
       " 'allenai/art',\n",
       " 'arxiv-community/arxiv_dataset',\n",
       " 'tuanphong/ascent_kb',\n",
       " 'achrafothman/aslg_pc12',\n",
       " 'AmazonScience/asnq',\n",
       " 'facebook/asset',\n",
       " 'nilc-nlp/assin',\n",
       " 'nilc-nlp/assin2',\n",
       " 'allenai/atomic',\n",
       " 'nwu-ctext/autshumato',\n",
       " 'facebook/babi_qa',\n",
       " 'legacy-datasets/banking77',\n",
       " 'phiwi/bbaw_egyptian',\n",
       " 'midas/bbc_hindi_nli',\n",
       " 'spyysalo/bc2gm_corpus',\n",
       " 'AI-Lab-Makerere/beans',\n",
       " 'nectec/best2009',\n",
       " 'Helsinki-NLP/bianet',\n",
       " 'Helsinki-NLP/bible_para',\n",
       " 'NortheasternUniversity/big_patent',\n",
       " 'FiscalNote/billsum',\n",
       " 'microsoft/bing_coronavirus_query_set',\n",
       " 'nlpaueb/biomrc',\n",
       " 'tabilab/biosses',\n",
       " 'TheBritishLibrary/blbooks',\n",
       " 'TheBritishLibrary/blbooksgenre',\n",
       " 'ParlAI/blended_skill_talk',\n",
       " 'nyu-mll/blimp',\n",
       " 'barilan/blog_authorship_corpus',\n",
       " 'rezacsedu/bn_hate_speech',\n",
       " 'bnl-data/bnl_newspapers',\n",
       " 'bookcorpus/bookcorpus',\n",
       " 'defunct-datasets/bookcorpusopen',\n",
       " 'google/boolq',\n",
       " 'clarin-pl/bprec',\n",
       " 'allenai/break_data',\n",
       " 'UFRGS/brwac',\n",
       " 'ryo0634/bsd_ja_en',\n",
       " 'community-datasets/bswac',\n",
       " 'dataset-org/c3',\n",
       " 'legacy-datasets/c4',\n",
       " 'china-ai-law-challenge/cail2018',\n",
       " 'community-datasets/caner',\n",
       " 'soarescmsa/capes',\n",
       " 'kchawla123/casino',\n",
       " 'community-datasets/catalonia_independence',\n",
       " 'microsoft/cats_vs_dogs',\n",
       " 'community-datasets/cawac',\n",
       " 'cam-cst/cbt',\n",
       " 'statmt/cc100',\n",
       " 'vblagoje/cc_news',\n",
       " 'ahelk/ccaligned_multilingual',\n",
       " 'community-datasets/cdsc',\n",
       " 'ptaszynski/cdt',\n",
       " 'sagteam/cedr_v1',\n",
       " 'google-research-datasets/cfq',\n",
       " 'shiyue/chr_en',\n",
       " 'uoft-cs/cifar10',\n",
       " 'uoft-cs/cifar100',\n",
       " 'google-research-datasets/circa',\n",
       " 'google/civil_comments',\n",
       " 'community-datasets/clickbait_news_bg',\n",
       " 'tdiggelm/climate_fever',\n",
       " 'clinc/clinc_oos',\n",
       " 'clue/clue',\n",
       " 'hfl/cmrc2018',\n",
       " 'festvox/cmu_hinglish_dog',\n",
       " 'abisee/cnn_dailymail',\n",
       " 'google-research-datasets/coached_conv_pref',\n",
       " 'google-research-datasets/coarse_discourse',\n",
       " 'jaredfern/codah',\n",
       " 'code-search-net/code_search_net',\n",
       " 'google/code_x_glue_cc_clone_detection_big_clone_bench',\n",
       " 'google/code_x_glue_cc_clone_detection_poj104',\n",
       " 'google/code_x_glue_cc_cloze_testing_all',\n",
       " 'google/code_x_glue_cc_cloze_testing_maxmin',\n",
       " 'google/code_x_glue_cc_code_completion_line',\n",
       " 'google/code_x_glue_cc_code_completion_token',\n",
       " 'google/code_x_glue_cc_code_refinement',\n",
       " 'google/code_x_glue_cc_code_to_code_trans',\n",
       " 'google/code_x_glue_cc_defect_detection',\n",
       " 'google/code_x_glue_ct_code_to_text',\n",
       " 'google/code_x_glue_tc_nl_code_search_adv',\n",
       " 'google/code_x_glue_tc_text_to_code',\n",
       " 'google/code_x_glue_tt_text_to_text',\n",
       " 'iamrishiraj/com_qa',\n",
       " 'allenai/common_gen',\n",
       " 'speechbrain/common_language',\n",
       " 'legacy-datasets/common_voice',\n",
       " 'tau/commonsense_qa',\n",
       " 'hendrycks/competition_math',\n",
       " 'asuglia/compguesswhat',\n",
       " 'conceptnet5/conceptnet5',\n",
       " 'eriktks/conll2000',\n",
       " 'eriktks/conll2002',\n",
       " 'eriktks/conll2003',\n",
       " 'ZihanWangKi/conllpp',\n",
       " 'CFPB/consumer-finance-complaints',\n",
       " 'convai-challenge/conv_ai',\n",
       " 'convai-challenge/conv_ai_2',\n",
       " 'convai-challenge/conv_ai_3',\n",
       " 'pchristm/conv_questions',\n",
       " 'stanfordnlp/coqa',\n",
       " 'allenai/cord19',\n",
       " 'cornell-movie-dialog/cornell_movie_dialog',\n",
       " 'Salesforce/cos_e',\n",
       " 'allenai/cosmos_qa',\n",
       " 'ucrelnlp/counter',\n",
       " 'castorini/covid_qa_castorini',\n",
       " 'deepset/covid_qa_deepset',\n",
       " 'UCSD-AI4H/covid_qa_ucsd',\n",
       " 'community-datasets/covid_tweets_japanese',\n",
       " 'facebook/covost2',\n",
       " 'rishitdagli/cppe-5',\n",
       " 'stanfordnlp/craigslist_bargains',\n",
       " 'google-research-datasets/crawl_domain',\n",
       " 'microsoft/crd3',\n",
       " 'community-datasets/crime_and_punish',\n",
       " 'nyu-mll/crows_pairs',\n",
       " 'aviaefrat/cryptonite',\n",
       " 'community-datasets/cs_restaurants',\n",
       " 'theatticusproject/cuad-qa',\n",
       " 'facebook/curiosity_dialogs',\n",
       " 'li2017dailydialog/daily_dialog',\n",
       " 'alexandrainst/dane',\n",
       " 'community-datasets/danish_political_comments',\n",
       " 'Yale-LILY/dart',\n",
       " 'datacommonsorg/datacommons_factcheck',\n",
       " 'fancyzhx/dbpedia_14',\n",
       " 'benjaminvdb/dbrd',\n",
       " 'mikelewis0/deal_or_no_dialog',\n",
       " 'community-datasets/definite_pronoun_resolution',\n",
       " 'jcblaise/dengue_filipino',\n",
       " 'dataset-org/dialog_re',\n",
       " 'community-datasets/diplomacy_detection',\n",
       " 'community-datasets/disaster_response_messages',\n",
       " 'google-research-datasets/discofuse',\n",
       " 'sileod/discovery',\n",
       " 'google-research-datasets/disfl_qa',\n",
       " 'IBM/doc2dial',\n",
       " 'thunlp/docred',\n",
       " 'community-datasets/doqa',\n",
       " 'dataset-org/dream',\n",
       " 'ucinlp/drop',\n",
       " 'ibm/duorc',\n",
       " 'corona-tweet/dutch_social',\n",
       " 'community-datasets/dyk',\n",
       " 'tuetschek/e2e_nlg',\n",
       " 'tuetschek/e2e_nlg_cleaned',\n",
       " 'Helsinki-NLP/ecb',\n",
       " 'AUEB-NLP/ecthr_cases',\n",
       " 'tugstugi/eduge',\n",
       " 'community-datasets/ehealth_kd',\n",
       " 'Helsinki-NLP/eitb_parcc',\n",
       " 'tulipa762/electricity_load_diagrams',\n",
       " 'defunct-datasets/eli5',\n",
       " 'rexarski/eli5_category',\n",
       " 'Helsinki-NLP/emea',\n",
       " 'SemEvalWorkshop/emo',\n",
       " 'dair-ai/emotion',\n",
       " 'emotone-ar-cicling2017/emotone_ar',\n",
       " 'facebook/empathetic_dialogues',\n",
       " 'ThiagoCF05/enriched_web_nlg',\n",
       " 'CogComp/eraser_multi_rc',\n",
       " 'esnli/esnli',\n",
       " 'google-research-datasets/eth_py150_open',\n",
       " 'iamollas/ethos',\n",
       " 'community-datasets/eu_regulatory_ir',\n",
       " 'NLP-AUEB/eurlex',\n",
       " 'community-datasets/euronews',\n",
       " 'community-datasets/europa_eac_tm',\n",
       " 'community-datasets/europa_ecdc_tm',\n",
       " 'Helsinki-NLP/europarl',\n",
       " 'uwnlp/event2Mind',\n",
       " 'jaydeyoung/evidence_infer_treatment',\n",
       " 'mhardalov/exams',\n",
       " 'factckbr/factckbr',\n",
       " 'community-datasets/fake_news_english',\n",
       " 'jcblaise/fake_news_filipino',\n",
       " 'community-datasets/farsi_news',\n",
       " 'zalando-datasets/fashion_mnist',\n",
       " 'fever/fever',\n",
       " 'thunlp/few_rel',\n",
       " 'takala/financial_phrasebank',\n",
       " 'mpsilfve/finer',\n",
       " 'facebook-llama/flores',\n",
       " 'GETALP/flue',\n",
       " 'ethz/food101',\n",
       " 'illuin/fquad',\n",
       " 'KelvinJiang/freebase_qa',\n",
       " 'google-research-datasets/gap',\n",
       " 'GEM/gem',\n",
       " 'airesearch/generated_reviews_enth',\n",
       " 'community-datasets/generics_kb',\n",
       " 'elenanereiss/german_legal_entity_recognition',\n",
       " 'tudarmstadt-lt/germaner',\n",
       " 'GermanEval/germeval_14',\n",
       " 'Helsinki-NLP/giga_fren',\n",
       " 'Harvard/gigaword',\n",
       " 'community-datasets/glucose',\n",
       " 'nyu-mll/glue',\n",
       " 'community-datasets/gnad10',\n",
       " 'google-research-datasets/go_emotions',\n",
       " 'allenai/gooaq',\n",
       " 'google-research-datasets/google_wellformed_query',\n",
       " 'dki-lab/grail_qa',\n",
       " 'google-research-datasets/great_code',\n",
       " 'AI-team-UoA/greek_legal_code',\n",
       " 'Efstathios/guardian_authorship',\n",
       " 'community-datasets/gutenberg_time',\n",
       " 'jhu-cogsci/hans',\n",
       " 'usc-isi/hansards',\n",
       " 'Elnagara/hard',\n",
       " 'Linguateca/harem',\n",
       " 'community-datasets/has_part',\n",
       " 'legacy-datasets/hate_offensive',\n",
       " 'odegiber/hate_speech18',\n",
       " 'hate-speech-filipino/hate_speech_filipino',\n",
       " 'tdavidson/hate_speech_offensive',\n",
       " 'community-datasets/hate_speech_pl',\n",
       " 'hate-speech-portuguese/hate_speech_portuguese',\n",
       " 'Hate-speech-CNERG/hatexplain',\n",
       " 'UdS-LSV/hausa_voa_ner',\n",
       " 'UdS-LSV/hausa_voa_topics',\n",
       " 'NirantK/hda_nli_hindi',\n",
       " 'dvilares/head_qa',\n",
       " 'ImperialCollegeLondon/health_fact',\n",
       " 'projectbenyehuda/hebrew_projectbenyehuda',\n",
       " 'omilab/hebrew_sentiment',\n",
       " 'community-datasets/hebrew_this_world',\n",
       " 'Rowan/hellaswag',\n",
       " 'cais/mmlu',\n",
       " 'pary/hind_encorp',\n",
       " 'midas/hindi_discourse',\n",
       " 'allenai/hippocorpus',\n",
       " 'nanyang-technological-university-singapore/hkcancor',\n",
       " 'philippelaban/hlgd',\n",
       " 'dravidianlangtech/hope_edi',\n",
       " 'hotpotqa/hotpot_qa',\n",
       " 'hover-nlp/hover',\n",
       " 'community-datasets/hrenwac_para',\n",
       " 'community-datasets/hrwac',\n",
       " 'SemEvalWorkshop/humicroedit',\n",
       " 'wenhu/hybrid_qa',\n",
       " 'SemEvalWorkshop/hyperpartisan_news_detection',\n",
       " 'iapp/iapp_wiki_qa_squad',\n",
       " 'community-datasets/id_clickbait',\n",
       " 'fajrikoto/id_liputan6',\n",
       " 'grit-id/id_nergrit_corpus',\n",
       " 'community-datasets/id_newspapers_2018',\n",
       " 'cahya/id_panl_bppt',\n",
       " 'ilhamfp/id_puisi',\n",
       " 'ignatius/igbo_english_machine_translation',\n",
       " 'ignatius/igbo_monolingual',\n",
       " 'ignatius/igbo_ner',\n",
       " 'kmi-linguistics/ilist',\n",
       " 'stanfordnlp/imdb',\n",
       " 'mirfan899/imdb_urdu_reviews',\n",
       " 'facebook/imppres',\n",
       " 'ai4bharat/indic_glue',\n",
       " 'afaji/indonli',\n",
       " 'indonlp/indonlu',\n",
       " 'UT-CompLing/inquisitive_qg',\n",
       " 'yavuzkomecoglu/interpress_news_category_tr',\n",
       " 'yavuzkomecoglu/interpress_news_category_tr_lite',\n",
       " 'jkkummerfeld/irc_disentangle',\n",
       " 'nwu-ctext/isixhosa_ner_corpus',\n",
       " 'nwu-ctext/isizulu_ner_corpus',\n",
       " 'IWSLT/iwslt2017',\n",
       " 'jeopardy-datasets/jeopardy',\n",
       " 'jhu-clsp/jfleg',\n",
       " 'google/jigsaw_toxicity_pred',\n",
       " 'google/jigsaw_unintended_bias',\n",
       " 'jnlpba/jnlpba',\n",
       " 'community-datasets/journalists_questions',\n",
       " 'AdWeeb/kan_hope',\n",
       " 'gaurvar/kannada_news',\n",
       " 'thu-coai/kd_conv_with_kb',\n",
       " 'Helsinki-NLP/kde4',\n",
       " 'google-research-datasets/kelm',\n",
       " 'facebook/kilt_tasks',\n",
       " 'facebook/kilt_wikipedia',\n",
       " 'andreniyongabo/kinnews_kirnews',\n",
       " 'klue/klue',\n",
       " 'wicho/kor_3i4k',\n",
       " 'inmoonlight/kor_hate',\n",
       " 'nlp-kmu/kor_ner',\n",
       " 'kakaobrain/kor_nli',\n",
       " 'kakaobrain/kor_nlu',\n",
       " 'songys/kor_qpair',\n",
       " 'wicho/kor_sae',\n",
       " 'SpellOnYou/kor_sarcasm',\n",
       " 'mohamedadaly/labr',\n",
       " 'facebook/lama',\n",
       " 'cimec/lambada',\n",
       " 'josecannete/large_spanish_corpus',\n",
       " 'universityofbucharest/laroseda',\n",
       " 'mohnish/lc_quad',\n",
       " 'peluz/lener_br',\n",
       " 'coastalcph/lex_glue',\n",
       " 'ucsbnlp/liar',\n",
       " 'openslr/librispeech_asr',\n",
       " 'openslr/librispeech_lm',\n",
       " 'IBM/limit',\n",
       " 'lince-benchmark/lince',\n",
       " 'cambridgeltl/linnaeus',\n",
       " 'PKU-TANGENT/liveqa',\n",
       " 'keithito/lj_speech',\n",
       " 'billion-word-benchmark/lm1b',\n",
       " 'lst-nectec/lst20',\n",
       " 'cis-lmu/m_lama',\n",
       " 'nilc-nlp/mac_morpho',\n",
       " 'shanasai/makhzan',\n",
       " 'masakhane/masakhaner',\n",
       " 'deepmind/math_dataset',\n",
       " 'allenai/math_qa',\n",
       " 'WHUIR/matinf',\n",
       " 'google-research-datasets/mbpp',\n",
       " 'legacy-datasets/mc4',\n",
       " 'CogComp/mc_taco',\n",
       " 'facebook/md_gender_bias',\n",
       " 'facebook/mdd',\n",
       " 'QAngaroo/med_hop',\n",
       " 'McGill-NLP/medal',\n",
       " 'UCSD26/medical_dialog',\n",
       " 'curaihealth/medical_questions_pairs',\n",
       " 'UdS-LSV/menyo20k_mt',\n",
       " 'microsoft/meta_woz',\n",
       " 'midas/metooma',\n",
       " 'Zaid/metrec',\n",
       " 'PierreColombo/miam',\n",
       " 'siripragadashashank/mkb',\n",
       " 'apple/mkqa',\n",
       " 'facebook/mlqa',\n",
       " 'reciTAL/mlsum',\n",
       " 'ylecun/mnist',\n",
       " 'anthonychen/mocha',\n",
       " 'universityofbucharest/moroco',\n",
       " 'eraser-benchmark/movie_rationales',\n",
       " 'mrqa-workshop/mrqa',\n",
       " 'microsoft/ms_marco',\n",
       " 'microsoft/ms_terms',\n",
       " 'microsoft/msr_genomics_kbcomp',\n",
       " 'microsoft/msr_sqa',\n",
       " 'microsoft/msr_text_compression',\n",
       " 'microsoft/msr_zhen_translation_parity',\n",
       " 'levow/msra_ner',\n",
       " 'IWSLT/mt_eng_vietnamese',\n",
       " 'us-lsi/muchocine',\n",
       " 'jerbarnes/multi_booked',\n",
       " 'coastalcph/multi_eurlex',\n",
       " 'alexfabbri/multi_news',\n",
       " 'nyu-mll/multi_nli',\n",
       " 'nyu-mll/multi_nli_mismatch',\n",
       " 'Helsinki-NLP/multi_para_crawl',\n",
       " 'google-research-datasets/multi_re_qa',\n",
       " 'pfb30/multi_woz_v22',\n",
       " 'yaolu/multi_x_science_sum',\n",
       " 'IBM/multidoc2dial',\n",
       " 'legacy-datasets/multilingual_librispeech',\n",
       " 'stanfordnlp/mutual_friends',\n",
       " 'salesforce/mwsc',\n",
       " 'ayehninnkhine/myanmar_news',\n",
       " 'deepmind/narrativeqa',\n",
       " 'deepmind/narrativeqa_manual',\n",
       " 'google-research-datasets/natural_questions',\n",
       " 'ncbi/ncbi_disease',\n",
       " 'nwu-ctext/nchlt',\n",
       " 'ncslgr/ncslgr',\n",
       " 'rtw-cmu/nell',\n",
       " 'facebook/neural_code_search',\n",
       " 'Helsinki-NLP/news_commentary',\n",
       " 'google-research-datasets/newsgroup',\n",
       " 'jcblaise/newsph',\n",
       " 'jcblaise/newsph_nli',\n",
       " 'liaad/newspop',\n",
       " 'Maluuba/newsqa',\n",
       " 'lil-lab/newsroom',\n",
       " 'nkjp/nkjp-ner',\n",
       " 'boun-tabi/nli_tr',\n",
       " 'xingkunliuxtracta/nlu_evaluation_data',\n",
       " 'ltgoslo/norec',\n",
       " 'ltgoslo/norne',\n",
       " 'ljos/norwegian_ner',\n",
       " 'google-research-datasets/nq_open',\n",
       " 'e9t/nsmc',\n",
       " 'INK-USC/numer_sense',\n",
       " 'yanaiela/numeric_fused_head',\n",
       " 'community-datasets/oclar',\n",
       " 'vpmoreira/offcombr',\n",
       " 'coltekin/offenseval2020_tr',\n",
       " 'community-datasets/offenseval_dravidian',\n",
       " 'Helsinki-NLP/ofis_publik',\n",
       " 'community-datasets/ohsumed',\n",
       " 'knowitall/ollie',\n",
       " 'OFAI/omp',\n",
       " 'iastate/onestop_english',\n",
       " 'malmaud/onestop_qa',\n",
       " 'Helsinki-NLP/open_subtitles',\n",
       " 'openai/openai_humaneval',\n",
       " 'allenai/openbookqa',\n",
       " 'openslr/openslr',\n",
       " 'Skylion007/openwebtext',\n",
       " 'kavgan/opinosis',\n",
       " 'Helsinki-NLP/opus-100',\n",
       " 'Helsinki-NLP/opus_books',\n",
       " 'Helsinki-NLP/opus_dgt',\n",
       " 'Helsinki-NLP/opus_dogc',\n",
       " 'Helsinki-NLP/opus_elhuyar',\n",
       " 'Helsinki-NLP/euconst',\n",
       " 'Helsinki-NLP/opus_finlex',\n",
       " 'Helsinki-NLP/opus_fiskmo',\n",
       " 'Helsinki-NLP/opus_gnome',\n",
       " 'Helsinki-NLP/opus_infopankki',\n",
       " 'Helsinki-NLP/opus_memat',\n",
       " 'Helsinki-NLP/opus_montenegrinsubs',\n",
       " 'Helsinki-NLP/opus_openoffice',\n",
       " 'Helsinki-NLP/opus_paracrawl',\n",
       " 'Helsinki-NLP/opus_rf',\n",
       " 'Helsinki-NLP/opus_tedtalks',\n",
       " 'Helsinki-NLP/opus_ubuntu',\n",
       " 'Helsinki-NLP/opus_wikipedia',\n",
       " 'Helsinki-NLP/opus_xhosanavy',\n",
       " 'EdinburghNLP/orange_sum',\n",
       " 'oscar-corpus/oscar',\n",
       " 'ParaCrawl/para_crawl',\n",
       " 'ParaPat/para_pat',\n",
       " 'community-datasets/parsinlu_reading_comprehension',\n",
       " 'yukimasano/pass',\n",
       " 'google-research-datasets/paws-x',\n",
       " 'google-research-datasets/paws',\n",
       " 'peixiang/pec',\n",
       " 'allenai/peer_read',\n",
       " 'peoples-daily-ner/peoples_daily_ner',\n",
       " 'community-datasets/per_sent',\n",
       " 'HaniehPoostchi/persian_ner',\n",
       " 'deepmind/pg19',\n",
       " 'Helsinki-NLP/php',\n",
       " 'AgentPublic/piaf',\n",
       " 'jerin/pib',\n",
       " 'ybisk/piqa',\n",
       " 'HooshvareLab/pn_summary',\n",
       " 'google-research-datasets/poem_sentiment',\n",
       " 'clarin-pl/polemo2',\n",
       " 'poleval/poleval2019_cyberbullying',\n",
       " 'poleval/poleval2019_mt',\n",
       " 'maciej-ogrodniczuk/polsum',\n",
       " 'rmyeid/polyglot_ner',\n",
       " 'PyThaiNLP/prachathai67k',\n",
       " 'sileod/pragmeval',\n",
       " 'community-datasets/proto_qa',\n",
       " 'community-datasets/psc',\n",
       " 'ptb-text-only/ptb_text_only',\n",
       " 'ncbi/pubmed',\n",
       " 'qiaojin/PubMedQA',\n",
       " '1stvamp/py_ast',\n",
       " 'community-datasets/qa4mre',\n",
       " 'luheng/qa_srl',\n",
       " 'community-datasets/qa_zre',\n",
       " 'community-datasets/qangaroo',\n",
       " 'community-datasets/qanta',\n",
       " 'allenai/qasc',\n",
       " 'allenai/qasper',\n",
       " 'google-research-datasets/qed',\n",
       " 'Helsinki-NLP/qed_amara',\n",
       " 'allenai/quac',\n",
       " 'textmachinelab/quail',\n",
       " 'community-datasets/quarel',\n",
       " 'allenai/quartz',\n",
       " 'quora-competitions/quora',\n",
       " 'allenai/quoref',\n",
       " 'ehovy/race',\n",
       " 'community-datasets/re_dial',\n",
       " 'mhardalov/reasoning_bg',\n",
       " 'mbien/recipe_nlg',\n",
       " 'community-datasets/reclor',\n",
       " 'kdexd/red_caps',\n",
       " 'webis/tldr-17',\n",
       " 'ctr4si/reddit_tifu',\n",
       " 'eleftheria/refresd',\n",
       " 'ucirvine/reuters21578',\n",
       " 'INK-USC/riddle_sense',\n",
       " 'dumitrescustefan/ro_sent',\n",
       " 'dumitrescustefan/ro_sts',\n",
       " 'dumitrescustefan/ro_sts_parallel',\n",
       " 'community-datasets/roman_urdu',\n",
       " 'community-datasets/ronec',\n",
       " 'allenai/ropes',\n",
       " 'cornell-movie-review-data/rotten_tomatoes',\n",
       " 'RussianNLP/russian_super_glue',\n",
       " 'Samsung/samsum',\n",
       " 'surajp/sanskrit_classic',\n",
       " 'inparallel/saudinewsnet',\n",
       " 'kuznetsoffandrey/sberquad',\n",
       " 'scan-tasks/scan-tasks',\n",
       " 'airesearch/scb_mt_enth_2020',\n",
       " 'zhoubolei/scene_parse_150',\n",
       " 'google-research-datasets/schema_guided_dstc8',\n",
       " 'allenai/scicite',\n",
       " 'community-datasets/scielo',\n",
       " 'armanc/scientific_papers',\n",
       " 'allenai/scifact',\n",
       " 'allenai/sciq',\n",
       " 'allenai/scitail',\n",
       " 'allenai/scitldr',\n",
       " 'kyunghyuncho/search_qa',\n",
       " 'hirupert/sede',\n",
       " 'community-datasets/selqa',\n",
       " 'SemEvalWorkshop/sem_eval_2010_task_8',\n",
       " 'SemEvalWorkshop/sem_eval_2014_task_1',\n",
       " 'SemEvalWorkshop/sem_eval_2018_task_1',\n",
       " 'SemEvalWorkshop/sem_eval_2020_task_11',\n",
       " 'google-research-datasets/sent_comp',\n",
       " 'senti-lex/senti_lex',\n",
       " 'community-datasets/senti_ws',\n",
       " 'stanfordnlp/sentiment140',\n",
       " 'community-datasets/sepedi_ner',\n",
       " 'nwu-ctext/sesotho_ner_corpus',\n",
       " 'community-datasets/setimes',\n",
       " 'nwu-ctext/setswana_ner_corpus',\n",
       " 'UCLNLP/sharc',\n",
       " 'nikhilweee/sharc_modified',\n",
       " 'RobZamp/sick',\n",
       " 'eusip/silicone',\n",
       " 'fbougares/simple_questions_v2',\n",
       " 'nwu-ctext/siswati_ner_corpus',\n",
       " 'dfki-nlp/smartdata',\n",
       " 'ucirvine/sms_spam',\n",
       " 'sonos-nlu-benchmark/snips_built_in_intents',\n",
       " 'stanfordnlp/snli',\n",
       " 'SNOW-NLP/snow_simplified_japanese_corpus',\n",
       " 'community-datasets/so_stacksample',\n",
       " 'allenai/social_bias_frames',\n",
       " 'allenai/social_i_qa',\n",
       " 'boschresearch/sofc_materials_articles',\n",
       " 'community-datasets/sogou_news',\n",
       " 'crscardellino/spanish_billion_words',\n",
       " 'Helsinki-NLP/spc',\n",
       " 'spyysalo/species_800',\n",
       " 'google/speech_commands',\n",
       " 'xlangai/spider',\n",
       " 'rajpurkar/squad',\n",
       " 'stanfordnlp/squad_adversarial',\n",
       " 'ccasimiro/squad_es',\n",
       " 'crux82/squad_it',\n",
       " 'KorQuAD/squad_kor_v1',\n",
       " 'KorQuAD/squad_kor_v2',\n",
       " 'nunorc/squad_v1_pt',\n",
       " 'rajpurkar/squad_v2',\n",
       " 'ludwigschmidt/squadshifts',\n",
       " 'community-datasets/srwac',\n",
       " 'stanfordnlp/sst',\n",
       " 'McGill-NLP/stereoset',\n",
       " 'LSDSem/story_cloze',\n",
       " 'timpal0l/stsb_mt_sv',\n",
       " 'PhilipMay/stsb_multi_mt',\n",
       " 'community-datasets/style_change_detection',\n",
       " 'megagonlabs/subjqa',\n",
       " 'aps/super_glue',\n",
       " 's3prl/superb',\n",
       " 'ufldl-stanford/svhn',\n",
       " 'allenai/swag',\n",
       " 'uestc-swahili/swahili',\n",
       " 'community-datasets/swahili_news',\n",
       " 'cgpotts/swda',\n",
       " 'community-datasets/swedish_medical_ner',\n",
       " 'klintan/swedish_ner_corpus',\n",
       " 'timpal0l/swedish_reviews',\n",
       " 'rcds/swiss_judgment_prediction',\n",
       " 'wenhu/tab_fact',\n",
       " 'community-datasets/tamilmixsentiment',\n",
       " 'Helsinki-NLP/tanzil',\n",
       " 'community-datasets/tapaco',\n",
       " 'community-datasets/tashkeela',\n",
       " 'google-research-datasets/taskmaster1',\n",
       " 'google-research-datasets/taskmaster2',\n",
       " 'google-research-datasets/taskmaster3',\n",
       " 'Helsinki-NLP/tatoeba',\n",
       " 'neulab/ted_hrlr',\n",
       " 'Helsinki-NLP/ted_iwlst2013',\n",
       " 'neulab/ted_multi',\n",
       " 'IWSLT/ted_talks_iwslt',\n",
       " 'community-datasets/telugu_books',\n",
       " 'community-datasets/telugu_news',\n",
       " 'Helsinki-NLP/tep_en_fa_para',\n",
       " 'alevkov95/text2log',\n",
       " 'tmu-nlp/thai_toxicity_tweet',\n",
       " 'wannaphong/thainer',\n",
       " 'pythainlp/thaiqa_squad',\n",
       " 'nakhun/thaisum',\n",
       " 'EleutherAI/pile',\n",
       " 'defunct-datasets/the_pile_books3',\n",
       " 'defunct-datasets/the_pile_openwebtext2',\n",
       " 'defunct-datasets/the_pile_stack_exchange',\n",
       " 'Helsinki-NLP/tilde_model',\n",
       " 'google-research-datasets/time_dial',\n",
       " 'community-datasets/times_of_india_news_headlines',\n",
       " 'timit-asr/timit_asr',\n",
       " 'karpathy/tiny_shakespeare',\n",
       " 'jitkapat/tlc',\n",
       " 'tmu-nlp/tmu_gfm_dataset',\n",
       " 'JAugusto97/told-br',\n",
       " 'google-research-datasets/totto',\n",
       " 'CogComp/trec',\n",
       " 'mandarjoshi/trivia_qa',\n",
       " 'fbougares/tsac',\n",
       " 'savasy/ttc4900',\n",
       " 'chaymafourati/tunizi',\n",
       " 'allenai/tuple_ie',\n",
       " 'community-datasets/turk',\n",
       " 'turkic-interlingua/turkic_xwmt',\n",
       " 'mkeskin/turkish_movie_sentiment',\n",
       " 'erayyildiz/turkish_ner',\n",
       " 'fthbrmnby/turkish_product_reviews',\n",
       " 'community-datasets/turkish_shrinked_ner',\n",
       " 'TurkuNLP/turku_ner_corpus',\n",
       " 'cardiffnlp/tweet_eval',\n",
       " 'ucsbnlp/tweet_qa',\n",
       " 'alt-qsri/tweets_ar_en_parallel',\n",
       " 'tweets-hate-speech-detection/tweets_hate_speech_detection',\n",
       " 'ajesujoba/twi_text_c3',\n",
       " 'ajesujoba/twi_wordsim353',\n",
       " 'google-research-datasets/tydiqa',\n",
       " 'ubuntu-dialogs-corpus/ubuntu_dialogs_corpus',\n",
       " 'community-datasets/udhr',\n",
       " 'community-datasets/um005',\n",
       " 'Helsinki-NLP/un_ga',\n",
       " 'Helsinki-NLP/multiun',\n",
       " 'Helsinki-NLP/un_pc',\n",
       " 'universal-dependencies/universal_dependencies',\n",
       " 'unimorph/universal_morphologies',\n",
       " 'community-datasets/urdu_fake_news',\n",
       " 'community-datasets/urdu_sentiment_corpus',\n",
       " 'CSTR-Edinburgh/vctk',\n",
       " 'AILAB-VNUHCM/vivos',\n",
       " 'webnlg-challenge/web_nlg',\n",
       " 'HDLTex/web_of_science',\n",
       " 'Stanford/web_questions',\n",
       " 'hltcoe/weibo_ner',\n",
       " 'bea2019st/wi_locness',\n",
       " 'CUHK-CSE/wider_face',\n",
       " 'google/wiki40b',\n",
       " 'neulab/wiki_asp',\n",
       " 'google-research-datasets/wiki_atomic_edits',\n",
       " 'chaojiang06/wiki_auto',\n",
       " 'michaelauli/wiki_bio',\n",
       " 'facebook/wiki_dpr',\n",
       " 'QAngaroo/wiki_hop',\n",
       " 'esdurmus/wiki_lingua',\n",
       " 'facebook/wiki_movies',\n",
       " 'microsoft/wiki_qa',\n",
       " 'qcri/wiki_qa_ar',\n",
       " 'community-datasets/wiki_snippets',\n",
       " 'Helsinki-NLP/wiki_source',\n",
       " 'google-research-datasets/wiki_split',\n",
       " 'm3hrdadfi/wiki_summary',\n",
       " 'unimelb-nlp/wikiann',\n",
       " 'gboleda/wikicorpus',\n",
       " 'wangwilliamyang/wikihow',\n",
       " 'legacy-datasets/wikipedia',\n",
       " 'Salesforce/wikisql',\n",
       " 'Salesforce/wikitext',\n",
       " 'clt-dlsu/wikitext_tl39',\n",
       " 'MartinThoma/wili_2018',\n",
       " 'uclanlp/wino_bias',\n",
       " 'ErnestSDavis/winograd_wsc',\n",
       " 'allenai/winogrande',\n",
       " 'allenai/wiqa',\n",
       " 'pythainlp/wisesight1000',\n",
       " 'pythainlp/wisesight_sentiment',\n",
       " 'wmt/wmt14',\n",
       " 'wmt/wmt15',\n",
       " 'wmt/wmt16',\n",
       " 'wmt/wmt17',\n",
       " 'wmt/wmt18',\n",
       " 'wmt/wmt19',\n",
       " 'wmt/wmt20_mlqe_task1',\n",
       " 'wmt/wmt20_mlqe_task2',\n",
       " 'wmt/wmt20_mlqe_task3',\n",
       " 'wmt/wmt_t2t',\n",
       " 'leondz/wnut_17',\n",
       " 'Wongnai/wongnai_reviews',\n",
       " 'PolyAI/woz_dialogue',\n",
       " 'CLARIN-PL/wrbsc',\n",
       " 'ZurichNLP/x_stance',\n",
       " 'cambridgeltl/xcopa',\n",
       " 'INK-USC/xcsr',\n",
       " 'Helsinki-NLP/xed_en_fi',\n",
       " 'microsoft/xglue',\n",
       " 'facebook/xnli',\n",
       " 'akariasai/xor_tydi_qa',\n",
       " 'google/xquad',\n",
       " 'google-research-datasets/xquad_r',\n",
       " 'EdinburghNLP/xsum',\n",
       " 'google-research-datasets/xsum_factuality',\n",
       " 'google/xtreme',\n",
       " 'nfL6/yahoo_answers_qa',\n",
       " 'community-datasets/yahoo_answers_topics',\n",
       " 'fancyzhx/yelp_polarity',\n",
       " 'Yelp/yelp_review_full',\n",
       " 'UdS-LSV/yoruba_bbc_topics',\n",
       " 'ajesujoba/yoruba_gv_ner',\n",
       " 'ajesujoba/yoruba_text_c3',\n",
       " 'ajesujoba/yoruba_wordsim353',\n",
       " 'community-datasets/youtube_caption_corrections',\n",
       " 'allenai/zest',\n",
       " '0n1xus/codexglue',\n",
       " '0n1xus/pytorrent-standalone',\n",
       " 'AConsApart/anime_subtitles_DialoGPT',\n",
       " 'AHussain0418/day2_data',\n",
       " 'AHussain0418/day4data',\n",
       " 'AHussain0418/demo_data',\n",
       " 'AI-Sweden/SuperLim',\n",
       " 'AI-it/khs_service_test',\n",
       " 'AI-it/korean-hate-speech',\n",
       " 'ARKseal/YFCC14M_subset_webdataset',\n",
       " 'ARTeLab/fanpage',\n",
       " 'ARTeLab/ilpost',\n",
       " 'ARTeLab/mlsum-it',\n",
       " 'ASCCCCCCCC/amazon_zh',\n",
       " 'ASCCCCCCCC/amazon_zh_simple',\n",
       " 'Abdo1Kamr/Arabic_Hadith',\n",
       " 'Abirate/code_net_dataset',\n",
       " 'Abirate/code_net_dev_dataset',\n",
       " 'Abirate/code_net_test_final_dataset',\n",
       " 'Abirate/english_quotes',\n",
       " 'Abirate/french_book_reviews',\n",
       " 'AdWeeb/DravidianMT',\n",
       " 'Adnan/Urdu_News_Headlines',\n",
       " 'AhmadSawal/qa',\n",
       " 'AhmedSSoliman/CoNaLa',\n",
       " 'Aisha/BAAD16',\n",
       " 'Aisha/BAAD6',\n",
       " 'Akila/ForgottenRealmsWikiDataset',\n",
       " 'Akshith/aa',\n",
       " 'Akshith/g_rock',\n",
       " 'Akshith/test',\n",
       " 'adorkin/extended_tweet_emojis',\n",
       " 'AlekseyKorshuk/comedy-scripts',\n",
       " 'AlekseyKorshuk/horror-scripts',\n",
       " 'AlexMaclean/all-deletion-compressions',\n",
       " 'AlexMaclean/wikipedia-deletion-compressions',\n",
       " 'AlexZapolskii/zapolskii-amazon',\n",
       " 'Aliseyfi/event_token_type',\n",
       " 'Alvenir/nst-da-16khz',\n",
       " 'AndrewMcDowell/de_corpora_parliament_processed',\n",
       " 'Annabelleabbott/real-fake-news-workshop',\n",
       " 'Annielytics/DoctorsNotes',\n",
       " 'Anurag-Singh-creator/task',\n",
       " 'Anurag-Singh-creator/tasks',\n",
       " 'ApiInferenceTest/asr_dummy',\n",
       " 'Arnold/hausa_common_voice',\n",
       " 'AryanLala/autonlp-data-Scientific_Title_Generator',\n",
       " 'Atsushi/fungi_diagnostic_chars_comparison_japanese',\n",
       " 'Atsushi/fungi_indexed_mycological_papers_japanese',\n",
       " 'Atsushi/fungi_trait_circus_database',\n",
       " 'Avishekavi/Avi',\n",
       " 'Babelscape/rebel-dataset',\n",
       " 'Babelscape/wikineural',\n",
       " 'BatuhanYilmaz/github-issues',\n",
       " 'Baybars/parla_text_corpus',\n",
       " 'BeIR/beir-corpus',\n",
       " 'BeIR/beir',\n",
       " 'Lacito/pangloss',\n",
       " 'Binbin/my_dataset',\n",
       " 'BlakesOrb6/Fred-Flintstone',\n",
       " 'Bosio/pacman',\n",
       " 'Bosio/pacman_descriptions',\n",
       " 'TheBritishLibrary/EThOS-PhD-metadata',\n",
       " 'CAGER/rick',\n",
       " 'CALM/arwiki',\n",
       " 'CAiRE/ASCEND',\n",
       " 'CShorten/KerasBERT',\n",
       " 'ChadxxxxHall/Inter-vision',\n",
       " 'Champion/vpc2020_clear_anon_speech',\n",
       " 'Check/a_re_gi',\n",
       " 'Check/region_1',\n",
       " 'Check/region_2',\n",
       " 'Check/region_3',\n",
       " 'Check/region_4',\n",
       " 'Check/region_5',\n",
       " 'Check/region_6',\n",
       " 'Check/region_7',\n",
       " 'Check/region_8',\n",
       " 'Check/region_9',\n",
       " 'Check/regions',\n",
       " 'Check/vverify',\n",
       " 'Cheranga/test',\n",
       " 'ChristophSchuhmann/MS_COCO_2017_URL_TEXT',\n",
       " 'Chun/dataset',\n",
       " 'Chuu/Vhh',\n",
       " 'CodedotAI/code-clippy-tfrecords',\n",
       " 'CodedotAI/code_clippy',\n",
       " 'CodedotAI/code_clippy_github',\n",
       " 'Crives/haha',\n",
       " 'Cropinky/flatearther',\n",
       " 'Cropinky/rap_lyrics_english',\n",
       " 'Cropinky/wow_fishing_bobber',\n",
       " 'Cyberfish/pos_tagger',\n",
       " 'Cyberfish/text_error_correction',\n",
       " 'CyranoB/polarity',\n",
       " 'DDSC/angry-tweets',\n",
       " 'DDSC/dkhate',\n",
       " 'DDSC/europarl',\n",
       " 'DDSC/lcc',\n",
       " 'DDSC/reddit-da-asr-preprocessed',\n",
       " 'DDSC/reddit-da',\n",
       " 'DELith/github-issues',\n",
       " 'DSCI511G1/COP26_Energy_Transition_Tweets',\n",
       " 'DanL/scientific-challenges-and-directions-dataset',\n",
       " 'Daniele/dante-corpus',\n",
       " 'Darren/data',\n",
       " 'Nexdata/accented_english',\n",
       " 'Nexdata/accented_mandarin',\n",
       " 'Nexdata/chinese_dialect',\n",
       " 'Nexdata/mandarin_chinese',\n",
       " 'Nexdata/mixed_speech_chinese_english',\n",
       " 'Nexdata/multi_language',\n",
       " 'Nexdata/multi_language_conversation',\n",
       " 'Davlan/conll2003_de_noMISC',\n",
       " 'Davlan/conll2003_noMISC',\n",
       " 'Davlan/masakhanerV1',\n",
       " 'DelgadoPanadero/Pokemon',\n",
       " 'DeskDown/ALTDataset',\n",
       " 'DeskDown/ALTDataset_en-to-fil-vi-id-ms-ja-khm',\n",
       " 'DiFronzo/Human_Activity_Recognition',\n",
       " 'Dmitriy612/1',\n",
       " 'Doohae/klue-mrc-bm25',\n",
       " 'Doohae/modern_music_re',\n",
       " 'DoyyingFace/github-embeddings-doy',\n",
       " 'DoyyingFace/github-issues-doy',\n",
       " 'DrishtiSharma/as_opus100_processed',\n",
       " 'DrishtiSharma/bg_opus100_processed',\n",
       " 'DrishtiSharma/br_opus100_processed',\n",
       " 'DrishtiSharma/hi_opus100_processed',\n",
       " 'DrishtiSharma/kk_opus100_processed',\n",
       " 'DrishtiSharma/mr_opus100_processed',\n",
       " 'DrishtiSharma/or_opus100_processed',\n",
       " 'DrishtiSharma/sl_opus100_processed',\n",
       " 'DrishtiSharma/sr_opus100_processed',\n",
       " 'EMBO/biolang',\n",
       " 'EMBO/sd-nlp',\n",
       " 'ESZER/H',\n",
       " 'Emanuel/UD_Portuguese-Bosque',\n",
       " 'Emma121/aaaaa',\n",
       " 'Emma121/testtest',\n",
       " 'Enes3774/data',\n",
       " 'Exr0n/wiki-entity-similarity',\n",
       " 'Eymen3455/xsum_tr',\n",
       " 'FIG-Loneliness/FIG-Loneliness',\n",
       " 'FL33TW00D/test-dataset',\n",
       " 'FRTNX/cosuju',\n",
       " 'FRTNX/worldbank-projects',\n",
       " 'Felix-ML/quoteli3',\n",
       " 'Finnish-NLP/mc4_fi_cleaned',\n",
       " 'Firoj/HumAID',\n",
       " 'Francois/futures_es',\n",
       " 'Fraser/mnist-text-default',\n",
       " 'Fraser/mnist-text-no-spaces',\n",
       " 'Fraser/mnist-text-small',\n",
       " 'Fraser/dream-coder',\n",
       " 'Fraser/python-lines',\n",
       " 'Fraser/python-state-changes',\n",
       " 'Fraser/short-jokes',\n",
       " 'Fraser/wiki_sentences',\n",
       " 'GEM/ART',\n",
       " 'GEM/BiSECT',\n",
       " 'GEM/CrossWOZ',\n",
       " 'GEM/OrangeSum',\n",
       " 'GEM/RiSAWOZ',\n",
       " 'GEM/RotoWire_English-German',\n",
       " 'GEM/SIMPITIKI',\n",
       " 'GEM/SciDuet',\n",
       " 'GEM/Taskmaster',\n",
       " 'GEM/cochrane-simplification',\n",
       " 'GEM/common_gen',\n",
       " 'GEM/conversational_weather',\n",
       " 'GEM/cs_restaurants',\n",
       " 'GEM/dart',\n",
       " 'GEM/dstc10_track2_task2',\n",
       " 'GEM/e2e_nlg',\n",
       " 'GEM/indonlg',\n",
       " 'GEM/mlb_data_to_text',\n",
       " 'GEM/mlsum',\n",
       " 'GEM/opusparcus',\n",
       " 'GEM/references',\n",
       " 'GEM/schema_guided_dialog',\n",
       " 'GEM/sportsett_basketball',\n",
       " 'GEM/squad_v2',\n",
       " 'GEM/surface_realisation_st_2020',\n",
       " 'GEM/totto',\n",
       " 'GEM/turku_hockey_data2text',\n",
       " 'GEM/turku_paraphrase_corpus',\n",
       " 'GEM-submissions/v1-outputs-and-scores',\n",
       " 'GEM/viggo',\n",
       " 'GEM/web_nlg',\n",
       " 'GEM/wiki_auto_asset_turk',\n",
       " 'GEM/wiki_cat_sum',\n",
       " 'GEM/wiki_lingua',\n",
       " 'GEM/xlsum',\n",
       " 'GEM/xsum',\n",
       " 'GEM-submissions/GEM__bart_base_schema_guided_dialog__1645547915',\n",
       " 'GEM-submissions/Leo__bart-large__1645784880',\n",
       " 'GEM-submissions/Leo__mbart-large-cc25__1645802644',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1645558682',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1645559101',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1645800191',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646049378',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646049424',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646049601',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646049876',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646050898',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646051364',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646052073',\n",
       " 'GEM-submissions/lewtun__this-is-a-test__1646052811',\n",
       " 'GEM-submissions/lewtun__this-is-a-test__1646230987',\n",
       " 'GEM-submissions/ratishsp',\n",
       " 'GEM-submissions/submission-scores',\n",
       " 'GV05/shlomit_speech',\n",
       " 'Gabriel/quora_swe',\n",
       " 'GalacticAI/Noirset',\n",
       " 'Gauravadlakha1509/new_one',\n",
       " 'GeoffVdr/cv8_trainval_processed',\n",
       " 'GonzaloA/fake_news',\n",
       " 'Graphcore/gqa-lxmert',\n",
       " 'Graphcore/gqa',\n",
       " 'Graphcore/vqa-lxmert',\n",
       " 'Graphcore/vqa',\n",
       " 'Graphcore/wikipedia-bert-128',\n",
       " 'Graphcore/wikipedia-bert-512',\n",
       " 'GroNLP/ik-nlp-22_pestyle',\n",
       " 'GroNLP/ik-nlp-22_slp',\n",
       " 'GroNLP/ik-nlp-22_transqe',\n",
       " 'GroNLP/ik-nlp-22_winemag',\n",
       " 'HHousen/ParaSCI',\n",
       " 'HHousen/msrp',\n",
       " 'HHousen/quora',\n",
       " 'HUPD/hupd',\n",
       " 'Halilyesilceng/autonlp-data-nameEntityRecognition',\n",
       " 'HarleyQ/WitcherDialogue',\n",
       " 'HarrisDePerceptron/sv_corpora_parliament_processed',\n",
       " 'HarrisDePerceptron/ur_corpora_pib',\n",
       " 'Harveenchadha/bol-models',\n",
       " 'Harveenchadha/indic-voice',\n",
       " 'HarveyBWest/mybot',\n",
       " 'Hellisotherpeople/DebateSum',\n",
       " 'Helsinki-NLP/tatoeba_mt',\n",
       " 'HenryAI/KerasAPIReference.txt',\n",
       " 'HenryAI/KerasBERTv1-Data',\n",
       " 'HenryAI/KerasCodeExamples.txt',\n",
       " 'HenryAI/KerasDeveloperGuides.txt',\n",
       " 'Huertas97/autonlp-data-mami-semeval-20-21',\n",
       " 'Husain/intent-classification-en-fr',\n",
       " 'IFSTalfredoswald/MBTI',\n",
       " 'Iftoo95/Arabic_Sentiment_and_Topics',\n",
       " 'IlyaGusev/gazeta',\n",
       " 'IlyaGusev/headline_cause',\n",
       " 'Intel/WEC-Eng',\n",
       " 'Ishwar/Senti',\n",
       " 'Iskaj/dutch_corpora_parliament_processed',\n",
       " 'JIWON/nil_dataset',\n",
       " 'JIsanan/war-ceb-wikipedia',\n",
       " 'Jack0508/TED2020_kor',\n",
       " 'Jack0508/TED2020_vi',\n",
       " 'Jack0508/TED2020vi_kor',\n",
       " 'Jack0508/demo',\n",
       " 'Jack0508/eng_vi_demo',\n",
       " 'Jack0508/test',\n",
       " 'Jack0508/vi-ko-TED-txt',\n",
       " ...]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import list_datasets\n",
    "available_datasets = list_datasets()\n",
    "available_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb78ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"cnn_dailymail\", \"2.0.0\", split = 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f8a31e",
   "metadata": {},
   "source": [
    "## A sneak peek on what is done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dab15",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74ecdc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['article']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839513dd",
   "metadata": {},
   "source": [
    "token for unprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "436b24a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2414,  1010,  2563,  1006, 26665,  1007,  1011,  1011,  4302,\n",
      "         10693,  2732,  3817, 22603, 12154,  3229,  2000,  1037,  2988, 21853,\n",
      "          2692,  2454,  1006,  1002,  4601,  1012,  1015,  2454,  1007,  7280,\n",
      "          2004,  2002,  4332,  2324,  2006,  6928,  1010,  2021,  2002, 16818,\n",
      "          1996,  2769,  2180,  1005,  1056,  3459,  1037,  6297,  2006,  2032,\n",
      "          1012,  3817, 22603,  2004,  4302, 10693,  1999,  1000,  4302, 10693,\n",
      "          1998,  1996,  2344,  1997,  1996,  6708,  1000,  2000,  1996, 10520,\n",
      "          1997, 13761, 13317,  2015,  2105,  1996,  2088,  1010,  1996,  2402,\n",
      "          3364,  2758,  2002,  2038,  2053,  3488,  2000, 10424, 27100,  2099,\n",
      "          2010,  5356,  2185,  2006,  3435,  3765,  1010,  4392,  1998,  8958,\n",
      "          4243,  1012,  1000,  1045,  2123,  1005,  1056,  2933,  2000,  2022,\n",
      "          2028,  1997,  2216,  2111,  2040,  1010,  2004,  2574,  2004,  2027,\n",
      "          2735,  2324,  1010,  3402,  4965,  3209,  1037,  5294,  2998,  2482,\n",
      "          3074,  2030,  2242,  2714,  1010,  1000,  2002,  2409,  2019,  2827,\n",
      "          4357,  2121,  3041,  2023,  3204,  1012,  1000,  1045,  2123,  1005,\n",
      "          1056,  2228,  1045,  1005,  2222,  2022,  3391, 27856,  1012,  1000,\n",
      "          1996,  2477,  1045,  2066,  9343,  2024,  2477,  2008,  3465,  2055,\n",
      "          2184,  7038,  1011,  1011,  2808,  1998, 14340,  1998, 22477,  1012,\n",
      "          1000,  2012,  2324,  1010, 22603,  2097,  2022,  2583,  2000, 18503,\n",
      "          1999,  1037,  9270,  1010,  4965,  1037,  4392,  1999,  1037,  9047,\n",
      "          2030,  2156,  1996,  5469,  2143,  1000, 21071,  1024,  2112,  2462,\n",
      "          1010,  1000,  2747,  2416,  3182,  2917,  2010,  2193,  2028,  3185,\n",
      "          2006,  1996,  2866,  3482,  2436,  3673,  1012,  4751,  1997,  2129,\n",
      "          2002,  1005,  2222,  2928,  2010,  8637,  5798,  2024,  2104, 19735,\n",
      "          1012,  2010,  4005,  1998,  2270,  2923,  2018,  2053,  7615,  2006,\n",
      "          2010,  3488,  1012,  1000,  1045,  1005,  2222,  5791,  2031,  2070,\n",
      "          4066,  1997,  2283,  1010,  1000,  2002,  2056,  1999,  2019,  4357,\n",
      "          1012,  1000, 11504,  3904,  1997,  2017,  2097,  2022,  3752,  2055,\n",
      "          2009,  1012,  1000, 22603,  1005,  1055, 16565,  2013,  1996,  2034,\n",
      "          2274, 10693,  3152,  2031,  2042,  2218,  1999,  1037,  3404,  4636,\n",
      "          2029,  2002,  2038,  2025,  2042,  2583,  2000,  3543,  1012,  2750,\n",
      "          2010,  3652,  4476,  1998, 26768,  1010,  1996,  3364,  2758,  2002,\n",
      "          2003,  4363,  2010,  2519,  7933,  2006,  1996,  2598,  1012,  1000,\n",
      "          2111,  2024,  2467,  2559,  2000,  2360,  1005,  4845,  2732,  3632,\n",
      "          2125,  1996, 15168,  1010,  1005,  1000,  2002,  2409, 12060,  2197,\n",
      "          3204,  1012,  1000,  2021,  1045,  3046,  2200,  2524,  2025,  2000,\n",
      "          2175,  2008,  2126,  2138,  2009,  2052,  2022,  2205,  3733,  2005,\n",
      "          2068,  1012,  1000,  2010,  6745, 26256,  2004,  1996,  2879, 10276,\n",
      "          1999,  1000,  4302, 10693,  1998,  1996,  2344,  1997,  1996,  6708,\n",
      "          1000,  2003,  4911,  2636,  2006,  2119,  3903,  1997,  1996,  4448,\n",
      "          1998,  2002,  2097, 16851,  1996,  2535,  1999,  1996,  2197,  2048,\n",
      "          3152,  1012,  3422,  1045,  1011,  6398,  2507,  2014,  3319,  1997,\n",
      "         10693,  1005,  1055,  6745,  1090,  1012,  2045,  2003,  2166,  3458,\n",
      "         10693,  1010,  2174,  1012,  1996,  2414,  2121,  2038,  6361,  1037,\n",
      "          2694,  3185,  2170,  1000,  2026,  2879,  2990,  1010,  1000,  2055,\n",
      "          3166, 18254,  4232, 11382, 14353,  1998,  2010,  2365,  1010,  2349,\n",
      "          2005,  2713,  2101,  2023,  2095,  1012,  2002,  2097,  2036,  3711,\n",
      "          1999,  1000,  2285,  3337,  1010,  1000,  2019,  2827,  2143,  2055,\n",
      "          2176,  3337,  2040,  4019,  2019, 18504,  1012,  3041,  2023,  2095,\n",
      "          1010,  2002,  2081,  2010,  2754,  2834,  2652,  1037, 12364, 10563,\n",
      "          1999,  2848, 21146, 12494,  1005,  1055,  1000,  1041, 28940,  2271,\n",
      "          1012,  1000,  5564,  1010,  2002,  2003, 15515,  2005,  2130,  3553,\n",
      "          2865, 17423,  2085,  2008,  2002,  1005,  1055, 10142,  2019,  4639,\n",
      "          1024,  1000,  1045,  2074,  2228,  1045,  1005,  1049,  2183,  2000,\n",
      "          2022,  2062,  4066,  1997,  4189,  2208,  1010,  1000,  2002,  2409,\n",
      "         26665,  1012,  1041,  1011,  5653,  2000,  1037,  2767,  1012,  9385,\n",
      "          2289, 26665,  1012,  2035,  2916,  9235,  1012,  2023,  3430,  2089,\n",
      "          2025,  2022,  2405,  1010,  3743,  1010,  2128, 15773,  1010,  2030,\n",
      "          2417,  2923,  3089,  8569,  3064,  1012,   102]])\n",
      "torch.Size([1, 587])\n",
      "torch.Size([587])\n"
     ]
    }
   ],
   "source": [
    "#check tokens\n",
    "#max_length = 512 for BERT tokenizer\n",
    "\n",
    "sample_input = np.array(data[0]['article'])\n",
    "tokenizer_output = tokenizer(text = sample_input.tolist(), return_tensors = 'pt')\n",
    "tokens = tokenizer_output['input_ids']\n",
    "\n",
    "print(tokens)\n",
    "print(tokens.size())\n",
    "print(tokens[0].size())\n",
    "# print(len(tokens[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e48a4",
   "metadata": {},
   "source": [
    "filtering function for data filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "590de7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_data(text):\n",
    "    #remove last line\n",
    "    text = re.sub(r\"Copyright \\d{4} Reuters. All rights reserved.*\", \"\", text)\n",
    "    \n",
    "    #replace \\'\n",
    "    text = text.replace(\"\\'\", \"\")\n",
    "    \n",
    "    #replace 's\n",
    "    text = re.sub(r\"'s\\b'\", \"\", text)\n",
    "    \n",
    "    #remove extra white space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9e2ac3",
   "metadata": {},
   "source": [
    "check out the filtered data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02c04551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money wont cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I dont plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I dont think Ill be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how hell mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"Ill definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffes earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say kid star goes off the rails,\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films. Watch I-Reporter give her review of Potters latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffers \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that hes legally an adult: \"I just think Im going to be more sort of fair game,\" he told Reuters. E-mail to a friend .\n"
     ]
    }
   ],
   "source": [
    "filter_text = filter_data(data[0]['article'])\n",
    "print(filter_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa6066",
   "metadata": {},
   "source": [
    "check out the effect on tokens after data filter processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9fe9256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2414,  1010,  2563,  1006, 26665,  1007,  1011,  1011,  4302,\n",
      "         10693,  2732,  3817, 22603, 12154,  3229,  2000,  1037,  2988, 21853,\n",
      "          2692,  2454,  1006,  1002,  4601,  1012,  1015,  2454,  1007,  7280,\n",
      "          2004,  2002,  4332,  2324,  2006,  6928,  1010,  2021,  2002, 16818,\n",
      "          1996,  2769,  2180,  2102,  3459,  1037,  6297,  2006,  2032,  1012,\n",
      "          3817, 22603,  2004,  4302, 10693,  1999,  1000,  4302, 10693,  1998,\n",
      "          1996,  2344,  1997,  1996,  6708,  1000,  2000,  1996, 10520,  1997,\n",
      "         13761, 13317,  2015,  2105,  1996,  2088,  1010,  1996,  2402,  3364,\n",
      "          2758,  2002,  2038,  2053,  3488,  2000, 10424, 27100,  2099,  2010,\n",
      "          5356,  2185,  2006,  3435,  3765,  1010,  4392,  1998,  8958,  4243,\n",
      "          1012,  1000,  1045,  2123,  2102,  2933,  2000,  2022,  2028,  1997,\n",
      "          2216,  2111,  2040,  1010,  2004,  2574,  2004,  2027,  2735,  2324,\n",
      "          1010,  3402,  4965,  3209,  1037,  5294,  2998,  2482,  3074,  2030,\n",
      "          2242,  2714,  1010,  1000,  2002,  2409,  2019,  2827,  4357,  2121,\n",
      "          3041,  2023,  3204,  1012,  1000,  1045,  2123,  2102,  2228,  5665,\n",
      "          2022,  3391, 27856,  1012,  1000,  1996,  2477,  1045,  2066,  9343,\n",
      "          2024,  2477,  2008,  3465,  2055,  2184,  7038,  1011,  1011,  2808,\n",
      "          1998, 14340,  1998, 22477,  1012,  1000,  2012,  2324,  1010, 22603,\n",
      "          2097,  2022,  2583,  2000, 18503,  1999,  1037,  9270,  1010,  4965,\n",
      "          1037,  4392,  1999,  1037,  9047,  2030,  2156,  1996,  5469,  2143,\n",
      "          1000, 21071,  1024,  2112,  2462,  1010,  1000,  2747,  2416,  3182,\n",
      "          2917,  2010,  2193,  2028,  3185,  2006,  1996,  2866,  3482,  2436,\n",
      "          3673,  1012,  4751,  1997,  2129,  3109,  2928,  2010,  8637,  5798,\n",
      "          2024,  2104, 19735,  1012,  2010,  4005,  1998,  2270,  2923,  2018,\n",
      "          2053,  7615,  2006,  2010,  3488,  1012,  1000,  5665,  5791,  2031,\n",
      "          2070,  4066,  1997,  2283,  1010,  1000,  2002,  2056,  1999,  2019,\n",
      "          4357,  1012,  1000, 11504,  3904,  1997,  2017,  2097,  2022,  3752,\n",
      "          2055,  2009,  1012,  1000, 22603,  2015, 16565,  2013,  1996,  2034,\n",
      "          2274, 10693,  3152,  2031,  2042,  2218,  1999,  1037,  3404,  4636,\n",
      "          2029,  2002,  2038,  2025,  2042,  2583,  2000,  3543,  1012,  2750,\n",
      "          2010,  3652,  4476,  1998, 26768,  1010,  1996,  3364,  2758,  2002,\n",
      "          2003,  4363,  2010,  2519,  7933,  2006,  1996,  2598,  1012,  1000,\n",
      "          2111,  2024,  2467,  2559,  2000,  2360,  4845,  2732,  3632,  2125,\n",
      "          1996, 15168,  1010,  1000,  2002,  2409, 12060,  2197,  3204,  1012,\n",
      "          1000,  2021,  1045,  3046,  2200,  2524,  2025,  2000,  2175,  2008,\n",
      "          2126,  2138,  2009,  2052,  2022,  2205,  3733,  2005,  2068,  1012,\n",
      "          1000,  2010,  6745, 26256,  2004,  1996,  2879, 10276,  1999,  1000,\n",
      "          4302, 10693,  1998,  1996,  2344,  1997,  1996,  6708,  1000,  2003,\n",
      "          4911,  2636,  2006,  2119,  3903,  1997,  1996,  4448,  1998,  2002,\n",
      "          2097, 16851,  1996,  2535,  1999,  1996,  2197,  2048,  3152,  1012,\n",
      "          3422,  1045,  1011,  6398,  2507,  2014,  3319,  1997, 10693,  2015,\n",
      "          6745,  1090,  1012,  2045,  2003,  2166,  3458, 10693,  1010,  2174,\n",
      "          1012,  1996,  2414,  2121,  2038,  6361,  1037,  2694,  3185,  2170,\n",
      "          1000,  2026,  2879,  2990,  1010,  1000,  2055,  3166, 18254,  4232,\n",
      "         11382, 14353,  1998,  2010,  2365,  1010,  2349,  2005,  2713,  2101,\n",
      "          2023,  2095,  1012,  2002,  2097,  2036,  3711,  1999,  1000,  2285,\n",
      "          3337,  1010,  1000,  2019,  2827,  2143,  2055,  2176,  3337,  2040,\n",
      "          4019,  2019, 18504,  1012,  3041,  2023,  2095,  1010,  2002,  2081,\n",
      "          2010,  2754,  2834,  2652,  1037, 12364, 10563,  1999,  2848, 21146,\n",
      "         12494,  2015,  1000,  1041, 28940,  2271,  1012,  1000,  5564,  1010,\n",
      "          2002,  2003, 15515,  2005,  2130,  3553,  2865, 17423,  2085,  2008,\n",
      "          2002,  2015, 10142,  2019,  4639,  1024,  1000,  1045,  2074,  2228,\n",
      "         10047,  2183,  2000,  2022,  2062,  4066,  1997,  4189,  2208,  1010,\n",
      "          1000,  2002,  2409, 26665,  1012,  1041,  1011,  5653,  2000,  1037,\n",
      "          2767,  1012,   102]])\n",
      "543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_input = np.array(filter_text)\n",
    "tokenizer_output = tokenizer(text = sample_input.tolist(), return_tensors = 'pt')\n",
    "tokens = tokenizer_output['input_ids']\n",
    "\n",
    "print(tokens)\n",
    "print(len(tokens[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd4fb0",
   "metadata": {},
   "source": [
    "## process begins for data in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83dabc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287113/287113 [00:43<00:00, 6594.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "train_data = []\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    filter_d = filter_data(data[i]['article'])\n",
    "    train_data.append(filter_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cec8eb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287113"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d53835",
   "metadata": {},
   "source": [
    "### select 10000 of the trainig data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b91ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b216a8a9",
   "metadata": {},
   "source": [
    "## make a dataset for training via CreateDataset and DataLoader\n",
    "Here are the parameters that can be used for DataLoader in PyTorch:\n",
    "```python\n",
    "DataLoader(\n",
    "    dataset, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    sampler=None, \n",
    "    batch_sampler=None, \n",
    "    num_workers=0, \n",
    "    collate_fn=None, \n",
    "    pin_memory=False, \n",
    "    drop_last=False, \n",
    "    timeout=0, \n",
    "    worker_init_fn=None, \n",
    "    multiprocessing_context=None, \n",
    "    generator=None, \n",
    "    prefetch_factor=2, \n",
    "    persistent_workers=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26dbb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CreateDataset(train_data, tokenizer)\n",
    "# dataloader = DataLoader(train_data, batch_size = 8, collate_fn = data_collate)\n",
    "dataloader = DataLoader(train_data, batch_size = 8, collate_fn = data_collate) # try increasing batch_size to 32\n",
    "# a general two-step approach: create a dataset, then create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf564d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f14c0",
   "metadata": {},
   "source": [
    "## Meddle deeper in transformer architecture\n",
    "since now input is done via CreateDataset and DataLoader, now let us dig in encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b917a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aca903",
   "metadata": {},
   "source": [
    "The first to come is positional encoding, of course...that is what tokens are faced with.\n",
    "\n",
    "Note that we should now cover the phases in transformer architecture of raw input, tokenization, embedding, and positional encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a60311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        # position[i] = i\n",
    "        # div_term[j] = exp(j * (-log(10000.0)) / d_model), en mathematics...\n",
    "        #             = exp(-log(10000.0) * j / d_model)\n",
    "        #             = 10000.0^(-j/d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # note the j is even number\n",
    "        # so if j = 2k, where k is continuous number between 0 and half max_len, then position * div_term should be:\n",
    "        # i * (10000.0^(-2/d_model))^k\n",
    "        # which is easier to programme.\n",
    "        \n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "          # (max_len, 1, d_model)\n",
    "        self.register_buffer('pe', pe)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :] \n",
    "        # 1. if x is of three dimensions, then it syntactically works under command of [:x.size(0), :]\n",
    "        # 2. i guess the x is of shape (max_len, batch_size, d_model) here. I will check in the antecedent codes.\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157f5b6f",
   "metadata": {},
   "source": [
    "## the whole, complete architecture of transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b1f8b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model \n",
    "class TransformerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, ntokens, ninp, nhead, nhid, nlayers, dropout = 0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layer = TransformerEncoderLayer(ninp, nhead, nhid, dropout, batch_first = True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, nlayers)\n",
    "        self.encoder = nn.Embedding(ntokens, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntokens)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        '''\n",
    "        We generate the mask to prevent the transformer from seeing future tokens\n",
    "        Square matrix is created with elements below the diagonal = 0\n",
    "        Conver the mask to float, all zeros are replaced with -inf(indicating no access to elements) \n",
    "        and 1 with 0.0 (this operation does not changes the magnitude but influences the output)\n",
    "        '''\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)  #  a lower triangular matrix of bools with ones above the diagonal and ones below and along.\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        # e.g. mask, if sz being 5:\n",
    "        # tensor([[0., -inf, -inf, -inf, -inf],\n",
    "        #         [0., 0.,   -inf, -inf, -inf],\n",
    "        #         [0., 0.,   0.,   -inf, -inf],\n",
    "        #         [0., 0.,   0.,   0.,   -inf],\n",
    "        #         [0., 0.,   0.,   0.,   0.]])\n",
    "        return mask\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)  # initializes the weights of the self.encoder layer with random values uniformly distributed between -initrange and initrange.\n",
    "        # parameters for nn.Embeding:\n",
    "        # num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse\n",
    "\n",
    "        self.decoder.bias.data.zero_() # sets the bias term to zero.\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange) # initializes the weights of the self.decoder like self.encoder\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        \n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10ddcd",
   "metadata": {},
   "source": [
    "## check mps availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b0f3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "    ntokens = tokenizer.vocab_size # 30522\n",
    "    emsize = 512 # embedding dimension\n",
    "\n",
    "    nhid = 100 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "\n",
    "    nlayers = 5 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "\n",
    "    nhead = 4 # the number of heads in the multiheadattention models\n",
    "\n",
    "    dropout = 0.2 # the dropout value\n",
    "\n",
    "    model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(mps_device)  # the model architecture is sent to mps. For the 1st time in the session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b259f",
   "metadata": {},
   "source": [
    "## confirm model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9534035d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-4): 5 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=100, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=100, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Embedding(30522, 512)\n",
       "  (decoder): Linear(in_features=512, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "897a6f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('pos_encoder',\n",
       "               PositionalEncoding(\n",
       "                 (dropout): Dropout(p=0.2, inplace=False)\n",
       "               )),\n",
       "              ('transformer_encoder',\n",
       "               TransformerEncoder(\n",
       "                 (layers): ModuleList(\n",
       "                   (0-4): 5 x TransformerEncoderLayer(\n",
       "                     (self_attn): MultiheadAttention(\n",
       "                       (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "                     )\n",
       "                     (linear1): Linear(in_features=512, out_features=100, bias=True)\n",
       "                     (dropout): Dropout(p=0.2, inplace=False)\n",
       "                     (linear2): Linear(in_features=100, out_features=512, bias=True)\n",
       "                     (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                     (dropout1): Dropout(p=0.2, inplace=False)\n",
       "                     (dropout2): Dropout(p=0.2, inplace=False)\n",
       "                   )\n",
       "                 )\n",
       "               )),\n",
       "              ('encoder', Embedding(30522, 512)),\n",
       "              ('decoder',\n",
       "               Linear(in_features=512, out_features=30522, bias=True))]),\n",
       " 'model_type': 'Transformer',\n",
       " 'ninp': 512}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e88b4e",
   "metadata": {},
   "source": [
    "## training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2f6e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader):\n",
    "    model.train()\n",
    "    # epochs = 50\n",
    "    epochs = 2 # pour savourer ce test, justement...\n",
    "    total_loss = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr = 0.1)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for batch in tqdm(dataloader):\n",
    "            optim.zero_grad()\n",
    "            input = batch['input_ids'].clone()\n",
    "            \n",
    "            src_mask = model.generate_square_subsequent_mask(batch['input_ids'].size(1)) # batch['input_ids'].size(1) represents how many tokens.\n",
    "            # this is for preventing from seeing future data.\n",
    "        \n",
    "            rand_value = torch.rand(batch.input_ids.shape)\n",
    "            rand_mask = (rand_value < 0.15) * (input != 101) * (input != 102) * (input != 0)\n",
    "            # 101: Special Token (e.g., CLS or BOS)\n",
    "                # Often used to represent the beginning of a sequence.\n",
    "                # Common in classification tasks where the token's representation is used for overall sequence classification.\n",
    "            # 102: Special Token (e.g., SEP or EOS)\n",
    "                # Typically indicates the end of a sequence.\n",
    "                # Frequently used in sentence pair classification tasks or question answering.\n",
    "            # 0: Padding Token\n",
    "                # Used to fill sequences to a fixed length.\n",
    "                # Often ignored during calculations.\n",
    "            \n",
    "            mask_idx=(rand_mask.flatten() == True).nonzero().view(-1)  # here, it is 'nonzero()' that returns indices  of the elements in the boolean tensor that are True.\n",
    "            \n",
    "            input = input.flatten()\n",
    "            input[mask_idx] = 103   # 103 is likely a special token (e.g., [MASK]) used for masked language modeling tasks. \n",
    "            # The mask_idx indices are determined by the rand_mask variable, which randomly selects 15% of the input tokens (excluding special tokens like CLS, SEP, and PAD) to be replaced with the [MASK] token.\n",
    "            input = input.view(batch['input_ids'].size())\n",
    "            \n",
    "            out = model(input.to(mps_device), src_mask.to(mps_device)) # sent to mps device, for the 2nd and  3rd time in the session, for input data and mask, respectively.\n",
    "            # the input has its masked operation, and it is a different operation form the src_masks. These are two different functions.\n",
    "            loss = criterion(out.view(-1, ntokens), batch['input_ids'].view(-1).to(mps_device)) # here for the 4th time in the session, something is sent to mps. \n",
    "            # ‘criterion' absorbs a tensor of shape (batch_size, num_classes) where num_classes is the number of classes in the classification problem, which is ntokens=30522 here.\n",
    "            # target: The true labels, which should be a tensor of shape (batch_size) containing the indices of the true classes.\n",
    "\n",
    "            total_loss += loss\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "        print(\"Epoch: {} -> loss: {}\".format(epoch+1, total_loss/(len(dataloader)*epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dba84f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [07:08<00:00,  2.92it/s]\n",
      " 50%|█████     | 1/2 [07:08<07:08, 428.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 -> loss: 37269.55078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [07:09<00:00,  2.91it/s]\n",
      "100%|██████████| 2/2 [14:18<00:00, 429.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 -> loss: 40.021324157714844\n"
     ]
    }
   ],
   "source": [
    "torch.mps.empty_cache()\n",
    "train(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9199166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 151.152MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "# Parameter objects are typically used to store model weights and biases.\n",
    "\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "# note buffers() method returns an iterator over all the Tensor objects in a model that are registered as buffers. \n",
    "# Buffers are typically used to store additional tensors that are not directly involved in the forward pass of the model.\n",
    "\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3262b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "one_mat = torch.ones(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f211bd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(one_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f89fa4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True],\n",
       "        [False,  True,  True,  True],\n",
       "        [False, False,  True,  True],\n",
       "        [False, False, False,  True]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(one_mat == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bcfa751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False],\n",
       "        [ True,  True, False, False],\n",
       "        [ True,  True,  True, False],\n",
       "        [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(one_mat == 1).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf5e6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.triu(one_mat == 1).transpose(0, 1).float()\n",
    "\n",
    "# one_mat == 1: Creates a boolean mask where all elements are True (since all elements in one_mat are 1).\n",
    "# torch.triu(...): Sets all elements below the diagonal to False, the rest being True.\n",
    "# .transpose(0, 1): Swaps the rows and columns of the resulting matrix.\n",
    "# .float(): Converts the boolean matrix to a floating-point matrix, where True becomes 1.0 and False becomes 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8e11dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.masked_fill(mat == 0, float('-inf')).masked_fill(mat == 1, float(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3575567c",
   "metadata": {},
   "source": [
    "## Optimizing GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5517c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "# Accelerator is applicable for mps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69718feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    learning_rate = 0.1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    #fp16=True, # can only be done with CUDA \n",
    "    output_dir = \"./model_output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54ee9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_data, batch_size=training_args.per_device_train_batch_size)\n",
    "\n",
    "# if training_args.gradient_checkpointing:\n",
    "    # model.gradient_checkpointing_enable()\n",
    "\n",
    "# 'TransformerModel' object has no attribute 'gradient_checkpointing_enable'\n",
    "\n",
    "# accelerator = Accelerator()\n",
    "# model, optimizer, dataloader = accelerator.prepare(model, adam_bnb_optim, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc8bc60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformer_encoder.layers.0.self_attn.out_proj.weight', 'transformer_encoder.layers.0.self_attn.out_proj.bias', 'transformer_encoder.layers.0.self_attn.in_proj_weight', 'transformer_encoder.layers.0.self_attn.q_proj_weight', 'transformer_encoder.layers.0.self_attn.k_proj_weight', 'transformer_encoder.layers.0.self_attn.v_proj_weight', 'transformer_encoder.layers.0.self_attn.in_proj_bias', 'transformer_encoder.layers.0.linear1.weight', 'transformer_encoder.layers.0.linear1.bias', 'transformer_encoder.layers.0.linear2.weight', 'transformer_encoder.layers.0.linear2.bias', 'transformer_encoder.layers.1.self_attn.out_proj.weight', 'transformer_encoder.layers.1.self_attn.out_proj.bias', 'transformer_encoder.layers.1.self_attn.in_proj_weight', 'transformer_encoder.layers.1.self_attn.q_proj_weight', 'transformer_encoder.layers.1.self_attn.k_proj_weight', 'transformer_encoder.layers.1.self_attn.v_proj_weight', 'transformer_encoder.layers.1.self_attn.in_proj_bias', 'transformer_encoder.layers.1.linear1.weight', 'transformer_encoder.layers.1.linear1.bias', 'transformer_encoder.layers.1.linear2.weight', 'transformer_encoder.layers.1.linear2.bias', 'transformer_encoder.layers.2.self_attn.out_proj.weight', 'transformer_encoder.layers.2.self_attn.out_proj.bias', 'transformer_encoder.layers.2.self_attn.in_proj_weight', 'transformer_encoder.layers.2.self_attn.q_proj_weight', 'transformer_encoder.layers.2.self_attn.k_proj_weight', 'transformer_encoder.layers.2.self_attn.v_proj_weight', 'transformer_encoder.layers.2.self_attn.in_proj_bias', 'transformer_encoder.layers.2.linear1.weight', 'transformer_encoder.layers.2.linear1.bias', 'transformer_encoder.layers.2.linear2.weight', 'transformer_encoder.layers.2.linear2.bias', 'transformer_encoder.layers.3.self_attn.out_proj.weight', 'transformer_encoder.layers.3.self_attn.out_proj.bias', 'transformer_encoder.layers.3.self_attn.in_proj_weight', 'transformer_encoder.layers.3.self_attn.q_proj_weight', 'transformer_encoder.layers.3.self_attn.k_proj_weight', 'transformer_encoder.layers.3.self_attn.v_proj_weight', 'transformer_encoder.layers.3.self_attn.in_proj_bias', 'transformer_encoder.layers.3.linear1.weight', 'transformer_encoder.layers.3.linear1.bias', 'transformer_encoder.layers.3.linear2.weight', 'transformer_encoder.layers.3.linear2.bias', 'transformer_encoder.layers.4.self_attn.out_proj.weight', 'transformer_encoder.layers.4.self_attn.out_proj.bias', 'transformer_encoder.layers.4.self_attn.in_proj_weight', 'transformer_encoder.layers.4.self_attn.q_proj_weight', 'transformer_encoder.layers.4.self_attn.k_proj_weight', 'transformer_encoder.layers.4.self_attn.v_proj_weight', 'transformer_encoder.layers.4.self_attn.in_proj_bias', 'transformer_encoder.layers.4.linear1.weight', 'transformer_encoder.layers.4.linear1.bias', 'transformer_encoder.layers.4.linear2.weight', 'transformer_encoder.layers.4.linear2.bias', 'encoder.weight', 'decoder.weight', 'decoder.bias']\n"
     ]
    }
   ],
   "source": [
    "from transformers.trainer_pt_utils import get_parameter_names\n",
    "\n",
    "decay_parameters = get_parameter_names(model, [nn.LayerNorm])\n",
    "#  retrieves the names of model parameters that are not inside a nn.LayerNorm layer.\n",
    "print(decay_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5fa50f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformer_encoder.layers.0.self_attn.out_proj.weight', 'transformer_encoder.layers.0.self_attn.in_proj_weight', 'transformer_encoder.layers.0.self_attn.q_proj_weight', 'transformer_encoder.layers.0.self_attn.k_proj_weight', 'transformer_encoder.layers.0.self_attn.v_proj_weight', 'transformer_encoder.layers.0.linear1.weight', 'transformer_encoder.layers.0.linear2.weight', 'transformer_encoder.layers.1.self_attn.out_proj.weight', 'transformer_encoder.layers.1.self_attn.in_proj_weight', 'transformer_encoder.layers.1.self_attn.q_proj_weight', 'transformer_encoder.layers.1.self_attn.k_proj_weight', 'transformer_encoder.layers.1.self_attn.v_proj_weight', 'transformer_encoder.layers.1.linear1.weight', 'transformer_encoder.layers.1.linear2.weight', 'transformer_encoder.layers.2.self_attn.out_proj.weight', 'transformer_encoder.layers.2.self_attn.in_proj_weight', 'transformer_encoder.layers.2.self_attn.q_proj_weight', 'transformer_encoder.layers.2.self_attn.k_proj_weight', 'transformer_encoder.layers.2.self_attn.v_proj_weight', 'transformer_encoder.layers.2.linear1.weight', 'transformer_encoder.layers.2.linear2.weight', 'transformer_encoder.layers.3.self_attn.out_proj.weight', 'transformer_encoder.layers.3.self_attn.in_proj_weight', 'transformer_encoder.layers.3.self_attn.q_proj_weight', 'transformer_encoder.layers.3.self_attn.k_proj_weight', 'transformer_encoder.layers.3.self_attn.v_proj_weight', 'transformer_encoder.layers.3.linear1.weight', 'transformer_encoder.layers.3.linear2.weight', 'transformer_encoder.layers.4.self_attn.out_proj.weight', 'transformer_encoder.layers.4.self_attn.in_proj_weight', 'transformer_encoder.layers.4.self_attn.q_proj_weight', 'transformer_encoder.layers.4.self_attn.k_proj_weight', 'transformer_encoder.layers.4.self_attn.v_proj_weight', 'transformer_encoder.layers.4.linear1.weight', 'transformer_encoder.layers.4.linear2.weight', 'encoder.weight', 'decoder.weight']\n"
     ]
    }
   ],
   "source": [
    "decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n",
    "print(decay_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8867af66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[-0.0128,  0.0444, -0.0700,  ...,  0.0691, -0.0440,  0.0548],\n",
       "           [-0.0557, -0.0509,  0.0462,  ...,  0.0512,  0.0477, -0.0594],\n",
       "           [-0.0413,  0.0370,  0.0520,  ...,  0.0455,  0.0476,  0.0474],\n",
       "           ...,\n",
       "           [-0.0499, -0.0471,  0.0474,  ..., -0.0495,  0.0472, -0.0471],\n",
       "           [ 0.0543,  0.0565, -0.0513,  ...,  0.0522,  0.0468,  0.0463],\n",
       "           [ 0.0515,  0.0479,  0.0527,  ...,  0.0486, -0.0528,  0.0459]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0525, -0.0461, -0.0537,  ...,  0.0451,  0.0537, -0.0438],\n",
       "           [ 0.0517, -0.0534, -0.0465,  ...,  0.0482,  0.0485, -0.0476],\n",
       "           [-0.0443,  0.0579, -0.0519,  ..., -0.0499, -0.0476, -0.0414],\n",
       "           ...,\n",
       "           [-0.0440,  0.0638,  0.0323,  ..., -0.0513, -0.0491,  0.0506],\n",
       "           [ 0.0514, -0.0455, -0.0518,  ...,  0.0486,  0.0501, -0.0533],\n",
       "           [-0.0407, -0.0493, -0.0617,  ...,  0.0506,  0.0527, -0.0485]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0529,  0.0496, -0.0493,  ..., -0.0508,  0.0498,  0.0493],\n",
       "           [ 0.0508, -0.0447,  0.0447,  ...,  0.0120,  0.0515, -0.0331],\n",
       "           [-0.0490,  0.0517,  0.0485,  ..., -0.0454,  0.0439,  0.0485],\n",
       "           ...,\n",
       "           [-0.0431,  0.0524, -0.0441,  ...,  0.0460,  0.0492, -0.0521],\n",
       "           [ 0.0519,  0.0518, -0.0519,  ...,  0.0480, -0.0536, -0.0505],\n",
       "           [ 0.0499,  0.0483,  0.0543,  ...,  0.0520,  0.0554, -0.0468]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0406, -0.0453, -0.0416,  ..., -0.0463, -0.0477, -0.0529],\n",
       "           [-0.0423, -0.0405, -0.0450,  ..., -0.0570, -0.0491, -0.0486],\n",
       "           [-0.0126, -0.0455,  0.0729,  ...,  0.0756, -0.0458,  0.0424],\n",
       "           ...,\n",
       "           [ 0.0445,  0.0398,  0.0588,  ...,  0.0549,  0.0719,  0.0522],\n",
       "           [-0.0509, -0.0444, -0.0417,  ..., -0.0462, -0.0507, -0.0511],\n",
       "           [-0.0466,  0.0511, -0.0500,  ..., -0.0654, -0.0563, -0.0520]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0045,  0.0711,  0.0681,  ...,  0.0078,  0.0561,  0.0606],\n",
       "           [-0.0312,  0.0688,  0.0659,  ...,  0.0589, -0.0401,  0.0542],\n",
       "           [-0.0728, -0.0087, -0.0248,  ...,  0.0662, -0.0586,  0.0054],\n",
       "           ...,\n",
       "           [ 0.0479, -0.0498,  0.0473,  ..., -0.0472,  0.0468, -0.0494],\n",
       "           [ 0.0459,  0.0476, -0.0501,  ...,  0.0526, -0.0508,  0.0428],\n",
       "           [ 0.0475,  0.0454,  0.0514,  ...,  0.0520, -0.0594,  0.0289]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0545,  0.0521, -0.0550,  ...,  0.0397,  0.0537,  0.0537],\n",
       "           [ 0.0549,  0.0498, -0.0487,  ...,  0.0324,  0.0506,  0.0548],\n",
       "           [ 0.0616,  0.0561, -0.0520,  ..., -0.0574,  0.0498,  0.0505],\n",
       "           ...,\n",
       "           [-0.0473, -0.0509,  0.0535,  ..., -0.0480, -0.0521, -0.0521],\n",
       "           [ 0.0504,  0.0519, -0.0508,  ...,  0.0457,  0.0513,  0.0472],\n",
       "           [ 0.0111, -0.0350, -0.0608,  ...,  0.0232,  0.0556,  0.0538]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0588, -0.0697, -0.0634,  ...,  0.0288,  0.0126,  0.0435],\n",
       "           [ 0.0506, -0.0514,  0.0455,  ...,  0.0568,  0.0552, -0.0451],\n",
       "           [-0.0508,  0.0518, -0.0320,  ..., -0.0475, -0.0412,  0.0505],\n",
       "           ...,\n",
       "           [-0.0665,  0.0448,  0.0460,  ...,  0.0530,  0.0447, -0.0567],\n",
       "           [ 0.0407,  0.0472, -0.0549,  ...,  0.0491, -0.0526, -0.0460],\n",
       "           [ 0.0496, -0.0487,  0.0518,  ...,  0.0517, -0.0047, -0.0492]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0523, -0.0532, -0.0443,  ..., -0.0503, -0.0536, -0.0543],\n",
       "           [-0.0589, -0.0384, -0.0441,  ..., -0.0564, -0.0561, -0.0453],\n",
       "           [-0.0052, -0.0711, -0.0405,  ..., -0.0571, -0.0476, -0.0602],\n",
       "           ...,\n",
       "           [ 0.0427,  0.0503,  0.0570,  ...,  0.0636, -0.0584,  0.0629],\n",
       "           [ 0.0591, -0.0431, -0.0416,  ..., -0.0227, -0.0511, -0.0506],\n",
       "           [-0.0466,  0.0761, -0.0450,  ..., -0.0502, -0.0506,  0.0652]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0368,  0.0637,  0.0666,  ..., -0.0659,  0.0700,  0.0695],\n",
       "           [-0.0309,  0.0652,  0.0645,  ...,  0.0141, -0.0130,  0.0672],\n",
       "           [-0.0639, -0.0283, -0.0097,  ...,  0.0272, -0.0390, -0.0271],\n",
       "           ...,\n",
       "           [ 0.0266, -0.0590, -0.0647,  ..., -0.0236,  0.0073, -0.0493],\n",
       "           [ 0.0040,  0.0590,  0.0639,  ...,  0.0353, -0.0029,  0.0500],\n",
       "           [ 0.0683,  0.0633,  0.0590,  ..., -0.0319,  0.0577,  0.0582]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0264,  0.0027, -0.0386,  ..., -0.0205,  0.0406,  0.0393],\n",
       "           [ 0.0625,  0.0617, -0.0516,  ..., -0.0578,  0.0512,  0.0559],\n",
       "           [ 0.0306, -0.0155, -0.0425,  ..., -0.0306,  0.0406,  0.0484],\n",
       "           ...,\n",
       "           [-0.0105,  0.0267,  0.0243,  ..., -0.0120, -0.0395, -0.0337],\n",
       "           [ 0.0527,  0.0829, -0.0523,  ..., -0.0495,  0.0497,  0.0458],\n",
       "           [-0.0372, -0.0085,  0.0352,  ...,  0.0514, -0.0817, -0.0926]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.6033, -0.5249, -0.5891,  ...,  0.4802, -0.4836,  0.5799],\n",
       "           [ 0.0486,  0.0410,  0.0349,  ..., -0.0362,  0.0556, -0.0480],\n",
       "           [ 0.0337, -0.2288, -0.6113,  ...,  0.2016, -0.4900,  0.2983],\n",
       "           ...,\n",
       "           [ 0.0726,  0.0697,  0.0617,  ..., -0.0651,  0.0567, -0.0606],\n",
       "           [ 0.5167, -0.3448, -0.4858,  ...,  0.1085, -0.1240,  0.5664],\n",
       "           [ 0.0490,  0.0574,  0.0566,  ...,  0.0560, -0.0545, -0.0525]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.5952, -0.0489, -0.3786,  ..., -0.0666,  0.0116, -0.0549],\n",
       "           [-0.6832, -0.0395,  0.1254,  ..., -0.0356, -0.4430, -0.0415],\n",
       "           [ 0.5267, -0.0526, -0.5300,  ..., -0.0627,  0.0419, -0.0556],\n",
       "           ...,\n",
       "           [ 0.6066,  0.0394, -0.5287,  ...,  0.0590, -0.3553,  0.0531],\n",
       "           [ 0.5509, -0.0472, -0.2817,  ...,  0.0138, -0.0263, -0.0507],\n",
       "           [-0.5952,  0.0607,  0.6561,  ..., -0.0040, -0.1145,  0.0492]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0327,  0.0095, -0.0282,  ..., -0.0217, -0.0272,  0.0578],\n",
       "           [-0.0543,  0.1118,  0.0372,  ...,  0.0423, -0.0630,  0.0369],\n",
       "           [-0.0168,  0.0161,  0.1685,  ..., -0.0206,  0.0337, -0.0168],\n",
       "           ...,\n",
       "           [-0.0394, -0.0524, -0.0285,  ...,  0.0543,  0.0245, -0.0194],\n",
       "           [ 0.0175,  0.0049,  0.0286,  ...,  0.0085, -0.0275,  0.0220],\n",
       "           [ 0.0823,  0.0617,  0.0400,  ..., -0.1251,  0.0025, -0.0735]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0575, -0.0062, -0.0574,  ..., -0.0647,  0.0571,  0.0692],\n",
       "           [ 0.1202,  0.0209, -0.0602,  ..., -0.0934,  0.0775,  0.0973],\n",
       "           [-0.0706, -0.0829, -0.0407,  ..., -0.0199,  0.0289,  0.0158],\n",
       "           ...,\n",
       "           [ 0.0335,  0.0552, -0.0257,  ..., -0.0526,  0.0237, -0.0328],\n",
       "           [ 0.0642, -0.0142, -0.0584,  ..., -0.0567,  0.0589,  0.0212],\n",
       "           [ 0.0446,  0.0581,  0.0216,  ...,  0.0305,  0.0100, -0.1326]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0502,  0.0413, -0.0078,  ..., -0.0545,  0.0684, -0.0405],\n",
       "           [ 0.0469,  0.0532, -0.0523,  ...,  0.0096,  0.0338, -0.0495],\n",
       "           [-0.0286,  0.0694,  0.0187,  ..., -0.0545,  0.0090,  0.0282],\n",
       "           ...,\n",
       "           [-0.0440,  0.0534,  0.0524,  ..., -0.0539,  0.0500,  0.0460],\n",
       "           [ 0.4239,  0.5444,  0.3717,  ..., -0.1525,  0.1168, -0.4829],\n",
       "           [-0.0163,  0.1530, -0.2800,  ...,  0.3824,  0.1192,  0.4036]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0513, -0.0456, -0.0762,  ..., -0.0496,  0.4875,  0.2430],\n",
       "           [ 0.0620,  0.0537, -0.0307,  ...,  0.0473, -0.1039,  0.1745],\n",
       "           [-0.0340, -0.0251,  0.0045,  ..., -0.0448,  0.2204,  0.5614],\n",
       "           ...,\n",
       "           [ 0.0512,  0.0545, -0.0056,  ...,  0.0482, -0.0617, -0.0053],\n",
       "           [ 0.0552, -0.0095, -0.0524,  ...,  0.0545,  0.1767,  0.1070],\n",
       "           [ 0.0828,  0.0152,  0.0660,  ..., -0.0505,  0.2764,  0.3274]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.4993,  0.5529, -0.5384,  ..., -0.2552, -0.4049, -0.5990],\n",
       "           [ 0.2966,  0.6413, -0.6453,  ..., -0.2840, -0.3512, -0.5624],\n",
       "           [ 0.3280,  0.3424, -0.2544,  ..., -0.0821, -0.2919, -0.0965],\n",
       "           ...,\n",
       "           [-0.0310, -0.1200,  0.2100,  ..., -0.0283,  0.0770,  0.1233],\n",
       "           [-0.0302,  0.1437, -0.2933,  ...,  0.1200, -0.1436, -0.0864],\n",
       "           [ 0.0195,  0.0902, -0.1740,  ...,  0.0370, -0.0788, -0.0992]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.2714,  0.2371,  0.0933,  ...,  0.1145, -0.1880, -0.1776],\n",
       "           [ 0.3883,  0.0053, -0.3074,  ...,  0.1291, -0.0206, -0.0233],\n",
       "           [ 0.3974, -0.7533, -0.1496,  ..., -0.6219,  0.6526,  0.6860],\n",
       "           ...,\n",
       "           [ 0.4673, -0.3940, -0.3327,  ..., -0.3020,  0.4946,  0.3410],\n",
       "           [-0.0806, -0.0408,  0.0395,  ..., -0.0532,  0.0445,  0.0431],\n",
       "           [-0.2455,  0.0269,  0.1932,  ..., -0.0413, -0.0378, -0.0086]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.4719, -0.4640, -0.1619,  ..., -0.7217, -0.0418,  0.3890],\n",
       "           [-0.7275, -0.5533, -0.2340,  ..., -0.9144, -0.0790,  0.6111],\n",
       "           [ 0.3960,  0.4622,  0.3425,  ...,  0.4361,  0.1102, -0.3153],\n",
       "           ...,\n",
       "           [ 1.1293,  1.2611,  1.1453,  ...,  0.9661,  0.8781, -1.2328],\n",
       "           [-0.1875, -0.1891,  0.0151,  ..., -0.0656, -0.0103,  0.2376],\n",
       "           [ 1.1126,  1.1061,  0.9612,  ...,  0.9151,  0.3785, -1.0264]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.5237,  0.7576,  0.0912,  ..., -0.0569, -0.6348, -0.1633],\n",
       "           [-0.6545, -0.5070,  0.0345,  ...,  0.1028, -0.4694,  0.0976],\n",
       "           [-0.2496, -0.3565, -0.1984,  ..., -0.0715, -0.5455, -0.0882],\n",
       "           ...,\n",
       "           [-0.0494, -0.1120,  4.3058,  ...,  5.2049,  0.6252,  5.2837],\n",
       "           [-1.3342, -1.4045, -1.4400,  ..., -2.1520, -0.6186, -2.2337],\n",
       "           [-0.2620, -0.6186, -0.0882,  ..., -0.1377,  0.5461, -0.0939]],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-5.6716e-02, -4.9218e-02, -5.1378e-02,  ...,  5.1425e-02,\n",
       "             5.4299e-02, -5.2375e-02],\n",
       "           [-5.0063e-03, -2.4728e-03,  1.7418e-03,  ..., -6.2306e-03,\n",
       "             4.7920e-03, -7.7233e-03],\n",
       "           [ 1.9330e-04, -7.3864e-03,  5.3280e-03,  ..., -5.1543e-03,\n",
       "             5.4882e-03, -1.2261e-03],\n",
       "           ...,\n",
       "           [ 4.9781e-03,  4.4525e-03,  1.8188e-03,  ..., -2.3010e-03,\n",
       "            -3.5136e-03,  5.5860e-03],\n",
       "           [-2.2087e-05, -4.4139e-03,  1.8779e-04,  ...,  5.5314e-03,\n",
       "            -7.3215e-03,  3.4944e-04],\n",
       "           [-6.5436e-03, -4.8372e-03,  4.7158e-03,  ...,  6.1361e-03,\n",
       "             1.9685e-03,  7.9965e-04]], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.6810, -2.4809, -0.5579,  ...,  0.3350,  0.7222,  0.1763],\n",
       "           [ 0.2068,  1.3078,  0.0203,  ..., -0.0033,  0.1888, -0.0783],\n",
       "           [ 0.1407,  1.3225,  0.0283,  ..., -0.0193,  0.0910, -0.0740],\n",
       "           ...,\n",
       "           [ 0.1218,  0.7742, -0.0102,  ..., -0.0213,  0.5269, -0.0672],\n",
       "           [ 0.1334,  1.3530,  0.0221,  ..., -0.0175,  0.0651, -0.0821],\n",
       "           [ 0.1142,  1.3256,  0.0305,  ..., -0.0152,  0.1972, -0.0797]],\n",
       "          device='mps:0', requires_grad=True)],\n",
       "  'weight_decay': 0.0},\n",
       " {'params': [Parameter containing:\n",
       "   tensor([ 0.0357, -0.0519,  0.0512,  ..., -0.0497,  0.0496,  0.0497],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0497, -0.0497,  0.0498,  0.0497,  0.0497,  0.0497, -0.0497, -0.0497,\n",
       "            0.0496, -0.0497,  0.0481,  0.0496,  0.0497,  0.0497,  0.0497,  0.0496,\n",
       "           -0.0497, -0.0496, -0.0497, -0.0499, -0.0498,  0.0497,  0.0497, -0.0497,\n",
       "            0.0497,  0.0497,  0.0497,  0.0497, -0.0497, -0.0498,  0.0498, -0.0497,\n",
       "            0.0497, -0.0498,  0.0496,  0.0497,  0.0497,  0.0497, -0.0497, -0.0498,\n",
       "           -0.0497,  0.0498, -0.0497,  0.0497, -0.0497, -0.0497,  0.0497, -0.0497,\n",
       "           -0.0497, -0.0497, -0.0497, -0.0497,  0.0497, -0.0497, -0.0497,  0.0497,\n",
       "            0.0497, -0.0497, -0.0497,  0.0497,  0.0497,  0.0496,  0.0497,  0.0497,\n",
       "            0.0500, -0.0497,  0.0497, -0.0497,  0.0497,  0.0497,  0.0497, -0.0497,\n",
       "            0.0497,  0.0497, -0.0497, -0.0497, -0.0497,  0.0497, -0.0497, -0.0497,\n",
       "           -0.0496, -0.0497, -0.0497, -0.0497, -0.0496,  0.0497,  0.0497, -0.0497,\n",
       "           -0.0497,  0.0497,  0.0497, -0.0497,  0.0497, -0.0497, -0.0496,  0.0497,\n",
       "           -0.0497,  0.0497, -0.0498,  0.0503,  0.0495,  0.0497,  0.0498,  0.0498,\n",
       "            0.0498,  0.0497, -0.0497,  0.0497,  0.0497,  0.0497, -0.0509,  0.0497,\n",
       "            0.0497, -0.0497,  0.0497,  0.0497,  0.0497, -0.0495, -0.0497, -0.0497,\n",
       "           -0.0497,  0.0497, -0.0497, -0.0497, -0.0497, -0.0498,  0.0497, -0.0497,\n",
       "            0.0496, -0.0497,  0.0497, -0.0497, -0.0497, -0.0497,  0.0497, -0.0497,\n",
       "            0.0499,  0.0496,  0.0497, -0.0496,  0.0496,  0.0497,  0.0496,  0.0479,\n",
       "           -0.0497, -0.0497,  0.0497, -0.0497, -0.0497, -0.0497, -0.0497,  0.0497,\n",
       "            0.0497,  0.0498,  0.0498,  0.0499, -0.0497,  0.0497, -0.0497, -0.0497,\n",
       "            0.0497, -0.0497,  0.0498, -0.0497, -0.0497, -0.0497,  0.0496,  0.0497,\n",
       "           -0.0498, -0.0497, -0.0497, -0.0496, -0.0497,  0.0497, -0.0497, -0.0497,\n",
       "           -0.0497,  0.0497,  0.0497,  0.0497, -0.0497, -0.0497,  0.0497, -0.0497,\n",
       "           -0.0497,  0.0497,  0.0497,  0.0497, -0.0496, -0.0500, -0.0497, -0.0497,\n",
       "           -0.0497,  0.0497,  0.0497,  0.0497, -0.0498,  0.0497,  0.0498,  0.0497,\n",
       "           -0.0498,  0.0497, -0.0467,  0.0497,  0.0497,  0.0497,  0.0497, -0.0497,\n",
       "            0.0498,  0.0509,  0.0497, -0.0495, -0.0492,  0.0497,  0.0497,  0.0497,\n",
       "            0.0496,  0.0497, -0.0497,  0.0497,  0.0497, -0.0497, -0.0497, -0.0496,\n",
       "            0.0497, -0.0501, -0.0497,  0.0497,  0.0497, -0.0497,  0.0497, -0.0497,\n",
       "           -0.0497,  0.0497,  0.0497,  0.0497, -0.0497, -0.0497,  0.0497, -0.0497,\n",
       "            0.0497, -0.0497,  0.0497,  0.0497,  0.0497, -0.0496, -0.0496, -0.0497,\n",
       "           -0.0497,  0.0497,  0.0497, -0.0497, -0.0497, -0.0497,  0.0497,  0.0497,\n",
       "            0.0497, -0.0497,  0.0497,  0.0497,  0.0496, -0.0497, -0.0497, -0.0497,\n",
       "           -0.0497, -0.0497, -0.0497, -0.0497,  0.0497,  0.0498,  0.0497,  0.0493,\n",
       "           -0.0494, -0.0497,  0.0496,  0.0497,  0.0497, -0.0497,  0.0497, -0.0497,\n",
       "            0.0497,  0.0492,  0.0497, -0.0497, -0.0497,  0.0497, -0.0497,  0.0496,\n",
       "           -0.0496, -0.0497, -0.0497, -0.0497,  0.0497,  0.0497,  0.0497,  0.0497,\n",
       "            0.0497,  0.0496, -0.0497,  0.0497, -0.0497, -0.0497,  0.0497, -0.0497,\n",
       "           -0.0497, -0.0495, -0.0497, -0.0497, -0.0497, -0.0497, -0.0497,  0.0497,\n",
       "           -0.0498, -0.0497, -0.0497, -0.0497,  0.0497, -0.0497, -0.0497,  0.0497,\n",
       "            0.0498, -0.0497, -0.0498, -0.0496, -0.0497,  0.0497, -0.0497,  0.0497,\n",
       "            0.0497, -0.0497, -0.0497,  0.0497, -0.0497, -0.0497, -0.0497, -0.0497,\n",
       "            0.0497,  0.0497, -0.0496,  0.0497,  0.0497, -0.0496,  0.0497,  0.0493,\n",
       "            0.0500,  0.0498,  0.0497,  0.0497, -0.0503,  0.0496, -0.0497,  0.0496,\n",
       "           -0.0497,  0.0497,  0.0497,  0.0497, -0.0497, -0.0497, -0.0497, -0.0497,\n",
       "           -0.0497, -0.0497, -0.0497, -0.0497,  0.0497, -0.0497, -0.0497, -0.0498,\n",
       "            0.0497, -0.0498, -0.0497,  0.0497, -0.0497, -0.0496,  0.0497, -0.0496,\n",
       "           -0.0497,  0.0497, -0.0497,  0.0497,  0.0497,  0.0497,  0.0497, -0.0498,\n",
       "           -0.0497, -0.0496, -0.0497,  0.0498, -0.0497,  0.0497, -0.0497, -0.0497,\n",
       "           -0.0497, -0.0497, -0.0497, -0.0497, -0.0497, -0.0497,  0.0497,  0.0497,\n",
       "           -0.0497,  0.0496,  0.0496,  0.0497, -0.0497,  0.0498, -0.0497, -0.0497,\n",
       "            0.0497,  0.0499,  0.0496,  0.0496, -0.0498,  0.0500,  0.0497,  0.0497,\n",
       "           -0.0497, -0.0497, -0.0497, -0.0497, -0.0497, -0.0497,  0.0497,  0.0497,\n",
       "           -0.0497, -0.0498,  0.0497,  0.0497,  0.0497,  0.0497,  0.0497, -0.0497,\n",
       "           -0.0497,  0.0499, -0.0497,  0.0497,  0.0496, -0.0496, -0.0497,  0.0497,\n",
       "            0.0497, -0.0497,  0.0496, -0.0497,  0.0496, -0.0497,  0.0497,  0.0497,\n",
       "           -0.0497, -0.0496, -0.0497,  0.0497,  0.0497, -0.0497,  0.0497,  0.0497,\n",
       "            0.0497, -0.0497,  0.0497,  0.0497,  0.0497, -0.0497,  0.0497,  0.0497,\n",
       "            0.0497, -0.0497,  0.0497,  0.0497, -0.0497,  0.0516, -0.0497, -0.0497,\n",
       "            0.0497, -0.0496, -0.0497,  0.0497, -0.0497,  0.0497,  0.0500,  0.0493,\n",
       "           -0.0498, -0.0497, -0.0496,  0.0497,  0.0496, -0.0497,  0.0497, -0.0497,\n",
       "           -0.0497,  0.0497, -0.0495,  0.0497, -0.0499,  0.0497, -0.0495, -0.0497,\n",
       "           -0.0497,  0.0497,  0.0497, -0.0496, -0.0497,  0.0497,  0.0496,  0.0497,\n",
       "           -0.0497,  0.0497,  0.0496, -0.0497, -0.0497,  0.0497, -0.0497, -0.0497],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0505, -0.0498,  0.0550, -0.0497, -0.0523,  0.0491,  0.0529, -0.0530,\n",
       "            0.0532,  0.0456,  0.0560,  0.0396, -0.0494, -0.0466,  0.0471, -0.0500,\n",
       "            0.0522,  0.0458,  0.0482, -0.0462,  0.0437,  0.0512,  0.0470,  0.0472,\n",
       "           -0.0483, -0.0522, -0.0503, -0.0408,  0.0511, -0.0474,  0.0444,  0.0481,\n",
       "           -0.0460,  0.0470,  0.0471,  0.0529,  0.0468, -0.0516,  0.0481, -0.0509,\n",
       "           -0.0501,  0.0091, -0.0496, -0.0521, -0.0519,  0.0479, -0.0511, -0.0474,\n",
       "            0.0516, -0.0537, -0.0507,  0.0537, -0.0473, -0.0489,  0.0498,  0.0470,\n",
       "           -0.0539, -0.0497,  0.0468, -0.0507,  0.0541,  0.0446, -0.0468, -0.0489,\n",
       "           -0.0491,  0.0481, -0.0471,  0.0497, -0.0494,  0.0523,  0.0523,  0.0511,\n",
       "           -0.0532,  0.0408,  0.0461, -0.0506,  0.0529, -0.0473,  0.0390,  0.0482,\n",
       "           -0.0514,  0.0751, -0.0497,  0.0488,  0.0468, -0.0475, -0.0465,  0.0485,\n",
       "           -0.0530, -0.0506,  0.0508, -0.0510, -0.0551, -0.0476,  0.0469, -0.0510,\n",
       "            0.0531,  0.0542,  0.0484, -0.0454], device='mps:0',\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0524, -0.0438, -0.0424,  0.0481,  0.0527,  0.0484, -0.0492, -0.0494,\n",
       "            0.0560, -0.0435, -0.0439,  0.0511,  0.0515,  0.0553,  0.0507,  0.0511,\n",
       "           -0.0541, -0.0489, -0.0421, -0.0464, -0.0530,  0.0460,  0.0303, -0.0430,\n",
       "            0.0495,  0.0523,  0.0527,  0.0563, -0.0500, -0.0520,  0.0439, -0.0556,\n",
       "            0.0517, -0.0428,  0.0442,  0.0503,  0.0430,  0.0451, -0.0545, -0.0470,\n",
       "           -0.0541,  0.0490, -0.0533,  0.0463, -0.0463, -0.0431,  0.0462, -0.0511,\n",
       "           -0.0531, -0.0535, -0.0441, -0.0513,  0.0561, -0.0419, -0.0421,  0.0501,\n",
       "            0.0565, -0.0532, -0.0480,  0.0519,  0.0423,  0.0485,  0.0462,  0.0502,\n",
       "            0.0517, -0.0558,  0.0512, -0.0451,  0.0553,  0.0417,  0.0516, -0.0502,\n",
       "            0.0483,  0.0509, -0.0544, -0.0473, -0.0424,  0.0469, -0.0526, -0.0515,\n",
       "           -0.0444, -0.0578, -0.0470, -0.0422, -0.0446,  0.0416,  0.0429, -0.0518,\n",
       "           -0.0561,  0.0500,  0.0420, -0.0524,  0.0522, -0.0461,  0.0532,  0.0440,\n",
       "           -0.0455,  0.0529,  0.0409, -0.0630,  0.0560,  0.0475,  0.0574,  0.0521,\n",
       "            0.0483,  0.0456, -0.0532,  0.0527,  0.0535,  0.0505, -0.0529,  0.0555,\n",
       "            0.0439, -0.0379,  0.0554,  0.0549,  0.0468, -0.0410, -0.0422, -0.0432,\n",
       "           -0.0529,  0.0422, -0.0493, -0.0430, -0.0486, -0.0527,  0.0456, -0.0542,\n",
       "            0.0532, -0.0550,  0.0492, -0.0466, -0.0533, -0.0536,  0.0504, -0.0460,\n",
       "           -0.0512,  0.0407,  0.0472, -0.0571,  0.0573,  0.0434, -0.0475, -0.0569,\n",
       "           -0.0512, -0.0569,  0.0456, -0.0578, -0.0486, -0.0424, -0.0532,  0.0550,\n",
       "            0.0557,  0.0555, -0.0618,  0.0594, -0.0441,  0.0573, -0.0554, -0.0471,\n",
       "            0.0441, -0.0504,  0.0487, -0.0417, -0.0529, -0.0430,  0.0560,  0.0483,\n",
       "           -0.0473, -0.0470, -0.0498,  0.0570, -0.0552,  0.0570,  0.0553, -0.0454,\n",
       "           -0.0516,  0.0464,  0.0575,  0.0554, -0.0479, -0.0555,  0.0478, -0.0488,\n",
       "           -0.0486,  0.0458,  0.0464,  0.0502, -0.0555,  0.0464, -0.0519, -0.0425,\n",
       "           -0.0552,  0.0427,  0.0492,  0.0532, -0.0495,  0.0563,  0.0587,  0.0523,\n",
       "           -0.0511,  0.0558, -0.0443,  0.0497,  0.0578,  0.0551,  0.0491, -0.0454,\n",
       "            0.0544, -0.0530,  0.0475, -0.0465, -0.0438,  0.0497,  0.0453,  0.0529,\n",
       "            0.0482,  0.0445, -0.0500,  0.0548,  0.0528, -0.0454, -0.0577, -0.0495,\n",
       "            0.0480, -0.0531, -0.0561,  0.0566, -0.0110, -0.0449,  0.0497, -0.0476,\n",
       "           -0.0455,  0.0488,  0.0448,  0.0522, -0.0509, -0.0528,  0.0552, -0.0580,\n",
       "            0.0450, -0.0564,  0.0526,  0.0513,  0.0569, -0.0543, -0.0525, -0.0435,\n",
       "           -0.0455,  0.0455,  0.0445, -0.0433, -0.0446, -0.0513,  0.0508,  0.0567,\n",
       "            0.0506, -0.0422,  0.0565,  0.0525, -0.0434, -0.0533,  0.0553, -0.0460,\n",
       "           -0.0423, -0.0526, -0.0523, -0.0425,  0.0471,  0.0471,  0.0483,  0.0311,\n",
       "           -0.0531, -0.0566,  0.0455,  0.0546,  0.0531, -0.0495,  0.0466, -0.0506,\n",
       "            0.0487, -0.0605,  0.0513, -0.0515, -0.0558,  0.0416, -0.0536, -0.0571,\n",
       "           -0.0567, -0.0532, -0.0555, -0.0456,  0.0419,  0.0504,  0.0564,  0.0540,\n",
       "            0.0570,  0.0421, -0.0520,  0.0454, -0.0468, -0.0524,  0.0547, -0.0472,\n",
       "           -0.0452, -0.0465, -0.0443, -0.0442, -0.0492, -0.0584, -0.0526,  0.0536,\n",
       "           -0.0494, -0.0442, -0.0468, -0.0436,  0.0525, -0.0571, -0.0510,  0.0552,\n",
       "            0.0420, -0.0452, -0.0466, -0.0429, -0.0546,  0.0521, -0.0427,  0.0470,\n",
       "            0.0449, -0.0553, -0.0488,  0.0453, -0.0428, -0.0423, -0.0508, -0.0517,\n",
       "            0.0464,  0.0562, -0.0448,  0.0531,  0.0459, -0.0420,  0.0451, -0.0479,\n",
       "            0.0529,  0.0516,  0.0551,  0.0553, -0.0464, -0.0493, -0.0518,  0.0659,\n",
       "            0.0483,  0.0563,  0.0515,  0.0429, -0.0424, -0.0535, -0.0461, -0.0460,\n",
       "           -0.0449, -0.0533, -0.0540, -0.0569,  0.0426, -0.0426, -0.0517, -0.0525,\n",
       "            0.0475, -0.0509, -0.0482,  0.0430, -0.0577, -0.0504,  0.0433, -0.0523,\n",
       "           -0.0494,  0.0433, -0.0511,  0.0559,  0.0429,  0.0496,  0.0435,  0.0417,\n",
       "           -0.0498, -0.0565, -0.0433,  0.0468, -0.0457,  0.0552, -0.0510, -0.0553,\n",
       "           -0.0446, -0.0568, -0.0526, -0.0574, -0.0440, -0.0470,  0.0526,  0.0497,\n",
       "           -0.0435,  0.0480,  0.0539,  0.0532, -0.0561,  0.0522, -0.0433, -0.0453,\n",
       "            0.0519, -0.0554,  0.0510,  0.0451, -0.0478,  0.0420,  0.0573,  0.0578,\n",
       "           -0.0531, -0.0505, -0.0513, -0.0490, -0.0551, -0.0535,  0.0556,  0.0430,\n",
       "           -0.0489, -0.0437,  0.0572,  0.0578,  0.0506,  0.0473,  0.0481, -0.0450,\n",
       "           -0.0469,  0.0540, -0.0546,  0.0423,  0.0485, -0.0592, -0.0449,  0.0545,\n",
       "            0.0538, -0.0550,  0.0510, -0.0502,  0.0569, -0.0527,  0.0550,  0.0579,\n",
       "           -0.0532, -0.0441, -0.0554,  0.0523,  0.0468, -0.0540,  0.0445,  0.0474,\n",
       "            0.0452, -0.0437,  0.0462,  0.0532,  0.0458,  0.0497,  0.0539,  0.0539,\n",
       "            0.0451, -0.0480,  0.0499,  0.0526, -0.0555, -0.0414, -0.0562, -0.0528,\n",
       "            0.0566, -0.0473, -0.0415,  0.0515, -0.0459,  0.0514,  0.0453,  0.0525,\n",
       "            0.0499, -0.0569, -0.0429,  0.0475,  0.0498, -0.0498,  0.0465, -0.0436,\n",
       "           -0.0504,  0.0544, -0.0565,  0.0560, -0.0467,  0.0535,  0.0500, -0.0452,\n",
       "           -0.0471,  0.0485,  0.0437, -0.0474, -0.0474,  0.0451, -0.0439,  0.0565,\n",
       "           -0.0575,  0.0487,  0.0547, -0.0426, -0.0537,  0.0474, -0.0512, -0.0578],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.1330,  0.1312,  0.0392,  0.0319,  0.1314,  0.0348,  0.0325,  0.1319,\n",
       "            0.0328,  0.1274,  0.1308,  0.1278,  0.0300,  0.1329,  0.0316,  0.0315,\n",
       "            0.1322,  0.1338,  0.1308,  0.1318,  0.1321,  0.0317,  0.0324,  0.1321,\n",
       "            0.0331,  0.0325,  0.0028,  0.0321,  0.1511,  0.1273,  0.0320,  0.1324,\n",
       "            0.0310,  0.1319,  0.0319,  0.0317,  0.0323,  0.1289,  0.1314,  0.1061,\n",
       "            0.1361,  0.0340,  0.1283,  0.0321,  0.1310,  0.1319,  0.0345,  0.0332,\n",
       "            0.1344,  0.1321,  0.0299,  0.0325,  0.1317,  0.1313,  0.0325,  0.1314,\n",
       "            0.1316,  0.0321,  0.0334,  0.0339,  0.1326,  0.0307,  0.0349,  0.0326,\n",
       "            0.1339,  0.0324,  0.0374,  0.0319,  0.1272,  0.0145,  0.0327,  0.0326,\n",
       "            0.1363,  0.0323,  0.0321,  0.0351,  0.0322,  0.1311,  0.0320,  0.0308,\n",
       "            0.0317,  0.0325,  0.0326,  0.0338,  0.1320,  0.0315,  0.0390,  0.0325,\n",
       "            0.1287,  0.0317,  0.1316,  0.0323,  0.0320,  0.0319,  0.0325,  0.1252,\n",
       "            0.0391,  0.1348,  0.0262,  0.1300,  0.1293,  0.1301,  0.0822,  0.1260,\n",
       "            0.1299,  0.1293,  0.1323,  0.0318,  0.0345,  0.1300,  0.0261,  0.1314,\n",
       "            0.1294,  0.0330,  0.1315,  0.0389,  0.1300,  0.0327,  0.1303,  0.0215,\n",
       "            0.0343,  0.1316,  0.0322,  0.1332,  0.0313,  0.0319,  0.0324,  0.0257,\n",
       "            0.1267,  0.0322,  0.0336,  0.1316,  0.0323,  0.1329,  0.1338,  0.1333,\n",
       "            0.1317,  0.0266,  0.0319,  0.1315,  0.0272,  0.1322,  0.0323,  0.1329,\n",
       "            0.0326,  0.0343,  0.0325,  0.0311,  0.1329,  0.0318,  0.1314,  0.1319,\n",
       "            0.0313,  0.1360,  0.1296,  0.0326,  0.1316,  0.1320,  0.0323,  0.1319,\n",
       "            0.0318,  0.0393,  0.0167,  0.0320,  0.0337,  0.0322,  0.1348,  0.1361,\n",
       "            0.1307,  0.0306,  0.0301,  0.1324,  0.1316,  0.0309,  0.1200,  0.0322,\n",
       "            0.1313,  0.1323,  0.1329,  0.1329,  0.1293,  0.1313,  0.1391,  0.1338,\n",
       "            0.1367,  0.0322,  0.0313,  0.1330,  0.0328,  0.0335,  0.1314,  0.0267,\n",
       "            0.1306,  0.0328,  0.0321,  0.0313,  0.0611,  0.1304,  0.0186,  0.1323,\n",
       "            0.0329,  0.1313,  0.0318,  0.0333,  0.0314,  0.0339,  0.0312,  0.0268,\n",
       "            0.1334,  0.1295,  0.0318,  0.0304,  0.1307,  0.1339,  0.0321,  0.0629,\n",
       "            0.1359,  0.1346,  0.0317,  0.1324,  0.0323,  0.0328,  0.1260,  0.0291,\n",
       "            0.0325,  0.1464,  0.0371,  0.1275,  0.0319,  0.0325,  0.1308,  0.0321,\n",
       "            0.1321,  0.0307,  0.1317,  0.1327,  0.0330,  0.0319,  0.0320,  0.1370,\n",
       "            0.1435,  0.1346,  0.1266,  0.1328,  0.1294,  0.0108,  0.1320,  0.0331,\n",
       "            0.1313,  0.1314,  0.0291,  0.1314,  0.1317,  0.1325,  0.0303,  0.1330,\n",
       "            0.0252,  0.0316,  0.0320,  0.1322,  0.1304,  0.0323,  0.0331,  0.1351,\n",
       "            0.1322,  0.0328,  0.0322,  0.0321,  0.0316,  0.1331,  0.1304,  0.1333,\n",
       "            0.1235,  0.0315,  0.0328,  0.1306,  0.0322,  0.0334,  0.0331,  0.0323,\n",
       "            0.1314,  0.0317,  0.0328,  0.0345,  0.0339,  0.1339,  0.1318,  0.1324,\n",
       "            0.0299,  0.1326,  0.0318,  0.0317,  0.1311,  0.1320,  0.0328,  0.1316,\n",
       "            0.1296,  0.0342,  0.1304,  0.1320,  0.0350,  0.1344,  0.0276,  0.1310,\n",
       "            0.1315,  0.0316,  0.1319,  0.0318,  0.0318,  0.1328,  0.1556,  0.1218,\n",
       "            0.1336,  0.0297,  0.1315,  0.0300,  0.0323,  0.0320,  0.1309,  0.1306,\n",
       "            0.0323,  0.0325,  0.0391,  0.1325,  0.0329,  0.1337,  0.0324,  0.0303,\n",
       "            0.1315,  0.0327,  0.1307,  0.1328,  0.1327,  0.1325,  0.1323,  0.0404,\n",
       "            0.0316,  0.1301,  0.1314,  0.1317,  0.1313,  0.0407,  0.0370,  0.0309,\n",
       "            0.0329,  0.1254,  0.0307,  0.1362,  0.1299,  0.1305,  0.1320,  0.1395,\n",
       "            0.1321,  0.0483,  0.0321,  0.1319,  0.1311,  0.0320,  0.1314,  0.0329,\n",
       "            0.1214,  0.1311,  0.1309,  0.0320,  0.0320,  0.0332,  0.1321,  0.0368,\n",
       "            0.1313,  0.1332,  0.1317,  0.1318,  0.1320,  0.0316,  0.0323,  0.1319,\n",
       "            0.1330,  0.0319,  0.1301,  0.1316,  0.0384,  0.1321,  0.0318,  0.1354,\n",
       "            0.1320,  0.0230,  0.1330,  0.1300,  0.1327,  0.1320,  0.1315,  0.0382,\n",
       "            0.1326,  0.0330,  0.1319,  0.0316,  0.1121,  0.0314,  0.1275,  0.1319,\n",
       "            0.1318,  0.1320,  0.0318,  0.1329,  0.1327,  0.0333,  0.1313,  0.0220,\n",
       "            0.1303,  0.0318,  0.0307,  0.0321,  0.1313,  0.0319,  0.0270,  0.1321,\n",
       "            0.0263,  0.1280,  0.0322,  0.0326,  0.1425,  0.0325,  0.0312,  0.0302,\n",
       "            0.1315,  0.1316,  0.0328,  0.1324,  0.0324,  0.1312,  0.0325,  0.0324,\n",
       "            0.1335,  0.0307,  0.1294,  0.0328,  0.0087,  0.0327,  0.1300,  0.1357,\n",
       "            0.0320,  0.0328,  0.1322,  0.0322,  0.0348,  0.1316,  0.0323,  0.1317,\n",
       "            0.1318,  0.0304,  0.1340,  0.1330,  0.0301,  0.0322,  0.0331,  0.0335,\n",
       "            0.0315,  0.0316,  0.0321,  0.1312,  0.0309,  0.0289,  0.0320,  0.1321,\n",
       "           -0.0396,  0.0326,  0.1301,  0.0325,  0.1314,  0.1426,  0.1458,  0.0324,\n",
       "            0.0321,  0.0324,  0.1314,  0.1317,  0.1315,  0.1315,  0.1290,  0.0264,\n",
       "            0.1273,  0.0327,  0.1344,  0.1318,  0.0311,  0.0299,  0.0322,  0.0319,\n",
       "            0.1322,  0.1354,  0.0325,  0.1311,  0.1326,  0.0332,  0.0330,  0.0327,\n",
       "            0.0333,  0.1321,  0.0308,  0.1425,  0.1320,  0.1250,  0.0325,  0.1339,\n",
       "            0.0324,  0.1329,  0.0323,  0.0302,  0.1312,  0.1314,  0.1349,  0.1314],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0489, -0.0494,  0.0578,  0.0496,  0.0495,  0.0502, -0.0496, -0.0495,\n",
       "            0.0484, -0.0495,  0.0215,  0.0484,  0.0495,  0.0501,  0.0495,  0.0482,\n",
       "           -0.0498, -0.0477, -0.0497, -0.0591, -0.0504,  0.0496,  0.0468, -0.0494,\n",
       "            0.0495,  0.0497,  0.0495,  0.0496, -0.0497, -0.0513,  0.0513, -0.0498,\n",
       "            0.0498, -0.0490,  0.0481,  0.0468,  0.0505,  0.0486, -0.0508, -0.0457,\n",
       "           -0.0494,  0.0521, -0.0498,  0.0494, -0.0488, -0.0503,  0.0495, -0.0488,\n",
       "           -0.0495, -0.0498, -0.0507, -0.0496,  0.0495, -0.0494, -0.0495,  0.0495,\n",
       "            0.0493, -0.0509, -0.0507,  0.0489,  0.0499,  0.0487,  0.0506,  0.0494,\n",
       "            0.0528, -0.0502,  0.0492, -0.0510,  0.0496,  0.0493,  0.0500, -0.0497,\n",
       "            0.0494,  0.0486, -0.0493, -0.0493, -0.0499,  0.0490, -0.0507, -0.0497,\n",
       "           -0.0484, -0.0493, -0.0500, -0.0503, -0.0483,  0.0496,  0.0503, -0.0499,\n",
       "           -0.0496,  0.0494,  0.0502, -0.0517,  0.0501, -0.0492,  0.0542,  0.0494,\n",
       "           -0.0494,  0.0499, -0.0505,  0.0499,  0.0464,  0.0495,  0.0499,  0.0482,\n",
       "            0.0516,  0.0494, -0.0496,  0.0494,  0.0493,  0.0496, -0.0570,  0.0511,\n",
       "            0.0507, -0.0492,  0.0490,  0.0497,  0.0494, -0.0444, -0.0495, -0.0490,\n",
       "           -0.0506,  0.0498, -0.0495, -0.0501, -0.0497, -0.0515,  0.0493, -0.0504,\n",
       "            0.0484, -0.0511,  0.0497, -0.0495, -0.0492, -0.0495,  0.0501, -0.0497,\n",
       "           -0.0522,  0.0457,  0.0491, -0.0466,  0.0472,  0.0494, -0.0472, -0.0497,\n",
       "           -0.0499, -0.0496,  0.0478, -0.0490, -0.0492, -0.0500, -0.0499,  0.0496,\n",
       "            0.0498,  0.0517,  0.0528,  0.0524, -0.0498,  0.0497, -0.0499, -0.0499,\n",
       "            0.0496, -0.0508,  0.0517, -0.0498, -0.0501, -0.0484,  0.0497,  0.0497,\n",
       "           -0.0488, -0.0495, -0.0493, -0.0619, -0.0497,  0.0498, -0.0471, -0.0492,\n",
       "           -0.0500,  0.0455,  0.0502,  0.0501, -0.0503, -0.0492,  0.0502, -0.0491,\n",
       "           -0.0508,  0.0494,  0.0497,  0.0487, -0.0485,  0.0269, -0.0499, -0.0491,\n",
       "           -0.0497,  0.0494,  0.0450,  0.0487, -0.0514,  0.0487,  0.0550,  0.0498,\n",
       "           -0.0483,  0.0496,  0.0221,  0.0490,  0.0497,  0.0496,  0.0491, -0.0490,\n",
       "            0.0518, -0.0330,  0.0495, -0.0468, -0.0245,  0.0492,  0.0493,  0.0493,\n",
       "            0.0497,  0.0497, -0.0496,  0.0502,  0.0500, -0.0498, -0.0500, -0.0474,\n",
       "            0.0497, -0.0565, -0.0507,  0.0500,  0.0531, -0.0486,  0.0495, -0.0490,\n",
       "           -0.0495,  0.0509,  0.0491,  0.0498, -0.0497, -0.0500,  0.0507, -0.0514,\n",
       "            0.0492, -0.0491,  0.0501,  0.0500,  0.0487, -0.0482, -0.0492, -0.0498,\n",
       "           -0.0476,  0.0493,  0.0503, -0.0502, -0.0500, -0.0494,  0.0491,  0.0511,\n",
       "            0.0487, -0.0486,  0.0498,  0.0501,  0.0488, -0.0497, -0.0498, -0.0497,\n",
       "           -0.0497, -0.0500, -0.0495, -0.0494,  0.0505,  0.0510,  0.0498,  0.0451,\n",
       "           -0.0490, -0.0499,  0.0496,  0.0496,  0.0497, -0.0502,  0.0494, -0.0497,\n",
       "            0.0497, -0.0590,  0.0502, -0.0499, -0.0499,  0.0489, -0.0497,  0.0485,\n",
       "           -0.0486, -0.0499, -0.0499, -0.0502,  0.0488,  0.0500,  0.0499,  0.0497,\n",
       "            0.0495,  0.0517, -0.0486,  0.0498, -0.0499, -0.0498,  0.0500, -0.0498,\n",
       "           -0.0501, -0.0461, -0.0498, -0.0494, -0.0491, -0.0509, -0.0499,  0.0526,\n",
       "           -0.0510, -0.0497, -0.0497, -0.0494,  0.0498, -0.0500, -0.0496,  0.0494,\n",
       "            0.0523, -0.0501, -0.0517, -0.0485, -0.0499,  0.0499, -0.0495,  0.0495,\n",
       "            0.0495, -0.0498, -0.0494,  0.0501, -0.0495, -0.0490, -0.0495, -0.0505,\n",
       "            0.0495,  0.0492, -0.0496,  0.0496,  0.0495, -0.0486,  0.0497,  0.0389,\n",
       "           -0.0455,  0.0514,  0.0492,  0.0507, -0.0530,  0.0479, -0.0497,  0.0471,\n",
       "           -0.0496,  0.0502,  0.0499,  0.0503, -0.0492, -0.0498, -0.0495, -0.0499,\n",
       "           -0.0491, -0.0503, -0.0496, -0.0495,  0.0502, -0.0490, -0.0497, -0.0514,\n",
       "            0.0507, -0.0480, -0.0495,  0.0503, -0.0499, -0.0481,  0.0500, -0.0487,\n",
       "           -0.0498,  0.0505, -0.0491,  0.0503,  0.0495,  0.0500,  0.0496, -0.0474,\n",
       "           -0.0497, -0.0495, -0.0506,  0.0505, -0.0498,  0.0499, -0.0498, -0.0491,\n",
       "           -0.0500, -0.0498, -0.0496, -0.0499, -0.0504, -0.0490,  0.0495,  0.0499,\n",
       "           -0.0488,  0.0512,  0.0476,  0.0505, -0.0495,  0.0514, -0.0502, -0.0494,\n",
       "            0.0485,  0.0478,  0.0484,  0.0481, -0.0509,  0.0488,  0.0490,  0.0498,\n",
       "           -0.0497, -0.0495, -0.0501, -0.0499, -0.0496, -0.0505,  0.0503,  0.0493,\n",
       "           -0.0504, -0.0507,  0.0494,  0.0493,  0.0497,  0.0499,  0.0498, -0.0493,\n",
       "           -0.0495,  0.0527, -0.0496,  0.0489,  0.0490, -0.0503, -0.0495,  0.0496,\n",
       "            0.0490, -0.0500,  0.0487, -0.0503,  0.0469, -0.0496,  0.0497,  0.0490,\n",
       "           -0.0498, -0.0484, -0.0500,  0.0497,  0.0493, -0.0496,  0.0497,  0.0500,\n",
       "            0.0486, -0.0497,  0.0496,  0.0500,  0.0495, -0.0500,  0.0487,  0.0502,\n",
       "            0.0492, -0.0498,  0.0502,  0.0501, -0.0476,  0.0674, -0.0498, -0.0493,\n",
       "            0.0499, -0.0484, -0.0495,  0.0496, -0.0500,  0.0503,  0.0529,  0.0424,\n",
       "           -0.0524, -0.0503, -0.0483,  0.0495,  0.0497, -0.0491,  0.0497, -0.0495,\n",
       "           -0.0497,  0.0495, -0.0446,  0.0165, -0.0504,  0.0490, -0.0461, -0.0478,\n",
       "           -0.0500,  0.0496,  0.0490, -0.0502, -0.0496,  0.0485,  0.0487,  0.0498,\n",
       "           -0.0497,  0.0492,  0.0481, -0.0496, -0.0499,  0.0503, -0.0495, -0.0492],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.1168,  0.1354,  0.1185,  0.0278,  0.1350,  0.1221,  0.0407,  0.1351,\n",
       "            0.0413,  0.0257,  0.1413,  0.1374,  0.0282,  0.1322,  0.0344,  0.0282,\n",
       "            0.1356,  0.1451,  0.1304,  0.1297,  0.1331,  0.0341,  0.0321,  0.1316,\n",
       "            0.0234,  0.0336,  0.0205,  0.0328,  0.0307,  0.1310,  0.0319,  0.1310,\n",
       "            0.0282,  0.1341,  0.0289,  0.0382,  0.0294,  0.1310,  0.1311,  0.0564,\n",
       "            0.1321,  0.0318,  0.1306,  0.0348,  0.1265,  0.1223,  0.0368,  0.0835,\n",
       "            0.1400,  0.1336,  0.0798,  0.0290,  0.1323,  0.1284,  0.0308,  0.1282,\n",
       "            0.1337,  0.0158,  0.0323,  0.0269,  0.1328,  0.0307,  0.0354,  0.0233,\n",
       "            0.1318,  0.0323,  0.1001,  0.0350,  0.1320,  0.0201,  0.0374,  0.0318,\n",
       "            0.1403,  0.0411,  0.0343,  0.1220,  0.0334,  0.1304,  0.0340,  0.1274,\n",
       "            0.0363,  0.0352,  0.0318,  0.0294,  0.1336,  0.0272,  0.0302,  0.0323,\n",
       "            0.1581,  0.0367,  0.1312,  0.0322,  0.0422,  0.0331,  0.0284,  0.1319,\n",
       "            0.0483,  0.1303,  0.0272,  0.1317,  0.1330,  0.1339,  0.1483,  0.1327,\n",
       "            0.1234,  0.0395,  0.1279,  0.0443,  0.1042,  0.1230,  0.0360,  0.1308,\n",
       "            0.1363,  0.0320,  0.1333,  0.1184,  0.0389,  0.0347,  0.0285,  0.0400,\n",
       "            0.0403,  0.1415,  0.0261,  0.1360,  0.0254,  0.0313,  0.0349,  0.0363,\n",
       "            0.1335,  0.0312,  0.0100,  0.1321,  0.0758,  0.1336,  0.1327,  0.1283,\n",
       "            0.1293,  0.0295,  0.0386,  0.1314,  0.0321,  0.1292,  0.0330,  0.1527,\n",
       "            0.0288,  0.0398,  0.0338,  0.0306,  0.1342,  0.0444,  0.1257,  0.1348,\n",
       "            0.1398,  0.1276,  0.1285,  0.0320,  0.1302,  0.1304,  0.0315,  0.1386,\n",
       "            0.0316,  0.0299,  0.0461,  0.0345,  0.0320,  0.0320,  0.1299,  0.0433,\n",
       "            0.1305,  0.0712,  0.0370,  0.0656,  0.1272,  0.0166,  0.0530,  0.0324,\n",
       "            0.1326,  0.1373,  0.1382,  0.1314,  0.1318,  0.1339,  0.1265,  0.1418,\n",
       "            0.1322,  0.0344,  0.0477,  0.1296,  0.0167,  0.0317,  0.1276,  0.1449,\n",
       "            0.1302,  0.0325,  0.0310,  0.0339,  0.0310,  0.1329,  0.0380,  0.1301,\n",
       "            0.0328,  0.1279,  0.0315,  0.1447,  0.0442,  0.0239,  0.0348,  0.0481,\n",
       "            0.1447,  0.1314,  0.0324,  0.0338,  0.1291,  0.0912,  0.0329,  0.1281,\n",
       "            0.1367,  0.1097,  0.0322,  0.1298,  0.0319,  0.0300,  0.1257,  0.0348,\n",
       "            0.0315,  0.1216,  0.0379,  0.1293,  0.0539,  0.0299,  0.1309,  0.0302,\n",
       "            0.1226,  0.0272,  0.1394,  0.1172,  0.0201,  0.0312,  0.0312,  0.1538,\n",
       "            0.0303,  0.1295,  0.1355,  0.1308,  0.1496,  0.1352,  0.1344,  0.1396,\n",
       "            0.0551,  0.1328,  0.0636,  0.1310,  0.1301,  0.1307,  0.0129,  0.1322,\n",
       "            0.1276,  0.0295,  0.0370,  0.1317,  0.1328,  0.0408,  0.0303,  0.1266,\n",
       "            0.1347,  0.0306,  0.1580,  0.0289,  0.0323,  0.1365,  0.0441,  0.1343,\n",
       "            0.1296,  0.0314,  0.0336,  0.1233,  0.0302,  0.0310,  0.0346,  0.0327,\n",
       "            0.1312,  0.0319,  0.0298,  0.0299,  0.0239,  0.1318,  0.1293,  0.0423,\n",
       "            0.0337,  0.1311,  0.0264,  0.0225,  0.1284,  0.1326,  0.0403,  0.1315,\n",
       "            0.1385,  0.0277,  0.1301,  0.1314,  0.1327,  0.1347,  0.0356,  0.1332,\n",
       "            0.1348,  0.0327,  0.1040,  0.0317,  0.0266,  0.1325, -0.0051,  0.1311,\n",
       "            0.1325,  0.0452,  0.1334,  0.0240,  0.0337,  0.0330,  0.1424,  0.0289,\n",
       "            0.0324,  0.0251,  0.0289,  0.0758,  0.1480,  0.1434,  0.0325,  0.0340,\n",
       "            0.1364,  0.0317,  0.1327,  0.1470,  0.1221,  0.0997,  0.1277,  0.1323,\n",
       "            0.0343,  0.1582,  0.1323,  0.1293,  0.1327,  0.0348,  0.1403,  0.0332,\n",
       "            0.0325,  0.1312,  0.0431,  0.1271,  0.1282,  0.1302,  0.1306,  0.0294,\n",
       "            0.1321,  0.0297,  0.0351,  0.1319,  0.0307,  0.0377,  0.1341,  0.0343,\n",
       "            0.1243,  0.1358,  0.1277,  0.0316,  0.0391,  0.0336,  0.1324,  0.0260,\n",
       "            0.1300,  0.1374,  0.1356,  0.1352,  0.1309,  0.0291,  0.0350,  0.1341,\n",
       "            0.1166,  0.0319,  0.1298,  0.1313,  0.0591,  0.1306,  0.0353,  0.1304,\n",
       "            0.1301,  0.1238,  0.1342,  0.1303,  0.1281,  0.1317,  0.1331,  0.1246,\n",
       "            0.1316,  0.0863,  0.1333,  0.1234,  0.0638,  0.0330,  0.0160,  0.1454,\n",
       "            0.1263,  0.1361,  0.0316,  0.1281,  0.1318,  0.0317,  0.1324,  0.0338,\n",
       "            0.1303,  0.0262,  0.0306,  0.0372,  0.1436,  0.0318,  0.0359,  0.1390,\n",
       "            0.1497,  0.0917,  0.0316, -0.0116,  0.1446,  0.0238,  0.0491,  0.0319,\n",
       "            0.1314,  0.1296,  0.0307,  0.1331,  0.0370,  0.1330,  0.0309,  0.0336,\n",
       "            0.1572,  0.0348,  0.1359,  0.0346,  0.0252,  0.0326,  0.1644,  0.1316,\n",
       "            0.0316,  0.0419,  0.1298,  0.0285,  0.0330,  0.1307,  0.0307,  0.1322,\n",
       "            0.1294,  0.0347,  0.1359,  0.1309,  0.0368,  0.0316,  0.0292,  0.0306,\n",
       "            0.0285,  0.0337,  0.0356,  0.1323,  0.0423,  0.0427,  0.0303,  0.1333,\n",
       "            0.0303,  0.0319,  0.1299,  0.0352,  0.1330,  0.0399,  0.1362,  0.0325,\n",
       "            0.0354,  0.0308,  0.0201,  0.1321,  0.1269,  0.1339,  0.1302,  0.0445,\n",
       "            0.0415,  0.0328,  0.0878,  0.1326,  0.0345,  0.0120,  0.0252,  0.1516,\n",
       "            0.1267,  0.1255,  0.0312,  0.1318,  0.1364,  0.0313,  0.0343,  0.0316,\n",
       "            0.0390,  0.1322,  0.0312,  0.1360,  0.1333,  0.1300,  0.0314,  0.1419,\n",
       "            0.0070,  0.1318,  0.0411,  0.0245,  0.1357,  0.0514,  0.1287,  0.1362],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0486, -0.0484, -0.0533,  0.0502,  0.0495,  0.0502, -0.0515, -0.0497,\n",
       "            0.0513, -0.0487, -0.0527,  0.0518,  0.0491,  0.0494,  0.0499,  0.0493,\n",
       "           -0.0506, -0.0481, -0.0493, -0.0458, -0.0470,  0.0503, -0.0644, -0.0494,\n",
       "            0.0499,  0.0528,  0.0486,  0.0501, -0.0498, -0.0614,  0.0514, -0.0496,\n",
       "            0.0488, -0.0496,  0.0485,  0.0540,  0.0490,  0.0506, -0.0463, -0.0441,\n",
       "           -0.0499,  0.0521, -0.0496,  0.0499, -0.0491, -0.0490,  0.0502, -0.0497,\n",
       "           -0.0509, -0.0518, -0.0507, -0.0485,  0.0495, -0.0494, -0.0492,  0.0488,\n",
       "            0.0516, -0.0473, -0.0477,  0.0494,  0.0490,  0.0498,  0.0503,  0.0497,\n",
       "            0.0482, -0.0497,  0.0487, -0.0498,  0.0503,  0.0488,  0.0502, -0.0493,\n",
       "            0.0512,  0.0498, -0.0502, -0.0496, -0.0495,  0.0495, -0.0650, -0.0501,\n",
       "           -0.0513, -0.0514, -0.0495, -0.0483, -0.0495,  0.0494,  0.0519, -0.0504,\n",
       "           -0.0501,  0.0507,  0.0496, -0.0490,  0.0518, -0.0440,  0.0400,  0.0503,\n",
       "           -0.0508,  0.0487,  0.0516, -0.0646,  0.0497,  0.0488,  0.0498,  0.0501,\n",
       "            0.0464,  0.0510, -0.0491,  0.0484,  0.0488,  0.0498, -0.0469,  0.0510,\n",
       "            0.0545, -0.0497,  0.0504,  0.0491,  0.0504, -0.0492, -0.0504, -0.0504,\n",
       "           -0.0495,  0.0503, -0.0485, -0.0497, -0.0458, -0.0517,  0.0500, -0.0480,\n",
       "            0.0499, -0.0383,  0.0481, -0.0466, -0.0497, -0.0509,  0.0484, -0.0454,\n",
       "           -0.0499,  0.0637,  0.0502, -0.0508,  0.0485,  0.0499, -0.0473, -0.0474,\n",
       "           -0.0488, -0.0496,  0.0524, -0.0493, -0.0492, -0.0496, -0.0501,  0.0501,\n",
       "            0.0507,  0.0491, -0.0627,  0.0758, -0.0493,  0.0501, -0.0503, -0.0529,\n",
       "            0.0498, -0.0520,  0.0502, -0.0508, -0.0497, -0.0504,  0.0430,  0.0505,\n",
       "           -0.0504, -0.0494, -0.0511,  0.0521, -0.0494,  0.0492,  0.0577, -0.0490,\n",
       "           -0.0500,  0.0503,  0.0505,  0.0490, -0.0496, -0.0491,  0.0504, -0.0509,\n",
       "           -0.0492,  0.0502,  0.0500,  0.0476, -0.0480,  0.0478, -0.0493, -0.0508,\n",
       "           -0.0498,  0.0502,  0.0630,  0.0475, -0.0421,  0.0504,  0.0515,  0.0493,\n",
       "           -0.0527,  0.0497, -0.0581,  0.0501,  0.0503,  0.0496,  0.0499, -0.0501,\n",
       "            0.0530, -0.0614,  0.0506, -0.0550, -0.0546,  0.0480,  0.0498,  0.0488,\n",
       "            0.0502,  0.0495, -0.0496,  0.0491,  0.0496, -0.0496, -0.0495, -0.0586,\n",
       "            0.0509, -0.0442, -0.0492,  0.0491,  0.0626, -0.0514,  0.0493, -0.0499,\n",
       "           -0.0484,  0.0490,  0.0503,  0.0482, -0.0494, -0.0508,  0.0504, -0.0480,\n",
       "            0.0499, -0.0462,  0.0492,  0.0491,  0.0495, -0.0504, -0.0487, -0.0508,\n",
       "           -0.0467,  0.0498,  0.0509, -0.0495, -0.0492, -0.0505,  0.0491,  0.0520,\n",
       "            0.0522, -0.0495,  0.0496,  0.0499, -0.0593, -0.0498,  0.0504, -0.0504,\n",
       "           -0.0498, -0.0490, -0.0494, -0.0490,  0.0486,  0.0516,  0.0498,  0.0516,\n",
       "           -0.0512, -0.0495,  0.0547,  0.0511,  0.0499, -0.0498,  0.0499, -0.0504,\n",
       "            0.0501,  0.0718,  0.0489, -0.0510, -0.0493,  0.0499, -0.0502, -0.0693,\n",
       "           -0.0539, -0.0499, -0.0505, -0.0495,  0.0476,  0.0502,  0.0507,  0.0489,\n",
       "            0.0496,  0.0470, -0.0474,  0.0499, -0.0500, -0.0497,  0.0524, -0.0510,\n",
       "           -0.0494, -0.0428, -0.0496, -0.0505, -0.0487, -0.0524, -0.0489,  0.0422,\n",
       "           -0.0504, -0.0504, -0.0501, -0.0484,  0.0490, -0.0504, -0.0510,  0.0481,\n",
       "            0.0467, -0.0488, -0.0449, -0.0511, -0.0503,  0.0483, -0.0505,  0.0496,\n",
       "            0.0503, -0.0510, -0.0502,  0.0495, -0.0476, -0.0501, -0.0505, -0.0497,\n",
       "            0.0500,  0.0499, -0.0471,  0.0497,  0.0473, -0.0500,  0.0444, -0.0422,\n",
       "            0.0589,  0.0505,  0.0503,  0.0476, -0.0523, -0.0518, -0.0489, -0.0501,\n",
       "            0.0449,  0.0512,  0.0495,  0.0490, -0.0508, -0.0503, -0.0498, -0.0497,\n",
       "           -0.0483, -0.0495, -0.0491, -0.0500,  0.0493, -0.0508, -0.0502, -0.0521,\n",
       "            0.0510, -0.0528, -0.0489,  0.0489, -0.0495, -0.0453,  0.0504, -0.0509,\n",
       "           -0.0497,  0.0502, -0.0490,  0.0496,  0.0504,  0.0492,  0.0491,  0.0578,\n",
       "           -0.0501, -0.0494, -0.0506,  0.0498, -0.0504,  0.0497, -0.0498, -0.0507,\n",
       "           -0.0494, -0.0504, -0.0506, -0.0495, -0.0469, -0.0497,  0.0492,  0.0493,\n",
       "           -0.0480,  0.0489,  0.0419,  0.0500, -0.0501,  0.0498, -0.0496, -0.0496,\n",
       "            0.0474, -0.0491,  0.0501,  0.0528, -0.0506,  0.0436,  0.0493,  0.0505,\n",
       "           -0.0482, -0.0504, -0.0460, -0.0505, -0.0496, -0.0495,  0.0498,  0.0474,\n",
       "           -0.0501, -0.0488,  0.0492,  0.0496,  0.0501,  0.0494,  0.0495, -0.0488,\n",
       "           -0.0503,  0.0465, -0.0496,  0.0502,  0.0383, -0.0567, -0.0476,  0.0496,\n",
       "            0.0504, -0.0490,  0.0479, -0.0497,  0.0566, -0.0499,  0.0492,  0.0496,\n",
       "           -0.0493, -0.0522, -0.0491,  0.0498,  0.0499, -0.0509, -0.0119,  0.0494,\n",
       "            0.0485, -0.0494,  0.0495,  0.0497,  0.0501,  0.0080,  0.0504,  0.0498,\n",
       "            0.0499, -0.0494,  0.0489,  0.0524, -0.0475, -0.0562, -0.0508, -0.0480,\n",
       "            0.0499, -0.0504, -0.0499,  0.0511, -0.0494,  0.0503,  0.0491,  0.0441,\n",
       "            0.0628, -0.0505, -0.0494,  0.0498,  0.0502, -0.0503,  0.0493, -0.0504,\n",
       "           -0.0508,  0.0485, -0.0612,  0.0407, -0.0514,  0.0491,  0.0577, -0.0454,\n",
       "           -0.0497,  0.0492,  0.0494, -0.0552, -0.0500,  0.0500, -0.0230,  0.0499,\n",
       "           -0.0500,  0.0480, -0.0398, -0.0495, -0.0496,  0.0491, -0.0493, -0.0493],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0038,  0.0445,  0.0692,  ..., -0.0495,  0.0499,  0.0503],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0495, -0.0496, -0.0496,  0.0497,  0.0496,  0.0498, -0.0498, -0.0497,\n",
       "            0.0494, -0.0497,  0.0497,  0.0499,  0.0497,  0.0497,  0.0496,  0.0497,\n",
       "           -0.0496, -0.0495, -0.0496, -0.0496, -0.0493,  0.0497,  0.0504, -0.0496,\n",
       "            0.0496,  0.0495,  0.0498,  0.0497, -0.0496, -0.0496,  0.0493, -0.0498,\n",
       "            0.0497, -0.0498,  0.0498,  0.0501,  0.0497,  0.0461, -0.0490,  0.0494,\n",
       "           -0.0496, -0.0490, -0.0497,  0.0497,  0.0501, -0.0497,  0.0497, -0.0500,\n",
       "           -0.0502, -0.0498, -0.0497, -0.0497,  0.0496, -0.0496, -0.0496,  0.0495,\n",
       "            0.0496, -0.0498, -0.0497,  0.0493,  0.0496,  0.0495,  0.0498,  0.0496,\n",
       "           -0.0495, -0.0498,  0.0497, -0.0498,  0.0497,  0.0496,  0.0497, -0.0499,\n",
       "            0.0497,  0.0499, -0.0497, -0.0497, -0.0498,  0.0496,  0.0531, -0.0497,\n",
       "           -0.0499, -0.0500, -0.0496, -0.0497, -0.0498,  0.0497,  0.0498, -0.0497,\n",
       "           -0.0497,  0.0497,  0.0495, -0.0494,  0.0494,  0.0493, -0.0496,  0.0498,\n",
       "           -0.0495,  0.0497, -0.0496,  0.0494,  0.0504,  0.0498,  0.0494,  0.0494,\n",
       "            0.0498,  0.0497, -0.0495,  0.0496,  0.0497,  0.0497, -0.0503, -0.0503,\n",
       "           -0.0493, -0.0465,  0.0497,  0.0498,  0.0495, -0.0500, -0.0497, -0.0497,\n",
       "           -0.0499,  0.0497, -0.0497, -0.0498, -0.0496, -0.0497,  0.0497, -0.0494,\n",
       "            0.0497,  0.0546,  0.0497, -0.0496, -0.0497, -0.0497,  0.0496, -0.0498,\n",
       "            0.0504, -0.0503,  0.0497, -0.0505,  0.0494,  0.0496, -0.0492, -0.0510,\n",
       "           -0.0496, -0.0496,  0.0497, -0.0497, -0.0493, -0.0497, -0.0494,  0.0496,\n",
       "            0.0497,  0.0495,  0.0503,  0.0497, -0.0497,  0.0496, -0.0496, -0.0499,\n",
       "            0.0497, -0.0497,  0.0500, -0.0498, -0.0497, -0.0497, -0.0499,  0.0497,\n",
       "            0.0504, -0.0497, -0.0496, -0.0501, -0.0498,  0.0497, -0.0497, -0.0495,\n",
       "           -0.0495,  0.0496,  0.0496,  0.0497, -0.0497, -0.0495,  0.0498, -0.0497,\n",
       "           -0.0521,  0.0497,  0.0497,  0.0496, -0.0490,  0.0491, -0.0497, -0.0497,\n",
       "           -0.0496,  0.0496,  0.0494, -0.0502,  0.0495,  0.0493,  0.0495,  0.0497,\n",
       "            0.0501,  0.0497, -0.0494,  0.0497,  0.0498,  0.0497,  0.0496, -0.0498,\n",
       "            0.0503, -0.0497,  0.0498, -0.0497, -0.0497,  0.0499,  0.0497,  0.0497,\n",
       "            0.0500,  0.0496, -0.0497,  0.0497,  0.0497, -0.0497, -0.0497, -0.0502,\n",
       "            0.0495, -0.0538, -0.0494,  0.0498,  0.0686, -0.0497,  0.0495, -0.0497,\n",
       "           -0.0495,  0.0496,  0.0495,  0.0498, -0.0496, -0.0498, -0.0498, -0.0495,\n",
       "            0.0497, -0.0496,  0.0497,  0.0498,  0.0498, -0.0497, -0.0496, -0.0497,\n",
       "           -0.0501,  0.0495,  0.0497, -0.0497, -0.0497, -0.0496,  0.0496,  0.0498,\n",
       "            0.0497, -0.0497,  0.0496,  0.0497,  0.0504, -0.0496, -0.0492, -0.0495,\n",
       "           -0.0497, -0.0497, -0.0497, -0.0496,  0.0496,  0.0496,  0.0497, -0.0499,\n",
       "           -0.0497, -0.0499,  0.0495,  0.0498,  0.0497, -0.0497,  0.0496, -0.0497,\n",
       "            0.0496,  0.0503,  0.0499, -0.0504, -0.0497,  0.0492, -0.0496, -0.0509,\n",
       "            0.0504, -0.0497, -0.0497, -0.0493,  0.0495,  0.0496,  0.0495,  0.0496,\n",
       "            0.0497,  0.0496, -0.0499,  0.0497, -0.0496, -0.0497,  0.0499, -0.0496,\n",
       "           -0.0495, -0.0433, -0.0496, -0.0497, -0.0497, -0.0497, -0.0496,  0.0496,\n",
       "           -0.0496, -0.0498, -0.0496, -0.0496,  0.0496, -0.0496, -0.0497,  0.0496,\n",
       "            0.0498, -0.0498,  0.0495, -0.0497, -0.0499,  0.0500, -0.0497,  0.0497,\n",
       "            0.0497, -0.0491,  0.0458,  0.0496, -0.0495, -0.0496, -0.0498, -0.0497,\n",
       "            0.0497,  0.0499, -0.0499,  0.0497,  0.0506, -0.0497,  0.0497, -0.0496,\n",
       "           -0.0391,  0.0497,  0.0496,  0.0498,  0.0509, -0.0503, -0.0497,  0.0498,\n",
       "           -0.0496,  0.0497,  0.0497,  0.0495, -0.0495, -0.0497, -0.0498, -0.0497,\n",
       "           -0.0496, -0.0498, -0.0496, -0.0498,  0.0498, -0.0497, -0.0498, -0.0505,\n",
       "            0.0498,  0.0491, -0.0496,  0.0496, -0.0497, -0.0495,  0.0496, -0.0494,\n",
       "           -0.0497,  0.0499, -0.0496,  0.0498,  0.0496,  0.0495,  0.0497, -0.0507,\n",
       "           -0.0496,  0.0601, -0.0498,  0.0498, -0.0496,  0.0496, -0.0497, -0.0498,\n",
       "           -0.0498, -0.0497, -0.0497, -0.0500, -0.0497, -0.0497,  0.0498,  0.0496,\n",
       "           -0.0498,  0.0500,  0.0494,  0.0494, -0.0496,  0.0495, -0.0498, -0.0497,\n",
       "            0.0497,  0.0503,  0.0683,  0.0496, -0.0500,  0.0479,  0.0498,  0.0497,\n",
       "           -0.0499, -0.0497, -0.0497, -0.0496, -0.0495, -0.0498,  0.0500,  0.0494,\n",
       "           -0.0498, -0.0498,  0.0497,  0.0497,  0.0497,  0.0497,  0.0497, -0.0498,\n",
       "           -0.0497, -0.0494, -0.0499,  0.0495,  0.0497, -0.0478, -0.0496,  0.0497,\n",
       "            0.0498, -0.0496,  0.0499, -0.0497,  0.0500, -0.0497,  0.0497,  0.0498,\n",
       "           -0.0496, -0.0499, -0.0497,  0.0497,  0.0497, -0.0497,  0.0507,  0.0503,\n",
       "            0.0497, -0.0497,  0.0496,  0.0497,  0.0497, -0.0500,  0.0496,  0.0497,\n",
       "            0.0498, -0.0497,  0.0495,  0.0495, -0.0498, -0.0498, -0.0496, -0.0496,\n",
       "            0.0497, -0.0497, -0.0496,  0.0497, -0.0497,  0.0499, -0.0481,  0.0494,\n",
       "           -0.0495, -0.0498, -0.0519,  0.0498,  0.0498, -0.0498,  0.0498, -0.0492,\n",
       "           -0.0497,  0.0497, -0.0498,  0.0497, -0.0495,  0.0500, -0.0499, -0.0503,\n",
       "           -0.0497,  0.0496,  0.0500, -0.0505, -0.0496,  0.0508,  0.0502,  0.0496,\n",
       "           -0.0497,  0.0493,  0.0501, -0.0497, -0.0497,  0.0498, -0.0497, -0.0495],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0569, -0.0493,  0.0533,  0.0311, -0.0503,  0.0504,  0.0476, -0.0538,\n",
       "           -0.0303,  0.0443,  0.0413,  0.0512, -0.0528, -0.0491,  0.0464, -0.0533,\n",
       "            0.0523,  0.0453,  0.0473, -0.0467,  0.0608,  0.0507,  0.0509,  0.0470,\n",
       "           -0.0420, -0.0427, -0.0536, -0.0500,  0.0531,  0.0500,  0.0473,  0.0575,\n",
       "           -0.0464,  0.0452,  0.0436,  0.0523,  0.0482, -0.0492,  0.0485, -0.0350,\n",
       "           -0.0503,  0.0496, -0.0601, -0.0512, -0.0446,  0.0481,  0.0488, -0.0397,\n",
       "            0.0494, -0.0446, -0.0513,  0.0519, -0.0473, -0.0458,  0.0511, -0.0395,\n",
       "           -0.0548, -0.0518,  0.0470, -0.0520,  0.0521,  0.0569, -0.0484, -0.0465,\n",
       "           -0.0468,  0.0489, -0.0315,  0.0529, -0.0531,  0.0368,  0.0534,  0.0547,\n",
       "           -0.0540,  0.0335,  0.0483, -0.0496, -0.1133, -0.0495, -0.0218,  0.0478,\n",
       "           -0.0523, -0.0610,  0.0406,  0.0498,  0.0454, -0.0503, -0.0408, -0.0229,\n",
       "           -0.0500, -0.0456,  0.0508, -0.0506, -0.0541, -0.0501,  0.0461, -0.0611,\n",
       "            0.0543,  0.0587,  0.0489, -0.0520], device='mps:0',\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0531, -0.0444, -0.0456,  0.0485,  0.0525,  0.0489, -0.0493, -0.0491,\n",
       "            0.0542, -0.0435,  0.0568,  0.0489,  0.0514,  0.0554,  0.0504,  0.0520,\n",
       "           -0.0539, -0.0477, -0.0425, -0.0465,  0.0496,  0.0462, -0.0552, -0.0435,\n",
       "            0.0492,  0.0514,  0.0525,  0.0561, -0.0500, -0.0403,  0.0438, -0.0558,\n",
       "            0.0516, -0.0259,  0.0447,  0.0498,  0.0431,  0.0274,  0.0484, -0.0448,\n",
       "           -0.0540,  0.0490, -0.0538,  0.0463, -0.0500, -0.0424,  0.0460, -0.0515,\n",
       "           -0.0525, -0.0544, -0.0439, -0.0524,  0.0563, -0.0409, -0.0419,  0.0510,\n",
       "            0.0545, -0.0537, -0.0476,  0.0529,  0.0421,  0.0474,  0.0462,  0.0496,\n",
       "           -0.0470, -0.0557,  0.0506, -0.0446,  0.0552,  0.0418,  0.0512, -0.0494,\n",
       "            0.0479,  0.0505, -0.0541, -0.0464, -0.0423,  0.0465, -0.0471, -0.0518,\n",
       "           -0.0430, -0.0578, -0.0473, -0.0421, -0.0441,  0.0420,  0.0427, -0.0519,\n",
       "           -0.0557,  0.0493,  0.0418, -0.0545,  0.0534,  0.0525, -0.0403,  0.0438,\n",
       "           -0.0447,  0.0531,  0.0426, -0.0539,  0.0572,  0.0482,  0.0568,  0.0529,\n",
       "            0.0512,  0.0447, -0.0538,  0.0527,  0.0544,  0.0506, -0.0509,  0.0536,\n",
       "           -0.0592,  0.0515,  0.0557,  0.0557,  0.0461, -0.0418, -0.0422, -0.0435,\n",
       "           -0.0524,  0.0417, -0.0487, -0.0432, -0.0493, -0.0512,  0.0451, -0.0536,\n",
       "            0.0531,  0.0427,  0.0501, -0.0292, -0.0530, -0.0531,  0.0509, -0.0477,\n",
       "            0.0460, -0.0609,  0.0465, -0.0588,  0.0577,  0.0436, -0.0486, -0.0541,\n",
       "           -0.0518, -0.0566,  0.0444, -0.0575, -0.0545, -0.0416, -0.0560,  0.0549,\n",
       "            0.0555,  0.0565,  0.0391,  0.0525, -0.0448,  0.0574, -0.0550, -0.0467,\n",
       "            0.0442, -0.0560,  0.0491, -0.0411, -0.0526, -0.0430,  0.0575,  0.0480,\n",
       "            0.0506, -0.0475, -0.0494, -0.0455, -0.0545,  0.0570, -0.0495, -0.0448,\n",
       "           -0.0514,  0.0460,  0.0570,  0.0554, -0.0416, -0.0541,  0.0477, -0.0485,\n",
       "           -0.0650,  0.0458,  0.0465,  0.0504, -0.0567,  0.0462, -0.0528, -0.0420,\n",
       "           -0.0573,  0.0427,  0.0477, -0.0458,  0.0479,  0.0542,  0.0564,  0.0520,\n",
       "            0.0502,  0.0559, -0.0456,  0.0491,  0.0574,  0.0553,  0.0484, -0.0450,\n",
       "            0.0539, -0.0495,  0.0478, -0.0469, -0.0476,  0.0521,  0.0455,  0.0532,\n",
       "            0.0505,  0.0440, -0.0498,  0.0548,  0.0528, -0.0452, -0.0581, -0.0501,\n",
       "            0.0479, -0.0405, -0.0555,  0.0568, -0.0586, -0.0459,  0.0503, -0.0482,\n",
       "           -0.0454,  0.0487,  0.0444,  0.0524, -0.0512, -0.0528, -0.0431, -0.0578,\n",
       "            0.0448, -0.0565,  0.0519,  0.0535,  0.0565, -0.0541, -0.0526, -0.0415,\n",
       "            0.0502,  0.0441,  0.0439, -0.0436, -0.0445, -0.0532,  0.0506,  0.0574,\n",
       "            0.0492, -0.0418,  0.0563,  0.0524, -0.0458, -0.0531, -0.0376, -0.0476,\n",
       "           -0.0423, -0.0527, -0.0536, -0.0424,  0.0470,  0.0465,  0.0482, -0.0485,\n",
       "           -0.0520, -0.0574,  0.0437,  0.0543,  0.0529, -0.0496,  0.0466, -0.0503,\n",
       "            0.0483,  0.0360,  0.0521, -0.0511, -0.0571,  0.0401, -0.0539, -0.0328,\n",
       "            0.0429, -0.0529, -0.0559, -0.0464,  0.0411,  0.0511,  0.0567,  0.0537,\n",
       "            0.0575,  0.0417, -0.0520,  0.0459, -0.0468, -0.0527,  0.0517, -0.0491,\n",
       "           -0.0449,  0.0721, -0.0446, -0.0439, -0.0492, -0.0570, -0.0536,  0.0530,\n",
       "           -0.0492, -0.0437, -0.0466, -0.0444,  0.0524, -0.0568, -0.0507,  0.0551,\n",
       "            0.0423, -0.0444, -0.0423, -0.0425, -0.0543,  0.0518, -0.0429,  0.0466,\n",
       "            0.0444,  0.0612,  0.0523,  0.0452, -0.0432, -0.0428, -0.0520, -0.0520,\n",
       "            0.0460,  0.0567, -0.0421,  0.0537,  0.0462, -0.0418,  0.0388, -0.0438,\n",
       "           -0.0573,  0.0518,  0.0563,  0.0501,  0.0104, -0.0491, -0.0520,  0.0494,\n",
       "           -0.0524,  0.0565,  0.0509,  0.0427, -0.0425, -0.0533, -0.0458, -0.0461,\n",
       "           -0.0455, -0.0530, -0.0575, -0.0568,  0.0417, -0.0423, -0.0519, -0.0500,\n",
       "            0.0477,  0.0393, -0.0489,  0.0431, -0.0579, -0.0497,  0.0430, -0.0512,\n",
       "           -0.0493,  0.0428, -0.0513,  0.0560,  0.0409,  0.0502,  0.0424,  0.0550,\n",
       "           -0.0508, -0.0613, -0.0435,  0.0487, -0.0443,  0.0553, -0.0516, -0.0546,\n",
       "           -0.0448, -0.0565, -0.0535, -0.0578, -0.0430, -0.0467,  0.0520,  0.0491,\n",
       "           -0.0439,  0.0463,  0.0534,  0.0562, -0.0560,  0.0527, -0.0431, -0.0457,\n",
       "            0.0519, -0.0554,  0.0498,  0.0455, -0.0467,  0.0373,  0.0577,  0.0579,\n",
       "           -0.0511, -0.0510, -0.0522, -0.0494, -0.0552, -0.0535,  0.0539,  0.0429,\n",
       "           -0.0488, -0.0466,  0.0571,  0.0581,  0.0504,  0.0469,  0.0480, -0.0454,\n",
       "           -0.0466, -0.0512, -0.0554,  0.0419,  0.0499, -0.0548, -0.0487,  0.0530,\n",
       "            0.0533, -0.0545,  0.0512, -0.0502,  0.0560, -0.0531,  0.0552,  0.0596,\n",
       "           -0.0539, -0.0433, -0.0561,  0.0524,  0.0468, -0.0540, -0.0556,  0.0479,\n",
       "            0.0438, -0.0439,  0.0466,  0.0533,  0.0455, -0.0514,  0.0565,  0.0541,\n",
       "            0.0448, -0.0479,  0.0507,  0.0494,  0.0253, -0.0419, -0.0564, -0.0524,\n",
       "            0.0563, -0.0468, -0.0419,  0.0522, -0.0457,  0.0520,  0.0375,  0.0488,\n",
       "           -0.0685, -0.0572, -0.0434,  0.0472,  0.0516, -0.0514,  0.0470,  0.0550,\n",
       "           -0.0505,  0.0548, -0.0440,  0.0527, -0.0473,  0.0641, -0.0516, -0.0490,\n",
       "           -0.0463,  0.0491,  0.0438,  0.0549, -0.0471,  0.0431,  0.0385,  0.0575,\n",
       "           -0.0585,  0.0475,  0.0210, -0.0423, -0.0537,  0.0478, -0.0511, -0.0522],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.1472,  0.1332,  0.1389,  0.0307,  0.1343,  0.1517,  0.0298,  0.1304,\n",
       "            0.0197,  0.0404,  0.0322,  0.1299,  0.1501,  0.1354,  0.0218,  0.0284,\n",
       "            0.1323,  0.1181,  0.1246,  0.1272,  0.1320,  0.0348,  0.0327,  0.1269,\n",
       "           -0.0037,  0.0318,  0.1263,  0.0318,  0.0214,  0.1281,  0.0309,  0.1302,\n",
       "            0.0199,  0.1321,  0.0299,  0.0376,  0.0329,  0.1327,  0.1339,  0.0286,\n",
       "            0.1214,  0.0322,  0.1379,  0.0320,  0.1286,  0.1689,  0.0332,  0.0499,\n",
       "            0.1357,  0.1310,  0.0330,  0.0374,  0.1323,  0.1876,  0.0180,  0.1312,\n",
       "            0.1311,  0.0362,  0.0318,  0.0362,  0.1325,  0.0384,  0.0386,  0.0301,\n",
       "            0.1265,  0.0428,  0.1496,  0.0361,  0.1302,  0.0410,  0.0336,  0.0346,\n",
       "            0.1228,  0.0410,  0.0319,  0.1156,  0.0337,  0.1324,  0.0288,  0.1316,\n",
       "            0.0268,  0.0357,  0.0114,  0.0967,  0.1306,  0.0237,  0.0369,  0.0351,\n",
       "            0.1509,  0.0256,  0.1437,  0.0308, -0.0274,  0.0301,  0.0301,  0.1629,\n",
       "            0.0352,  0.0005,  0.0295,  0.1362,  0.1319,  0.1443,  0.1813,  0.1439,\n",
       "            0.1323,  0.0408,  0.1297,  0.0271,  0.1367,  0.1339,  0.0334,  0.1320,\n",
       "            0.1334,  0.0456,  0.1347,  0.1325,  0.1021,  0.0310,  0.1218,  0.0168,\n",
       "            0.0332,  0.1315,  0.0182,  0.1263,  0.0264,  0.0256,  0.0315, -0.0765,\n",
       "            0.1335,  0.0422,  0.0337,  0.1315,  0.0325,  0.1327,  0.1228,  0.1336,\n",
       "            0.1310,  0.0321,  0.0420,  0.1307,  0.0100,  0.1147,  0.0380,  0.1364,\n",
       "            0.0299,  0.0312,  0.0326,  0.0324,  0.1191,  0.0578,  0.1359,  0.1339,\n",
       "            0.1473,  0.1355,  0.1341,  0.0307,  0.1316,  0.1309,  0.0215,  0.1316,\n",
       "            0.0312,  0.0268,  0.0573,  0.0350,  0.0295,  0.0278,  0.1318,  0.0353,\n",
       "            0.1341,  0.0212,  0.0290,  0.0262,  0.1389,  0.2209,  0.0213,  0.0304,\n",
       "            0.1307,  0.1151,  0.1388,  0.1346,  0.1485,  0.1316,  0.1608,  0.1245,\n",
       "            0.1501,  0.0320,  0.0333,  0.1350,  0.0301,  0.0316,  0.1337,  0.0170,\n",
       "            0.1498,  0.0305,  0.0305,  0.0333,  0.0135,  0.1439, -0.0035,  0.1303,\n",
       "            0.0330,  0.1338,  0.0352,  0.0910,  0.0278,  0.0401,  0.0320,  0.1225,\n",
       "            0.1333,  0.1298,  0.0319,  0.0311,  0.1269,  0.1232,  0.0299,  0.1314,\n",
       "            0.0810,  0.0294,  0.0339,  0.1366,  0.0319,  0.0365,  0.0241,  0.0295,\n",
       "            0.0252,  0.1274,  0.0520,  0.1334,  0.1402,  0.0346,  0.1339,  0.0322,\n",
       "            0.1895,  0.0316,  0.1281,  0.1260,  0.0316,  0.0277,  0.0295,  0.3730,\n",
       "            0.0315,  0.1303,  0.1725,  0.1479,  0.1307,  0.1280,  0.1280,  0.1299,\n",
       "            0.0305,  0.1294,  0.0439,  0.1304,  0.1327,  0.1275,  0.1241,  0.1314,\n",
       "            0.1424,  0.0304,  0.0326,  0.1161,  0.1333,  0.0293,  0.0309,  0.1465,\n",
       "            0.1722,  0.0374,  0.0203,  0.0271,  0.0302,  0.1248, -0.1430,  0.1290,\n",
       "            0.1317,  0.0326,  0.0374,  0.1453,  0.0336,  0.0366,  0.0273,  0.0298,\n",
       "            0.1310,  0.0340,  0.0357,  0.0336,  0.0423,  0.1146,  0.1321,  0.0442,\n",
       "            0.0309,  0.1295,  0.0330,  0.0203,  0.1309,  0.1311,  0.0318,  0.1326,\n",
       "            0.1333,  0.0133,  0.1253,  0.1322,  0.0366,  0.1361,  0.0392,  0.1242,\n",
       "            0.1258,  0.0285,  0.1376,  0.0319,  0.0317,  0.1335,  0.0898,  0.1350,\n",
       "            0.2541,  0.0302,  0.1333,  0.0255,  0.0276,  0.0231,  0.1410,  0.0632,\n",
       "            0.0308,  0.0294,  0.0305,  0.0969,  0.0550,  0.0922,  0.0305,  0.0335,\n",
       "            0.1460,  0.0321,  0.0987,  0.1294,  0.1136,  0.1375,  0.1287,  0.1272,\n",
       "            0.0336,  0.1364,  0.1319,  0.1314,  0.1298,  0.0284,  0.1217,  0.0349,\n",
       "            0.0318,  0.1346,  0.0275,  0.1332,  0.1369,  0.1321,  0.1318,  0.0217,\n",
       "            0.1281,  0.0310,  0.0288,  0.1308,  0.0245,  0.0294,  0.1326,  0.0353,\n",
       "            0.1257,  0.1350,  0.2945,  0.0310,  0.0295,  0.0266,  0.1343,  0.0396,\n",
       "            0.1324,  0.1359,  0.1319,  0.1306,  0.1326,  0.0396,  0.0329,  0.1355,\n",
       "            0.0336,  0.0337,  0.1289,  0.1853,  0.0207,  0.1303,  0.0318,  0.1304,\n",
       "            0.1339,  0.1232,  0.1321,  0.1320,  0.1236,  0.1326,  0.1326,  0.0373,\n",
       "            0.1333, -0.1912,  0.1327,  0.1421,  0.0319,  0.0315,  0.1284,  0.1308,\n",
       "            0.1337,  0.1310,  0.0030,  0.1216,  0.1318,  0.0297,  0.1355,  0.0670,\n",
       "            0.1278,  0.0357,  0.1437,  0.0278,  0.1314,  0.0348,  0.0193,  0.1305,\n",
       "           -0.0110,  0.1294,  0.0338,  0.0186,  0.2879,  0.0328,  0.0479,  0.0276,\n",
       "            0.1319,  0.1320,  0.0338,  0.1311,  0.0289,  0.1695,  0.0343,  0.0331,\n",
       "            0.0285,  0.0345,  0.1502,  0.0460,  0.0203,  0.0325,  0.1406,  0.1316,\n",
       "            0.0347,  0.0593,  0.1337,  0.0268,  0.0317,  0.1321,  0.0343,  0.1317,\n",
       "            0.1337,  0.0319,  0.1339,  0.1351,  0.0556,  0.0303,  0.0310,  0.0347,\n",
       "            0.0322,  0.0421,  0.0561,  0.1313,  0.1301,  0.0310,  0.0235,  0.1395,\n",
       "            0.0318,  0.1441,  0.1329,  0.0265,  0.1307,  0.0301,  0.3712,  0.0308,\n",
       "            0.0317,  0.0292,  0.1295,  0.1296,  0.1320,  0.1330,  0.1254, -0.0296,\n",
       "            0.1454,  0.0339,  0.1042,  0.1324,  0.0410, -0.0220,  0.0326,  0.1303,\n",
       "            0.1315,  0.1422,  0.0296,  0.1333,  0.1356,  0.0324,  0.0394,  0.0322,\n",
       "            0.0316,  0.1346,  0.0320,  0.1263,  0.1313,  0.1324,  0.0328,  0.1392,\n",
       "            0.1745,  0.1079,  0.0392,  0.0507,  0.1320,  0.0509,  0.0120,  0.1191],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0465, -0.0505, -0.0448,  0.0499,  0.0483,  0.0465, -0.0515, -0.0506,\n",
       "            0.0548, -0.0479,  0.0487,  0.0482,  0.0486,  0.0478,  0.0499,  0.0516,\n",
       "           -0.0497, -0.0607, -0.0481, -0.0569,  0.0042,  0.0482,  0.0281, -0.0496,\n",
       "            0.0518,  0.0501,  0.0485,  0.0507, -0.0475, -0.0578,  0.0473, -0.0503,\n",
       "            0.0522, -0.0357,  0.0543,  0.0538,  0.0496,  0.0426, -0.0407,  0.0642,\n",
       "           -0.0510,  0.0637, -0.0491,  0.0496,  0.0286, -0.0444,  0.0494, -0.0480,\n",
       "           -0.0579, -0.0541, -0.0473, -0.0453,  0.0489, -0.0449, -0.0524,  0.0463,\n",
       "            0.0488, -0.0469, -0.0537,  0.0414,  0.0476,  0.0394,  0.0476,  0.0501,\n",
       "           -0.0817, -0.0488,  0.0450, -0.0449,  0.0516,  0.0480,  0.0495, -0.0437,\n",
       "            0.0518,  0.0465, -0.0494, -0.0473, -0.0517,  0.0486, -0.0497, -0.0503,\n",
       "           -0.0562, -0.0502, -0.0487, -0.0499, -0.0499,  0.0512,  0.0476, -0.0494,\n",
       "           -0.0481,  0.0510,  0.0411, -0.0512,  0.0585,  0.0467, -0.0489,  0.0486,\n",
       "           -0.0475,  0.0500, -0.0808,  0.0103,  0.0537,  0.0474,  0.0487,  0.0477,\n",
       "            0.0534,  0.0427, -0.0482,  0.0498,  0.0486,  0.0488, -0.0373, -0.0722,\n",
       "           -0.0283,  0.3200,  0.0480,  0.0493,  0.0515, -0.0622, -0.0481, -0.0492,\n",
       "           -0.0504,  0.0487, -0.0503, -0.0501, -0.0519, -0.0537,  0.0500, -0.0514,\n",
       "            0.0479,  0.1009,  0.0509, -0.0544, -0.0493, -0.0505,  0.0545, -0.0488,\n",
       "            0.0599, -0.0096,  0.0473, -0.0251,  0.0573,  0.0492, -0.0408, -0.0562,\n",
       "           -0.0465, -0.0496,  0.0490, -0.0500, -0.0534, -0.0460, -0.0502,  0.0495,\n",
       "            0.0487,  0.0460,  0.0493,  0.0601, -0.0494,  0.0490, -0.0487, -0.0520,\n",
       "            0.0506, -0.0474,  0.0455, -0.0498, -0.0508, -0.0535, -0.0337,  0.0484,\n",
       "            0.0510, -0.0506, -0.0497, -0.0584, -0.0482,  0.0498, -0.0472, -0.0528,\n",
       "           -0.0507,  0.0544,  0.0480,  0.0473, -0.0431, -0.0447,  0.0481, -0.0496,\n",
       "            0.1055,  0.0478,  0.0493,  0.0477, -0.0570,  0.0529, -0.0495, -0.0511,\n",
       "           -0.0462,  0.0488,  0.0559, -0.0535,  0.0549,  0.0378,  0.0509,  0.0499,\n",
       "            0.0449,  0.0491, -0.0203,  0.0511,  0.0500,  0.0494,  0.0532, -0.0530,\n",
       "            0.0466, -0.0614,  0.0484, -0.0480, -0.0527,  0.0521,  0.0509,  0.0471,\n",
       "            0.0519,  0.0500, -0.0488,  0.0482,  0.0512, -0.0499, -0.0506, -0.0650,\n",
       "            0.0480,  0.0774, -0.0387,  0.0459,  0.0943, -0.0457,  0.0469, -0.0512,\n",
       "           -0.0453,  0.0493,  0.0493,  0.0506, -0.0502, -0.0560, -0.0389, -0.0422,\n",
       "            0.0509, -0.0474,  0.0478,  0.0482,  0.0486, -0.0506, -0.0506, -0.0408,\n",
       "           -0.0217,  0.0505,  0.0488, -0.0502, -0.0497, -0.0553,  0.0497,  0.0502,\n",
       "            0.0422, -0.0531,  0.0483,  0.0527,  0.0525, -0.0498, -0.0550, -0.0470,\n",
       "           -0.0481, -0.0457, -0.0519, -0.0512,  0.0516,  0.0540,  0.0501, -0.0468,\n",
       "           -0.0494, -0.0504,  0.0380,  0.0500,  0.0495, -0.0495,  0.0476, -0.0516,\n",
       "            0.0483,  0.0517,  0.0492, -0.0575, -0.0470,  0.0559, -0.0496, -0.1673,\n",
       "            0.0588, -0.0498, -0.0492, -0.0525,  0.0456,  0.0484,  0.0478,  0.0473,\n",
       "            0.0470,  0.0626, -0.0494,  0.0491, -0.0481, -0.0482,  0.0441, -0.0554,\n",
       "           -0.0488, -0.0482, -0.0477, -0.0514, -0.0489, -0.0474, -0.0498,  0.0477,\n",
       "           -0.0456, -0.0525, -0.0482, -0.0503,  0.0496, -0.0509, -0.0487,  0.0484,\n",
       "            0.0496, -0.0457,  0.0602, -0.0539, -0.0508,  0.0550, -0.0519,  0.0500,\n",
       "            0.0484, -0.0557,  0.0429,  0.0488, -0.0511, -0.0452, -0.0598, -0.0483,\n",
       "            0.0504,  0.0498, -0.0205,  0.0496,  0.0571, -0.0499,  0.0514, -0.0457,\n",
       "            0.0137,  0.0490,  0.0520,  0.0483,  0.0745, -0.1076, -0.0489,  0.0631,\n",
       "           -0.0512,  0.0530,  0.0506,  0.0497, -0.0499, -0.0531, -0.0484, -0.0473,\n",
       "           -0.0498, -0.0474, -0.0514, -0.0514,  0.0548, -0.0529, -0.0458, -0.0473,\n",
       "            0.0485,  0.0293, -0.0499,  0.0529, -0.0492, -0.0462,  0.0482, -0.0319,\n",
       "           -0.0506,  0.0505, -0.0500,  0.0459,  0.0527,  0.0489,  0.0497, -0.0771,\n",
       "           -0.0482, -0.1399, -0.0515, -0.0481, -0.0530,  0.0499, -0.0487, -0.0497,\n",
       "           -0.0522, -0.0527, -0.0473, -0.0493, -0.0470, -0.0498,  0.0517,  0.0490,\n",
       "           -0.0502,  0.0479,  0.0575,  0.0568, -0.0487,  0.0471, -0.0481, -0.0504,\n",
       "            0.0541,  0.1606,  0.0161,  0.0507, -0.0523, -0.0213,  0.0501,  0.0495,\n",
       "           -0.0486, -0.0499, -0.0499, -0.0533, -0.0429, -0.0488,  0.0418,  0.0481,\n",
       "           -0.0508, -0.0479,  0.0488,  0.0500,  0.0499,  0.0497,  0.0484, -0.0468,\n",
       "           -0.0501, -0.0461, -0.0484,  0.0428,  0.0536, -0.0627, -0.0600,  0.0496,\n",
       "            0.0457, -0.0475,  0.0500, -0.0530,  0.0502, -0.0500,  0.0487,  0.0515,\n",
       "           -0.0499, -0.0550, -0.0481,  0.0494,  0.0489, -0.0510, -0.0366,  0.0537,\n",
       "            0.0493, -0.0478,  0.0489,  0.0496,  0.0490, -0.0586,  0.0588,  0.0478,\n",
       "            0.0514, -0.0483,  0.0492,  0.0515, -0.0327, -0.0574, -0.0459, -0.0506,\n",
       "            0.0504, -0.0534, -0.0497,  0.0515, -0.0497,  0.0462, -0.0758,  0.0508,\n",
       "           -0.0227, -0.0469, -0.0943,  0.0502,  0.0385, -0.0515,  0.0491, -0.0439,\n",
       "           -0.0498,  0.0500, -0.0557,  0.0455, -0.0493,  0.0137, -0.0385, -0.1503,\n",
       "           -0.0478,  0.0481,  0.0538, -0.0520, -0.0500,  0.0378,  0.0577,  0.0488,\n",
       "           -0.0489,  0.0636,  0.0453, -0.0479, -0.0488,  0.0463, -0.0491, -0.0484],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 1.7987e-01,  1.2121e-01,  1.3867e-01, -1.0180e-04,  1.0248e-01,\n",
       "           -1.5626e-02, -2.5781e-02,  1.5337e-01,  1.8058e-02,  3.9772e-02,\n",
       "           -6.1790e-03,  9.2474e-02,  2.7416e-01,  1.9078e-01, -2.2743e-02,\n",
       "            3.1514e-02,  1.4247e-01,  1.7086e-01, -2.1336e-02,  1.1771e-01,\n",
       "            9.8771e-02,  4.3845e-02,  1.2886e-02,  1.3820e-01,  1.5029e-01,\n",
       "           -3.6756e-02,  1.3597e-01,  1.2924e-02, -3.2008e-02,  1.0085e-01,\n",
       "            3.8312e-02,  1.7022e-02,  1.9888e-02,  1.2199e-01,  1.4456e-02,\n",
       "            5.9457e-02,  1.9426e-02,  1.2116e-01,  1.2310e-01,  8.9339e-02,\n",
       "            1.0938e-01,  3.0579e-02,  1.5271e-01,  2.9873e-02,  1.3839e-01,\n",
       "            1.4708e-01,  1.1287e-01,  1.6471e-01,  1.6200e-01,  1.3469e-01,\n",
       "           -7.4516e-02,  1.2777e-01,  1.4001e-01,  6.8721e-01, -1.2252e-01,\n",
       "            1.5614e-01,  1.3674e-01,  4.7263e-03,  2.8126e-02,  1.3140e-01,\n",
       "            1.0971e-01,  1.4092e-02, -2.2355e-02, -3.5106e-03, -5.4593e-04,\n",
       "            3.7573e-02,  1.3679e-01,  9.7219e-03,  9.1838e-02, -3.8588e-02,\n",
       "            8.0419e-03,  4.2073e-04,  1.0477e-01,  1.4725e-01,  1.5848e-02,\n",
       "           -1.1907e-01,  9.6939e-02,  1.3861e-01,  6.3209e-03,  1.5370e-01,\n",
       "            2.1277e-02,  8.9418e-02, -2.9000e-01,  8.7388e-02,  1.1104e-01,\n",
       "           -1.9272e-02,  2.6571e-02,  2.0062e-02,  2.1146e-01, -2.8906e-02,\n",
       "            9.4087e-02,  4.4278e-02, -2.1271e-01,  1.7878e-01,  3.2823e-02,\n",
       "            1.7905e-02,  2.9905e-02,  2.4192e-01,  1.3459e-02,  1.1048e-01,\n",
       "            1.6445e-01,  1.4906e-01,  1.6840e-01,  7.5768e-02,  1.6598e-01,\n",
       "            4.5317e-02,  2.6927e-01,  5.2178e-02,  1.9899e-01,  1.1718e-01,\n",
       "            1.4544e-02,  1.2889e-01,  1.4925e-01,  8.2311e-02,  1.0715e-01,\n",
       "            1.3666e-01, -2.0373e-01,  3.6196e-02,  9.8990e-03, -5.1255e-01,\n",
       "           -2.1321e-03,  2.3411e-01,  3.6983e-01,  6.5188e-02, -9.8342e-02,\n",
       "           -3.8986e-03,  2.5194e-02, -2.1723e-02,  9.7696e-02,  6.1539e-02,\n",
       "            4.6615e-01,  1.6518e-01,  1.6556e-01,  1.1584e-01,  4.0355e-03,\n",
       "            1.4620e-01,  1.0925e-01,  4.9378e-02,  1.1490e-02,  1.2663e-01,\n",
       "            6.0943e-02, -4.3688e-02, -6.3633e-03,  9.1784e-02,  2.7940e-02,\n",
       "           -1.7401e-02,  2.3179e-02,  1.3829e-02,  3.8019e-01, -3.2922e-02,\n",
       "            2.3524e-01, -3.4161e-01,  1.3975e-01,  1.4126e-01,  1.3807e-01,\n",
       "            2.6499e-02,  1.5507e-01,  1.3579e-01,  1.2155e-02,  2.5816e-02,\n",
       "            1.7370e-02, -7.9072e-03,  2.5593e-01,  1.5237e-02,  6.4904e-02,\n",
       "           -6.3591e-02,  1.3295e-01,  1.5680e-02,  6.2343e-02, -4.0413e-01,\n",
       "           -4.9369e-03,  3.1330e-02, -1.2995e-01,  1.3336e-01,  4.1745e-02,\n",
       "            1.4865e-02,  1.3790e-01, -5.1069e-03,  1.2007e-01,  1.4338e-01,\n",
       "            5.0302e-01,  1.0282e-01, -1.9986e-02,  8.2894e-02,  9.6916e-02,\n",
       "            1.5368e-02, -8.1744e-02,  1.3718e-01,  6.5882e-02,  1.0272e-02,\n",
       "            1.8773e-01, -1.0457e-01,  3.1782e-01,  6.8762e-02,  1.6252e-02,\n",
       "            3.7396e-02, -1.2057e-02,  8.2013e-02,  2.9362e-01,  1.3109e-01,\n",
       "            9.8428e-03,  1.4669e-01,  3.6091e-02,  1.4954e-01, -4.8423e-02,\n",
       "           -1.9920e-01,  2.0336e-02, -2.3089e-01,  1.3143e-01,  1.2629e-01,\n",
       "            2.7624e-02,  3.4384e-02,  3.0372e-01,  8.6359e-02,  1.8972e-02,\n",
       "            1.6071e-01, -1.1583e-01, -4.3887e-02,  1.1250e-02,  1.2290e-01,\n",
       "            1.8201e-02, -4.9364e-03,  8.4174e-01, -1.2479e-02,  1.1067e-01,\n",
       "            1.3914e-01,  1.7994e-02,  1.6281e-01,  1.3154e-01,  1.5540e-02,\n",
       "            1.4865e-01,  1.1011e-02, -5.5436e-02,  6.2981e-02, -2.9830e-02,\n",
       "           -6.2165e-01,  3.2099e-01, -7.1475e-03,  1.1160e-02,  1.6434e-01,\n",
       "           -6.4166e-02,  1.3470e-01,  1.4091e-01,  4.4406e-01, -1.6753e-01,\n",
       "            1.0005e-01,  1.7775e-01,  1.3972e-01, -5.7877e-02,  5.8700e-02,\n",
       "           -9.9675e-02,  1.2631e-01,  1.0322e-01,  1.4809e-01,  1.5558e-01,\n",
       "            1.4548e-01,  3.2495e-03,  1.2834e-02, -3.0128e-02,  1.9368e-02,\n",
       "            1.0588e-01, -2.6376e-03,  2.8930e-02,  2.0926e-01,  5.1285e-01,\n",
       "            3.6525e-02,  5.1423e-01, -2.0738e-02,  7.6536e-03,  1.4375e-01,\n",
       "           -5.4757e-02,  1.4239e-01,  4.3533e-02,  2.1415e-02,  2.1524e-02,\n",
       "           -1.9617e-01, -1.1679e-02,  2.2374e-01, -1.3242e-01,  8.2688e-03,\n",
       "            8.8587e-02,  3.8376e-02, -5.9950e-02,  9.5467e-03,  1.2368e-01,\n",
       "           -5.4923e-02,  1.4554e-01,  3.3389e-02,  2.0038e-02,  1.2801e-01,\n",
       "            1.8889e-02,  2.8323e-02,  1.0852e-01,  1.4409e-01,  2.7957e-02,\n",
       "            9.1878e-02,  1.8485e-01, -1.6134e-01,  7.6584e-02,  1.4094e-01,\n",
       "            9.6901e-02,  1.3140e-01, -6.0211e-03,  5.6753e-02,  1.9568e-01,\n",
       "            3.1263e-02,  1.7076e-02,  2.7223e-02, -1.4530e-02,  1.3427e-01,\n",
       "            4.4105e-01,  1.3439e-01,  1.2041e-01, -1.4043e-02,  1.4545e-01,\n",
       "           -4.1388e-03,  6.1532e-02,  3.0289e-02,  1.4169e-01,  3.2368e-02,\n",
       "            4.3137e-02, -3.5896e-01,  2.3699e-02,  4.7037e-02,  2.2997e-01,\n",
       "           -8.5954e-02,  3.4312e-02, -7.6560e-03,  7.6162e-02,  1.3672e-01,\n",
       "           -3.4346e-02,  1.9976e-01, -1.7803e-01,  1.4703e-01,  1.8480e-01,\n",
       "            1.0328e-01,  8.3486e-03,  1.2395e-01,  1.5244e-01,  1.4158e-01,\n",
       "            4.8174e-02,  3.5227e-02,  1.3033e-01,  1.4933e-02,  3.2142e-02,\n",
       "            1.3389e-01,  4.2767e-01, -1.1444e-01,  1.1736e-01,  5.9359e-02,\n",
       "            1.8224e-01,  3.3892e-02,  1.3222e-01,  2.0691e-02, -1.0197e-01,\n",
       "            1.2219e-01, -6.9597e-03,  1.2451e-02,  1.3036e-01, -4.5488e-02,\n",
       "           -1.1288e-01,  7.2242e-02,  1.4064e+00,  1.3391e-02,  2.1229e-03,\n",
       "           -4.7941e-02,  1.4589e-01,  2.5315e-02,  1.4948e-01,  1.2895e-01,\n",
       "            1.5076e-01,  1.2456e-01,  1.2760e-01, -1.8023e-02, -8.6600e-03,\n",
       "            1.2860e-01,  3.3333e-03,  8.0062e-02,  1.6404e-01,  2.7496e-01,\n",
       "           -1.3842e-01,  1.5197e-01,  7.7248e-03,  1.7515e-01,  1.4103e-01,\n",
       "            1.3204e-01,  1.9135e-01,  1.5421e-01,  1.1435e-01,  1.2962e-01,\n",
       "            1.7571e-01, -2.1996e-01,  1.4155e-01, -1.1323e-02,  1.8477e-01,\n",
       "            1.2954e-01,  3.0834e-02,  1.9668e-02, -3.7600e-02,  1.6357e-01,\n",
       "            1.3250e-01,  7.5464e-02,  1.4218e-01,  2.4095e-01,  1.5471e-01,\n",
       "            1.4724e-01,  6.4937e-03,  4.7595e-01,  1.4058e-01,  8.8215e-02,\n",
       "           -1.8131e-01,  6.0833e-02, -3.0184e-01,  4.4720e-02, -6.3116e-02,\n",
       "            1.8713e-01,  1.0293e-01, -9.3023e-02,  2.2014e-02,  2.8811e-01,\n",
       "            1.3977e-02,  6.6351e-03,  1.7665e-01,  2.6148e-02,  5.9480e-02,\n",
       "            1.7537e-01, -2.3712e-02,  1.2862e-01,  3.2813e-03,  1.2719e-01,\n",
       "            1.6511e-02,  5.5196e-02,  2.1289e-02,  2.1002e-03,  2.1534e-01,\n",
       "           -3.6189e-02, -1.0642e-02,  3.6471e-02, -4.1486e-02,  4.0334e-02,\n",
       "            2.4925e-02, -3.7694e-02,  6.9770e-02, -5.4425e-02,  1.3772e-02,\n",
       "            1.4450e-01, -5.2346e-03,  2.1873e-01,  1.4526e-01,  5.7440e-02,\n",
       "            1.7403e-01,  1.6723e-01, -6.1051e-02, -9.1705e-03,  1.5611e-02,\n",
       "            1.4219e-03, -8.6268e-02, -5.6105e-03,  1.0557e-01,  1.5354e-01,\n",
       "            4.0839e-02,  2.0205e-02,  2.2169e-02,  1.4703e-01,  1.4295e-02,\n",
       "           -8.1434e-03,  1.6697e-01,  1.0362e-01,  1.7623e-01,  3.2367e-02,\n",
       "            2.3484e-01,  2.1717e-02, -7.3570e-03,  2.0310e-02, -3.8705e-02,\n",
       "            1.6730e-01,  1.8671e-01,  1.5994e-01,  1.2070e-01,  1.7383e-01,\n",
       "           -2.2112e-01,  9.1696e-02, -8.0215e-02,  4.3115e-02,  1.4867e-01,\n",
       "           -7.2824e-01,  1.7977e-02,  1.1398e-01,  1.6461e-01,  1.7598e-01,\n",
       "            4.7698e-02,  1.2263e-01,  2.1979e-01,  3.2133e-02,  1.7180e-01,\n",
       "            2.0259e-02,  1.2088e-02,  1.6481e-01, -1.9721e-02,  1.2017e-01,\n",
       "            1.3616e-01,  1.5594e-01,  3.7321e-02,  6.4661e-01,  1.9660e-01,\n",
       "            1.2490e-01, -1.7348e-02, -1.9907e-01,  1.1913e-01,  1.1492e-01,\n",
       "            1.0714e-02,  1.8305e-01], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0605, -0.0520, -0.0465,  0.0402,  0.0366,  0.0387, -0.0299, -0.0591,\n",
       "            0.0459, -0.0486, -0.0078, -0.0048,  0.0555,  0.0483,  0.0452,  0.0265,\n",
       "           -0.0621, -0.0762, -0.0390, -0.0385, -0.0932,  0.0371,  0.1509, -0.0500,\n",
       "            0.0541,  0.0760,  0.0222,  0.0359, -0.0353,  0.1089,  0.0674, -0.0483,\n",
       "            0.0308, -0.0938,  0.0295,  0.0274,  0.0367, -0.3144, -0.1400, -0.3676,\n",
       "           -0.0511, -0.1035, -0.0764,  0.0445, -0.0675, -0.0647,  0.0499, -0.0055,\n",
       "           -0.1082, -0.0539, -0.0268, -0.0614,  0.0575, -0.0827, -0.0244,  0.0584,\n",
       "            0.0812, -0.0281, -0.0705,  0.0812,  0.0513,  0.0114,  0.0391,  0.0407,\n",
       "            0.0550, -0.0543,  0.0562, -0.0111,  0.0647,  0.0281,  0.0483, -0.0170,\n",
       "            0.0430,  0.0569, -0.0341, -0.0402, -0.0348,  0.0525,  0.1360, -0.0576,\n",
       "           -0.0185, -0.0677, -0.0383, -0.0581, -0.0315,  0.0418,  0.0692, -0.0361,\n",
       "           -0.0492,  0.0272,  0.0136, -0.1120,  0.0086,  0.0773,  0.1857,  0.0447,\n",
       "           -0.0357,  0.0507, -0.0131,  0.1250,  0.0809,  0.0774,  0.0751,  0.0814,\n",
       "            0.0692, -0.0028, -0.0714,  0.0595,  0.0545,  0.0517, -0.0705,  0.3259,\n",
       "           -0.2448, -0.3142,  0.0223,  0.0985,  0.0193, -0.0129, -0.0434, -0.0325,\n",
       "           -0.0395,  0.0648, -0.0577, -0.0315,  0.0015, -0.0671,  0.0361, -0.0011,\n",
       "            0.0640,  0.0979,  0.0679,  0.2233, -0.0531, -0.0424,  0.0592, -0.0591,\n",
       "           -0.4780, -0.3351,  0.0286,  0.0112,  0.0954,  0.0388, -0.0088,  0.0376,\n",
       "           -0.0678, -0.0440,  0.0059, -0.0271, -0.1012, -0.0268, -0.0909,  0.0256,\n",
       "            0.0582,  0.0649, -0.0216,  0.0134, -0.0656,  0.0616, -0.0523, -0.0145,\n",
       "            0.0368,  0.0084,  0.0751, -0.0162, -0.0492, -0.0281,  0.3304,  0.0395,\n",
       "            0.0149, -0.0183, -0.0253,  0.0279, -0.0244,  0.0544, -0.0733, -0.0138,\n",
       "           -0.0837,  0.0161,  0.0588,  0.0604,  0.0722, -0.0238,  0.0408, -0.0306,\n",
       "           -0.2024,  0.0367,  0.0334,  0.0656, -0.1566,  0.1059, -0.0640, -0.0346,\n",
       "           -0.0767,  0.0734,  0.3264, -0.0765,  0.0136,  0.1012,  0.0766,  0.0607,\n",
       "           -0.0093,  0.0565, -0.1142,  0.0694,  0.0345,  0.0336,  0.0159, -0.0020,\n",
       "            0.0256,  0.0086,  0.0304, -0.0050, -0.0836,  0.0731,  0.0350,  0.0649,\n",
       "           -0.0194,  0.0334, -0.0412,  0.0585,  0.0328, -0.0429, -0.0546,  0.0301,\n",
       "            0.0629, -0.3128, -0.0358,  0.0625, -0.3509,  0.0148,  0.0606, -0.0320,\n",
       "           -0.0850,  0.0835,  0.0288,  0.0304, -0.0604, -0.0248, -0.0179, -0.0726,\n",
       "            0.0300, -0.0362,  0.0531,  0.0677,  0.0222, -0.0323, -0.0682, -0.0735,\n",
       "           -0.1337,  0.0078,  0.0365, -0.0043, -0.0544, -0.0863,  0.0590,  0.0863,\n",
       "            0.0249, -0.0215,  0.0356,  0.0384, -0.3699, -0.0259, -0.1393, -0.0664,\n",
       "           -0.0511, -0.0314, -0.0766, -0.0303,  0.0093,  0.0510,  0.0393,  0.0501,\n",
       "           -0.0651, -0.0358, -0.1172,  0.0187,  0.0326, -0.0488,  0.0374, -0.0330,\n",
       "            0.0376, -0.1561,  0.0191,  0.0039, -0.0786,  0.0891, -0.0581,  0.0484,\n",
       "           -0.0199, -0.0546, -0.0248,  0.0346,  0.0253,  0.0636,  0.0574,  0.0708,\n",
       "            0.0623, -0.0044, -0.0768,  0.0563, -0.0628, -0.0556, -0.0212, -0.0129,\n",
       "           -0.0508, -0.0230, -0.0353, -0.0342, -0.0324,  0.0096, -0.0623,  0.0709,\n",
       "           -0.0715, -0.0280, -0.0543, -0.0341,  0.0451, -0.0484, -0.0585,  0.0715,\n",
       "            0.0209,  0.0871,  0.2195, -0.0227, -0.0669,  0.0282, -0.0359,  0.0356,\n",
       "            0.0367,  0.1481, -0.2374,  0.0547, -0.0268, -0.0562, -0.0772, -0.0386,\n",
       "            0.0357,  0.0745, -0.0999,  0.0601, -0.0140, -0.0357, -0.1283, -0.0227,\n",
       "           -0.2031,  0.0393,  0.0379,  0.0851, -0.1144, -0.0085, -0.0629,  0.0710,\n",
       "           -0.0716,  0.0482,  0.0357,  0.0616, -0.0207, -0.0284, -0.0632, -0.0286,\n",
       "           -0.0343, -0.0289, -0.0533, -0.0336, -0.0128, -0.0543, -0.0542,  0.0527,\n",
       "            0.0330,  0.1840, -0.0589,  0.0295, -0.0548, -0.0171,  0.0336, -0.1637,\n",
       "           -0.0373,  0.0350, -0.0476,  0.0834,  0.0014,  0.0588,  0.0290,  0.3475,\n",
       "           -0.0699, -0.0659, -0.0758,  0.1416, -0.0480,  0.0569, -0.0619, -0.0243,\n",
       "           -0.0604, -0.0315, -0.0565, -0.0787,  0.0011, -0.0318,  0.0292,  0.0587,\n",
       "           -0.0633,  0.0913,  0.1224,  0.1098, -0.0579,  0.0628, -0.0609, -0.0593,\n",
       "            0.0670,  0.0307, -0.0171,  0.0154, -0.0254,  0.1653, -0.0080,  0.0619,\n",
       "           -0.0458, -0.0244, -0.0293, -0.0594, -0.0678, -0.0313,  0.0694,  0.0511,\n",
       "           -0.0774, -0.1233,  0.0343,  0.0599,  0.0428,  0.0570,  0.0368, -0.0616,\n",
       "           -0.0401,  0.1009, -0.0657,  0.0187,  0.0060, -0.2850, -0.2170,  0.0702,\n",
       "            0.0460, -0.0359,  0.0248, -0.0294,  0.0036, -0.0562,  0.0390,  0.0690,\n",
       "           -0.0633, -0.0677, -0.0615,  0.0599,  0.0380, -0.0368, -0.2120, -0.0024,\n",
       "           -0.0662, -0.0359,  0.0642,  0.0581,  0.0290,  0.1829,  0.1041,  0.0540,\n",
       "            0.0304, -0.0476,  0.0763,  0.0931, -0.2399, -0.0035, -0.0561, -0.0308,\n",
       "            0.0401, -0.0062, -0.0363,  0.0663, -0.0577,  0.0771, -0.4149,  0.0071,\n",
       "           -0.4899, -0.0407,  0.1344,  0.0386,  0.0150, -0.0267,  0.0292,  0.2583,\n",
       "           -0.0581,  0.0566,  0.0853,  0.0967, -0.0687,  0.2510, -0.1180,  0.0905,\n",
       "           -0.0179,  0.0608, -0.0042,  0.1740, -0.0549, -0.0176, -0.2851,  0.0641,\n",
       "           -0.0666,  0.1667, -0.2111, -0.0390, -0.0566,  0.0581, -0.0540,  0.1476],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0658,  0.0072,  0.0230,  ..., -0.0465,  0.0447,  0.0351],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0505, -0.0492, -0.0505,  0.0496,  0.0502,  0.0497, -0.0493, -0.0503,\n",
       "            0.0485, -0.0498,  0.0492,  0.0499,  0.0498,  0.0496,  0.0497,  0.0493,\n",
       "           -0.0502,  0.0434, -0.0476, -0.0472,  0.0465,  0.0496, -0.0447, -0.0498,\n",
       "            0.0501,  0.0501,  0.0500,  0.0494, -0.0491, -0.0520,  0.0499, -0.0495,\n",
       "            0.0496, -0.0492,  0.0494,  0.0492,  0.0494, -0.0511, -0.0529,  0.0507,\n",
       "           -0.0502,  0.0426, -0.0584,  0.0496,  0.0499, -0.0499,  0.0500, -0.0501,\n",
       "           -0.0509, -0.0541, -0.0449, -0.0502,  0.0498, -0.0595, -0.0495,  0.0500,\n",
       "            0.0508, -0.0496, -0.0480,  0.0530,  0.0502, -0.0485,  0.0496,  0.0490,\n",
       "           -0.0485, -0.0498,  0.0493, -0.0498,  0.0490,  0.0494,  0.0499, -0.0566,\n",
       "            0.0495,  0.0504, -0.0490, -0.0495, -0.0492,  0.0502, -0.0511, -0.0500,\n",
       "           -0.0491, -0.0503, -0.0497, -0.0500, -0.0498,  0.0493,  0.0496, -0.0495,\n",
       "           -0.0495,  0.0496,  0.0489,  0.0514,  0.0468,  0.0509, -0.0491,  0.0498,\n",
       "           -0.0495,  0.0494,  0.0466, -0.0405,  0.0515,  0.0497,  0.0510,  0.0502,\n",
       "            0.0195, -0.0513, -0.0504,  0.0498,  0.0498,  0.0490,  0.0491, -0.0493,\n",
       "           -0.0491,  0.0493,  0.0501,  0.0515,  0.0490, -0.0495, -0.0499, -0.0498,\n",
       "           -0.0495,  0.0496, -0.0501, -0.0493, -0.0494, -0.0497,  0.0496, -0.0493,\n",
       "            0.0501,  0.0504,  0.0498,  0.0513, -0.0499, -0.0497,  0.0434, -0.0488,\n",
       "            0.0510, -0.0510,  0.0491, -0.0521,  0.0496,  0.0494, -0.0484, -0.0510,\n",
       "           -0.0507, -0.0501,  0.0509, -0.0496,  0.0500, -0.0498, -0.0484,  0.0492,\n",
       "            0.0500,  0.0502,  0.0514,  0.0500, -0.0498,  0.0499, -0.0496, -0.0499,\n",
       "            0.0494, -0.0499,  0.0497, -0.0503, -0.0496, -0.0499, -0.0483,  0.0493,\n",
       "            0.0500, -0.0497, -0.0501, -0.0497, -0.0498,  0.0495, -0.0500, -0.0475,\n",
       "            0.0481,  0.0503,  0.0502,  0.0504, -0.0503, -0.0502,  0.0499, -0.0492,\n",
       "           -0.0762,  0.0496,  0.0503,  0.0502,  0.0498,  0.0517, -0.0500, -0.0497,\n",
       "           -0.0565,  0.0503,  0.0505, -0.0493,  0.0495,  0.0518,  0.0497,  0.0499,\n",
       "            0.0492,  0.0499, -0.0456,  0.0503,  0.0496,  0.0499,  0.0436, -0.0479,\n",
       "            0.0606,  0.0415,  0.0497, -0.0497, -0.0503,  0.0484,  0.0495,  0.0487,\n",
       "            0.0496,  0.0497, -0.0495,  0.0503,  0.0493, -0.0497, -0.0492, -0.0470,\n",
       "            0.0499,  0.0476, -0.0486,  0.0497, -0.0562, -0.0490,  0.0498, -0.0496,\n",
       "           -0.0479,  0.0504,  0.0501,  0.0492, -0.0498, -0.0482, -0.0498, -0.0498,\n",
       "            0.0495, -0.0500,  0.0492,  0.0500,  0.0497, -0.0492, -0.0500,  0.0409,\n",
       "            0.0454, -0.0511,  0.0496, -0.0509, -0.0499, -0.0452,  0.0502,  0.0501,\n",
       "            0.0505, -0.0495,  0.0496,  0.0497,  0.0483, -0.0488, -0.0496, -0.0493,\n",
       "           -0.0498, -0.0495, -0.0502, -0.0495,  0.0497,  0.0500,  0.0495, -0.0477,\n",
       "           -0.0499, -0.0490,  0.0534,  0.0499,  0.0492, -0.0496,  0.0493, -0.0492,\n",
       "            0.0500, -0.0506,  0.0495,  0.0642, -0.0505,  0.0484, -0.0494, -0.0516,\n",
       "            0.0489, -0.0496, -0.0507, -0.0514,  0.0500,  0.0498,  0.0494,  0.0501,\n",
       "            0.0500,  0.0480, -0.0510,  0.0497, -0.0502, -0.0500,  0.0489, -0.0498,\n",
       "           -0.0489,  0.0493, -0.0508, -0.0494, -0.0497, -0.0489, -0.0499,  0.0500,\n",
       "           -0.0498, -0.0497, -0.0494, -0.0498,  0.0507, -0.0496, -0.0499,  0.0499,\n",
       "            0.0471,  0.0379,  0.0512, -0.0489, -0.0506,  0.0490, -0.0497,  0.0493,\n",
       "            0.0499,  0.0528,  0.0498,  0.0497, -0.0497, -0.0503, -0.0523, -0.0495,\n",
       "            0.0491,  0.0495,  0.0500,  0.0498,  0.0476, -0.0499,  0.0483, -0.0495,\n",
       "           -0.0501,  0.0488,  0.0491,  0.0480,  0.0486, -0.0490, -0.0497,  0.0483,\n",
       "           -0.0489, -0.0518,  0.0491,  0.0506, -0.0496, -0.0498, -0.0500, -0.0491,\n",
       "           -0.0495, -0.0497, -0.0495, -0.0494, -0.0529, -0.0498, -0.0511, -0.0485,\n",
       "            0.0500,  0.0503, -0.0502,  0.0490, -0.0496, -0.0504,  0.0498, -0.0465,\n",
       "           -0.0498,  0.0494, -0.0502,  0.0516,  0.0491,  0.0499,  0.0498, -0.0426,\n",
       "           -0.0501,  0.0499, -0.0533, -0.0494, -0.0487,  0.0499, -0.0501, -0.0495,\n",
       "           -0.0505, -0.0488, -0.0494, -0.0501, -0.0378, -0.0496,  0.0494,  0.0501,\n",
       "           -0.0499,  0.0507,  0.0506,  0.0491, -0.0496,  0.0495, -0.0498, -0.0492,\n",
       "            0.0501,  0.0436, -0.0512,  0.0498, -0.0495, -0.0491,  0.0495,  0.0499,\n",
       "           -0.0478, -0.0493, -0.0495, -0.0492, -0.0507, -0.0496,  0.0507,  0.0495,\n",
       "           -0.0499, -0.0533,  0.0496,  0.0505,  0.0497,  0.0498,  0.0496, -0.0500,\n",
       "           -0.0497, -0.0495, -0.0504,  0.0494,  0.0501, -0.0523, -0.0501,  0.0511,\n",
       "            0.0499, -0.0495,  0.0498, -0.0497,  0.0495, -0.0501,  0.0497,  0.0500,\n",
       "           -0.0500, -0.0497, -0.0502,  0.0499,  0.0499, -0.0494,  0.0510,  0.0503,\n",
       "            0.0479, -0.0500,  0.0512,  0.0497,  0.0494, -0.0485,  0.0582,  0.0494,\n",
       "            0.0492, -0.0498,  0.0502,  0.0503,  0.0500, -0.0497, -0.0493, -0.0491,\n",
       "            0.0497, -0.0506, -0.0492,  0.0504, -0.0501,  0.0552, -0.0515,  0.0489,\n",
       "           -0.0524, -0.0501,  0.0508,  0.0494,  0.0300, -0.0496,  0.0495,  0.0529,\n",
       "           -0.0500,  0.0495, -0.0507,  0.0494, -0.0495, -0.0498, -0.0493,  0.0688,\n",
       "           -0.0493,  0.0500, -0.0538,  0.0543, -0.0498, -0.0535,  0.0489,  0.0500,\n",
       "           -0.0503, -0.0487,  0.0488, -0.0497, -0.0499,  0.0509, -0.0497,  0.0515],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.5599, -0.0485,  0.4184,  0.0533, -0.0522, -0.0700, -0.1602, -0.0531,\n",
       "           -0.4726, -0.0618, -0.0625,  0.0380, -0.0461,  0.1739,  0.0678, -0.0624,\n",
       "           -0.1610,  0.0203,  0.0166, -0.0443, -0.5000,  0.5002,  0.0225,  0.0224,\n",
       "           -0.0596, -0.0672, -0.0480, -0.0494, -0.0395, -0.3570, -0.0122, -0.0657,\n",
       "           -0.0477,  0.1781,  0.0416,  0.0863, -0.1220,  0.0227,  0.3115, -0.0547,\n",
       "           -0.2304,  0.4692, -0.0502, -0.0536, -0.5189,  0.0061,  0.0188, -0.0636,\n",
       "           -0.0239, -0.0618, -0.0509, -0.1202, -0.5617, -0.0484,  0.0498, -0.0507,\n",
       "            0.4903, -0.0506,  0.0470, -0.0466,  0.0376,  0.5618, -0.0456, -0.0492,\n",
       "           -0.0512,  0.0102, -0.0257,  0.3344, -0.0515,  0.3786, -0.1988,  0.0030,\n",
       "           -0.0488,  0.0384,  0.1243, -0.0517, -0.0019, -0.0474, -0.0600,  0.1699,\n",
       "           -0.0504, -0.0677,  0.0333,  0.0660, -0.1867, -0.0467, -0.0468, -0.0547,\n",
       "           -0.0522, -0.0526,  0.0396, -0.0508, -0.2113, -0.0471,  0.3095, -0.0518,\n",
       "            0.0767, -0.0034,  0.1380, -0.0493], device='mps:0',\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0535, -0.0594, -0.0536,  0.0471,  0.0505,  0.0397, -0.0472, -0.0480,\n",
       "            0.0533, -0.0485,  0.0571,  0.0416,  0.0529,  0.0533,  0.0545,  0.0551,\n",
       "           -0.0536,  0.0333, -0.0381, -0.0376,  0.0645,  0.0454, -0.0510, -0.0485,\n",
       "            0.1028,  0.0565,  0.0284,  0.0572, -0.0524, -0.0493,  0.0440, -0.0551,\n",
       "            0.0495, -0.0782,  0.0442,  0.0458,  0.0480, -0.0591,  0.0238,  0.0503,\n",
       "           -0.0786,  0.0420, -0.0603,  0.0468, -0.0069, -0.0555,  0.0462, -0.0145,\n",
       "           -0.0488, -0.1137, -0.0436, -0.0709,  0.0546,  0.4130, -0.0420,  0.0416,\n",
       "            0.0223, -0.0527,  0.0496,  0.0420,  0.0461, -0.0688,  0.0460,  0.0476,\n",
       "           -0.0451, -0.0562,  0.0708, -0.0366,  0.0629,  0.0372,  0.0510, -0.0357,\n",
       "            0.0733,  0.0500, -0.0530, -0.0992, -0.0473,  0.0459, -0.0212, -0.0575,\n",
       "           -0.0450, -0.0621, -0.0476, -0.0455, -0.0508,  0.0460,  0.0446, -0.0517,\n",
       "           -0.0413,  0.0489,  0.0417,  0.0173,  0.0493,  0.0677, -0.0355,  0.0451,\n",
       "           -0.0459,  0.0412,  0.0420, -0.0354,  0.1026,  0.0808,  0.0435,  0.0507,\n",
       "           -0.1874, -0.0528, -0.0478,  0.0525,  0.0544,  0.0495, -0.0467, -0.0285,\n",
       "           -0.0888,  0.0631,  0.0586,  0.1331,  0.0518, -0.0400, -0.0420, -0.0390,\n",
       "           -0.0522,  0.0405, -0.0666, -0.0407, -0.0584, -0.0550,  0.0416, -0.0396,\n",
       "            0.0522, -0.0712,  0.0552,  0.1139, -0.0552, -0.0500,  0.5147, -0.0687,\n",
       "            0.0462, -0.0509,  0.0445, -0.1046,  0.0601,  0.0454, -0.0450,  0.2654,\n",
       "           -0.0476, -0.0728,  0.0458, -0.0579,  0.0216, -0.0425, -0.0511,  0.0654,\n",
       "            0.0587,  0.0601, -0.0256,  0.0497, -0.0477,  0.0313, -0.0545, -0.0480,\n",
       "            0.0440, -0.0530,  0.0485, -0.0451, -0.0523, -0.0402,  0.3101,  0.0460,\n",
       "            0.0509, -0.0508, -0.0484, -0.0441, -0.0575,  0.0669, -0.0668, -0.0399,\n",
       "            0.0264,  0.0432,  0.0594,  0.0524,  0.0359, -0.0681,  0.0355, -0.0454,\n",
       "           -0.0499,  0.0440,  0.0474,  0.0683,  0.0327,  0.0628, -0.0518, -0.0419,\n",
       "           -0.0252,  0.0434,  0.0499, -0.0489,  0.0488,  0.0540,  0.0589,  0.0776,\n",
       "            0.0498,  0.0693,  0.0570,  0.0481,  0.0589,  0.0581,  0.0502, -0.1512,\n",
       "            0.0123, -0.3581,  0.0475, -0.0412, -0.1058,  0.0388,  0.0445,  0.0556,\n",
       "           -0.0061,  0.0450, -0.0496,  0.0567,  0.0429, -0.0454, -0.0602, -0.0334,\n",
       "            0.0484, -0.0846, -0.0485,  0.0599,  0.0836, -0.0336,  0.0505, -0.0486,\n",
       "           -0.0181,  0.0480,  0.0399,  0.0528, -0.0355, -0.0506, -0.0432, -0.0538,\n",
       "            0.0439, -0.0561,  0.0490,  0.0491,  0.0288, -0.0574, -0.0488, -0.2868,\n",
       "            0.0624, -0.1389,  0.0434,  0.0623, -0.0442, -0.0533,  0.0750,  0.0632,\n",
       "            0.0519, -0.0391,  0.0568,  0.0554, -0.1244, -0.0510, -0.0377, -0.0701,\n",
       "           -0.0159, -0.0497,  0.0338, -0.0483,  0.0471,  0.0213,  0.0490,  0.0039,\n",
       "           -0.0452, -0.0629, -0.0579,  0.0534,  0.0511, -0.0576,  0.0469, -0.0430,\n",
       "            0.0445,  0.0569,  0.0535, -0.0344, -0.0462,  0.0392, -0.0710, -0.0499,\n",
       "            0.0417, -0.0537, -0.0587,  0.5312,  0.0430,  0.0508,  0.0612,  0.0652,\n",
       "            0.0508,  0.0314, -0.0504,  0.0459, -0.0482, -0.0454,  0.0749, -0.0372,\n",
       "           -0.0500,  0.0670,  0.0278, -0.0399, -0.0495, -0.0617, -0.0528,  0.0758,\n",
       "           -0.0466, -0.0434, -0.0356, -0.0450,  0.0493, -0.0492, -0.0509,  0.0604,\n",
       "            0.0377,  0.0649,  0.0012, -0.0449, -0.0419,  0.0507, -0.0554,  0.0459,\n",
       "            0.0771,  0.0341,  0.0512,  0.0514, -0.0434, -0.0704, -0.0669, -0.0518,\n",
       "            0.0481,  0.0220,  0.0892,  0.0503,  0.0459, -0.0408,  0.0063, -0.0446,\n",
       "           -0.0311,  0.0382,  0.0574,  0.0535, -0.1013, -0.0330, -0.0376,  0.0372,\n",
       "           -0.0570,  0.0462,  0.0531,  0.0643, -0.0428, -0.0526,  0.0054, -0.0443,\n",
       "           -0.0427, -0.0583, -0.0444, -0.0540, -0.0788, -0.0417,  0.0522,  0.0067,\n",
       "            0.0457,  0.0532, -0.0499, -0.0136, -0.0617, -0.0468,  0.0416,  0.1836,\n",
       "           -0.0485,  0.0404, -0.0535,  0.0145,  0.0376,  0.0477,  0.0384, -0.0646,\n",
       "           -0.0552,  0.0463,  0.0828, -0.0556, -0.0497,  0.0555, -0.0514, -0.0487,\n",
       "           -0.0454, -0.0575, -0.0534, -0.0954,  0.1112, -0.0465, -0.0154,  0.1096,\n",
       "           -0.0422,  0.0575,  0.0351,  0.0625, -0.0723,  0.0514, -0.0429, -0.0535,\n",
       "            0.0365, -0.4624,  0.2078,  0.0482, -0.0366, -0.0572,  0.0371,  0.0579,\n",
       "           -0.0904, -0.0301, -0.0548, -0.0509, -0.0219, -0.0521,  0.0525,  0.0560,\n",
       "           -0.1001, -0.0710,  0.0561,  0.0586,  0.0459,  0.0478,  0.0428, -0.0445,\n",
       "           -0.0453, -0.0467, -0.0846,  0.0390,  0.0476, -0.0528, -0.0958,  0.0520,\n",
       "            0.0526, -0.0567,  0.0557, -0.0116,  0.0698, -0.0486,  0.0540,  0.0773,\n",
       "           -0.0700, -0.0593, -0.0564,  0.0303,  0.0408, -0.0524, -0.0770,  0.0579,\n",
       "           -0.0978, -0.0483,  0.0490,  0.0516, -0.0016,  0.0439, -0.0168,  0.0452,\n",
       "            0.0445, -0.0504,  0.0587,  0.0477,  0.0426, -0.0384, -0.0517, -0.0489,\n",
       "            0.0525,  0.0035, -0.0406,  0.0471, -0.0466,  0.0168, -0.0670,  0.0506,\n",
       "           -0.0343, -0.0617,  0.0826,  0.0468,  0.0516, -0.0495,  0.0482,  0.0404,\n",
       "           -0.0535,  0.0492, -0.0633,  0.0525, -0.0417, -0.0442, -0.0468,  0.0423,\n",
       "           -0.0628,  0.0497, -0.0557,  0.0378, -0.0470,  0.0528, -0.0335,  0.0878,\n",
       "           -0.0611, -0.0517,  0.0479, -0.0592, -0.0528,  0.0394, -0.0520,  0.0470],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-3.6403e-01,  1.3591e-01,  6.6831e-01, -1.4459e-01,  2.8761e-01,\n",
       "           -3.7268e-01,  2.0025e-01,  1.1097e-01, -1.0403e-01, -2.4879e-01,\n",
       "            2.3094e-01,  3.3476e-01, -8.9909e-02,  4.4747e-01, -4.0319e-01,\n",
       "           -1.1412e-01,  5.6850e-01,  1.2837e-01, -2.8832e-02, -7.9325e-03,\n",
       "           -7.1843e-02, -2.7135e-01,  5.5413e-02, -3.6196e-01,  6.7666e-01,\n",
       "            6.3484e-01,  1.1498e-03, -3.1807e-02, -5.2028e-01, -1.6174e-02,\n",
       "            5.4184e-01,  4.5720e-01, -4.1609e-01, -4.9931e-02,  1.6261e-01,\n",
       "            2.0437e-01, -3.1167e-02,  2.7358e-01,  4.3472e-01, -2.6368e-02,\n",
       "            1.2506e-01,  6.3792e-02, -3.7436e-01, -1.1259e-01,  4.6707e-01,\n",
       "           -4.2223e-01,  7.3277e-01, -3.7840e-01,  6.5760e-01, -1.6832e-01,\n",
       "            1.3921e-01, -7.4403e-02,  1.4490e-01,  9.1013e-02, -3.8972e-01,\n",
       "           -3.9641e-02,  3.6138e-01, -1.3087e-01, -6.3710e-02,  1.8579e-01,\n",
       "            5.0025e-01,  1.6983e-01, -1.3511e-01,  6.3057e-02, -2.4132e-01,\n",
       "           -2.2039e-01, -4.0473e-01,  1.0813e-01,  3.1948e-01, -4.6686e-01,\n",
       "           -1.8724e-02, -2.6656e-01, -3.7414e-01,  5.4194e-01, -9.5864e-02,\n",
       "            5.2040e-01, -4.8192e-01,  3.1716e-01, -2.9921e-01,  3.0062e-01,\n",
       "           -1.2637e-01,  5.5287e-01, -4.4030e-01,  6.3393e-01,  4.6930e-01,\n",
       "            2.4994e-01, -3.7315e-01,  7.1329e-02,  4.8939e-01,  4.8734e-01,\n",
       "            1.8696e-02,  1.4475e-01, -5.8109e-02,  6.9315e-01,  1.2117e-02,\n",
       "           -4.1200e-01, -7.1830e-02, -4.2837e-01,  2.5693e-02,  3.8989e-01,\n",
       "            2.8278e-01,  1.2634e-01,  6.8607e-01,  4.9382e-01,  5.7619e-01,\n",
       "           -4.5067e-01,  6.1020e-01, -4.3106e-01, -3.7969e-01, -4.4196e-01,\n",
       "           -2.3780e-01,  4.5737e-01,  1.7288e-01, -3.0890e-01,  4.9242e-02,\n",
       "            5.6760e-01,  1.0151e-01,  8.7127e-03, -1.2433e-01, -4.4018e-01,\n",
       "           -3.2594e-01,  3.7539e-01,  6.4598e-01, -1.3044e-01, -1.9119e-01,\n",
       "            6.2687e-01, -1.5615e-02,  6.3996e-01,  5.2893e-01,  5.7630e-01,\n",
       "            4.6087e-01,  4.6570e-01,  4.0420e-01,  4.7897e-01, -2.7777e-01,\n",
       "            4.1315e-01, -3.3038e-01, -4.4496e-01,  2.1276e-02,  2.3143e-01,\n",
       "            4.7329e-01, -5.2764e-01,  4.4130e-02,  4.3582e-01, -9.8243e-02,\n",
       "            1.5836e-01, -1.2417e-01, -1.1997e-01,  5.8058e-01, -4.9394e-01,\n",
       "            6.9510e-01, -4.8765e-01,  1.2047e-01,  3.6334e-01, -3.5036e-01,\n",
       "            1.7622e-01,  1.7930e-01,  1.0385e-01, -4.4193e-01, -4.8951e-01,\n",
       "            2.1089e-02,  2.1097e-01, -5.1683e-01,  2.3583e-01, -1.7665e-01,\n",
       "            4.1618e-01, -3.1500e-01, -1.4321e-02,  4.8781e-01, -5.1560e-01,\n",
       "           -4.3791e-01, -3.8447e-01,  5.0693e-01,  4.0413e-01, -4.6663e-01,\n",
       "           -2.0423e-02,  1.0025e-01, -3.5285e-01,  5.3860e-01,  1.0102e-02,\n",
       "           -4.4848e-01,  2.2009e-01,  6.9987e-01,  3.6786e-01,  7.3965e-01,\n",
       "            3.4985e-01, -3.3517e-01,  3.6279e-01, -2.5288e-01,  3.0098e-01,\n",
       "            2.8079e-01,  6.7953e-01,  5.7066e-02, -2.0517e-01,  2.4745e-02,\n",
       "           -7.5548e-02, -1.9380e-01,  1.8076e-01, -4.2940e-01,  6.1476e-01,\n",
       "           -2.0649e-01,  2.0421e-01,  2.9967e-02,  6.0493e-02, -3.3251e-01,\n",
       "           -4.1415e-01,  5.1667e-02, -1.3467e-01, -6.4036e-02,  2.1617e-01,\n",
       "           -4.0429e-01,  2.3277e-01, -2.6089e-01, -3.9561e-01, -2.9974e-02,\n",
       "           -2.7772e-01, -4.9705e-01, -3.7937e-01, -2.3526e-01,  4.0737e-01,\n",
       "           -9.9424e-02,  1.2105e-01, -4.2287e-01, -1.0562e-01,  5.1023e-01,\n",
       "           -3.5799e-02,  2.3088e-01,  3.5222e-02,  6.3035e-01, -2.0626e-01,\n",
       "            1.8959e-02,  1.2502e-01,  1.2150e-01,  5.3957e-01, -3.7019e-01,\n",
       "           -4.1651e-01,  5.9835e-01,  4.9452e-03,  1.3925e-01,  5.9423e-01,\n",
       "           -7.7954e-02,  6.4237e-01, -2.3321e-01, -2.9532e-01,  3.7660e-01,\n",
       "            3.6261e-01,  2.1307e-01, -2.2597e-02,  2.8762e-02, -3.8609e-01,\n",
       "           -4.7183e-01,  3.2995e-01, -3.8904e-01,  1.7396e-01,  6.5850e-01,\n",
       "            3.0597e-01,  5.4203e-01, -4.4178e-01, -2.3026e-01,  6.2795e-01,\n",
       "           -2.6554e-01, -2.7073e-01,  1.3153e-01, -1.1125e-01,  6.4027e-01,\n",
       "           -6.5655e-02, -1.9870e-01, -5.3109e-01, -3.4154e-01,  3.3833e-01,\n",
       "           -4.6163e-01, -2.4656e-01,  5.4299e-01, -2.1874e-01, -2.5049e-01,\n",
       "           -4.1664e-01, -2.5601e-01, -1.3117e-01,  5.8437e-01, -2.4588e-02,\n",
       "            3.8242e-01,  4.2974e-02,  9.4170e-02,  4.1537e-01, -2.2192e-01,\n",
       "            1.4465e-01,  1.8421e-01, -4.2524e-01, -1.9270e-01, -2.9875e-01,\n",
       "            1.4981e-01,  6.1356e-01,  3.2049e-01,  3.3246e-02,  5.4931e-01,\n",
       "            2.6972e-01,  3.9920e-01, -3.4526e-01,  5.9295e-01,  1.6268e-01,\n",
       "           -3.3397e-01, -3.3976e-01, -3.5322e-01, -3.9473e-01, -4.7597e-01,\n",
       "            1.1908e-02,  5.7077e-01,  8.9204e-02, -2.2283e-01, -3.1930e-03,\n",
       "           -4.2628e-01, -3.0066e-01, -4.9359e-01,  8.8802e-02,  3.3481e-01,\n",
       "           -4.8436e-01, -4.0834e-01, -4.3927e-01,  2.2349e-01, -4.9515e-01,\n",
       "           -4.1963e-02,  3.3735e-01,  6.7129e-01, -3.5452e-01, -1.3181e-01,\n",
       "           -3.3092e-01,  3.2789e-02,  1.9488e-01, -2.4841e-03,  4.8954e-01,\n",
       "            4.2861e-01, -4.8605e-01, -3.8698e-01,  5.5103e-01,  6.5743e-01,\n",
       "           -6.1632e-02,  2.3662e-01, -3.6466e-01,  5.7411e-01,  2.8538e-02,\n",
       "           -2.1215e-01, -4.4383e-01,  6.5312e-01, -4.8674e-01,  2.8649e-01,\n",
       "           -4.2304e-02, -2.3340e-01, -3.3915e-01, -2.9474e-01,  6.4219e-01,\n",
       "            4.1233e-01,  2.4053e-02, -2.1723e-01,  3.3559e-01, -2.0034e-01,\n",
       "            2.2420e-01, -1.8324e-01, -2.6264e-01, -1.7074e-01, -1.8735e-01,\n",
       "           -1.2017e-01, -2.7367e-01, -5.2634e-01, -3.0945e-02,  4.6289e-01,\n",
       "           -3.3805e-01,  6.0497e-01, -4.8235e-01, -2.2914e-01,  1.7633e-01,\n",
       "           -7.3767e-02, -1.5467e-01,  1.1573e-02, -4.9714e-01,  7.0038e-02,\n",
       "            1.4962e-01, -3.7612e-01, -2.5840e-01,  7.0341e-01,  2.9824e-01,\n",
       "            4.9429e-01,  2.2410e-01, -1.0035e-01,  9.5808e-02,  3.2995e-01,\n",
       "            1.6035e-01,  5.1748e-01, -3.4169e-01, -1.6953e-02,  1.4345e-01,\n",
       "            2.1726e-01,  2.2054e-01,  7.6953e-03, -4.2381e-01,  3.9852e-03,\n",
       "            5.4122e-01,  2.0704e-01,  2.3260e-01, -2.3696e-01,  3.3991e-01,\n",
       "           -2.4562e-02, -7.5614e-03,  8.6379e-02,  5.4980e-01,  1.2581e-01,\n",
       "            3.8663e-01, -2.0331e-01, -5.2630e-01, -2.0797e-01, -2.1876e-01,\n",
       "            2.4275e-01, -4.0940e-01,  6.0022e-01, -6.7634e-02,  1.1169e-01,\n",
       "            5.1792e-01,  7.4684e-02,  3.7722e-01, -1.8014e-01,  3.8921e-01,\n",
       "            6.5312e-01, -1.7294e-01, -3.4036e-01,  3.2734e-02, -2.4179e-02,\n",
       "            5.8838e-01, -5.3118e-02,  2.9713e-01,  9.4036e-02,  5.5956e-01,\n",
       "           -8.4936e-03, -2.4013e-01,  3.1527e-01, -4.9934e-01,  5.6756e-01,\n",
       "           -5.0162e-01, -2.0813e-01,  2.5453e-01,  6.3925e-01,  5.6509e-01,\n",
       "           -2.8011e-01, -3.1255e-01, -3.9224e-01,  5.5669e-01,  4.0654e-01,\n",
       "            4.3335e-01,  5.9388e-01, -5.6806e-02, -4.5263e-02,  3.3497e-01,\n",
       "            3.3256e-01,  6.3991e-01,  3.7876e-02,  6.1317e-04, -2.4679e-01,\n",
       "            4.3946e-01, -1.1495e-01, -4.0185e-02,  6.6809e-01,  1.7978e-01,\n",
       "           -2.2570e-01, -2.0197e-01,  2.1714e-02, -3.9621e-01, -3.2986e-02,\n",
       "           -2.7680e-01,  3.3490e-01, -4.6149e-01, -1.7915e-01,  5.2038e-02,\n",
       "            4.2331e-01,  5.1224e-02, -2.8041e-01, -2.9975e-01, -5.2279e-01,\n",
       "            8.3907e-02,  6.6876e-01,  5.5743e-01,  5.2528e-01, -5.6103e-01,\n",
       "            4.1380e-01, -4.5191e-01,  5.0553e-01,  5.9373e-01,  5.3801e-01,\n",
       "           -3.9353e-01,  5.7073e-02, -1.6720e-02,  5.8345e-01,  3.4126e-01,\n",
       "            5.5430e-01,  1.3878e-01, -1.5506e-01, -2.3898e-02,  6.3835e-01,\n",
       "            1.4223e-02, -2.3020e-01,  2.6009e-01,  3.6422e-01,  6.5260e-02,\n",
       "            1.1101e-01, -2.3248e-01,  1.4078e-01, -4.4417e-01,  6.3923e-01,\n",
       "            1.6641e-01,  2.1986e-01,  6.4868e-01,  2.5347e-01, -2.6882e-01,\n",
       "           -5.2307e-01,  5.6219e-01], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0449, -0.0489, -0.1972, -0.0475,  0.0153, -0.0974, -0.1796, -0.0364,\n",
       "           -0.1177, -0.0107,  0.2540, -0.1158,  0.0387,  0.1274, -0.0131, -0.1309,\n",
       "           -0.2614, -0.5144,  0.2031,  0.4395, -0.3848, -0.0564,  0.4442,  0.2913,\n",
       "           -0.0377,  0.4641, -0.0582, -0.0365,  0.2304,  0.4061, -0.1331, -0.2795,\n",
       "           -0.0894,  0.2687,  0.0145,  0.2208, -0.0059, -0.0174,  0.3917, -0.0356,\n",
       "           -0.0600, -0.4138,  0.4565, -0.0366,  0.4350,  0.3241, -0.0261, -0.1310,\n",
       "           -0.5471,  0.0967,  0.4535, -0.0067,  0.0739, -0.4111,  0.1389, -0.0590,\n",
       "            0.1702, -0.0637,  0.4626,  0.5819,  0.1891, -0.5701, -0.0364,  0.0083,\n",
       "            0.2699, -0.0095, -0.3702, -0.1378,  0.0128, -0.2911, -0.0248,  0.4848,\n",
       "           -0.1719,  0.4619,  0.1377, -0.0629,  0.3417,  0.1378, -0.5800, -0.1007,\n",
       "            0.3286, -0.4770,  0.0070, -0.1667, -0.2729, -0.2568, -0.1580, -0.0794,\n",
       "           -0.2393,  0.2311, -0.1125,  0.5720,  0.5420,  0.3563, -0.5606,  0.1773,\n",
       "           -0.0319, -0.1846,  0.1836,  0.1662,  0.2947,  0.0578,  0.2317,  0.3197,\n",
       "           -0.5272,  0.4057, -0.5458, -0.2117, -0.0931, -0.1560,  0.1415, -0.4516,\n",
       "           -0.2336, -0.4826, -0.0020,  0.4321,  0.2115,  0.0092, -0.2115,  0.0572,\n",
       "            0.0850,  0.2117, -0.1025, -0.2307,  0.0530, -0.2217, -0.0369, -0.3612,\n",
       "            0.1269,  0.5412,  0.1240,  0.3802, -0.0810, -0.0407, -0.5571, -0.0266,\n",
       "           -0.2056,  0.4188,  0.0528, -0.6275,  0.4281, -0.1644,  0.0018, -0.3757,\n",
       "           -0.0023, -0.1072,  0.5468,  0.1260,  0.5118,  0.0075, -0.5578, -0.0882,\n",
       "            0.0932,  0.2954, -0.1618, -0.0766, -0.0977,  0.1564,  0.0841, -0.1657,\n",
       "            0.0284,  0.1657, -0.1226, -0.0914,  0.0755, -0.1597,  0.4782,  0.0100,\n",
       "            0.1039,  0.1058,  0.2405,  0.0052, -0.0419, -0.0409, -0.1526,  0.4162,\n",
       "           -0.0097, -0.0319,  0.2844, -0.0277,  0.4365, -0.2799,  0.2641, -0.0958,\n",
       "           -0.5785, -0.1253, -0.0218,  0.1815, -0.4435,  0.5357, -0.1490, -0.1639,\n",
       "           -0.4769,  0.4001,  0.4518,  0.0830,  0.0898,  0.4938, -0.2046, -0.0768,\n",
       "           -0.2272,  0.1179, -0.6068,  0.1396, -0.0740, -0.3587, -0.3084,  0.4991,\n",
       "           -0.2337, -0.5471, -0.2240,  0.2771,  0.1595, -0.3108, -0.0261, -0.1165,\n",
       "           -0.1074, -0.1038,  0.0905,  0.2651, -0.1678,  0.0499,  0.0721,  0.4053,\n",
       "           -0.2261, -0.4837, -0.3597,  0.0144, -0.5717,  0.3232, -0.0014, -0.1281,\n",
       "           -0.5949,  0.3877,  0.1393, -0.2489, -0.1827,  0.1184,  0.1137, -0.3655,\n",
       "           -0.0051, -0.3051, -0.1041, -0.0385,  0.2438, -0.1674, -0.0590, -0.5224,\n",
       "           -0.2026,  0.2916, -0.0934,  0.3564,  0.0987,  0.2349,  0.0412,  0.1535,\n",
       "            0.0532,  0.3989, -0.0267,  0.1336, -0.4319,  0.2268, -0.1172,  0.1562,\n",
       "           -0.1358,  0.0441,  0.3614,  0.4093, -0.2811,  0.1733, -0.0787,  0.3585,\n",
       "           -0.3120,  0.2882, -0.1975, -0.1971, -0.1386,  0.0289,  0.0764,  0.0387,\n",
       "            0.1528, -0.4838,  0.0998,  0.5830,  0.0820,  0.0435, -0.1480,  0.4661,\n",
       "            0.2292, -0.0498,  0.2196, -0.5661,  0.3118,  0.0811, -0.3420,  0.1765,\n",
       "            0.2603, -0.3202, -0.4264,  0.1506, -0.2115,  0.0729, -0.4737,  0.3949,\n",
       "            0.0072, -0.0158, -0.1574, -0.0106,  0.0668,  0.3701, -0.0060,  0.2914,\n",
       "            0.1471, -0.0077, -0.0841,  0.2436, -0.4085, -0.0318, -0.0910, -0.2636,\n",
       "           -0.5088,  0.1229,  0.4413,  0.1420, -0.0837, -0.0842,  0.0729, -0.0543,\n",
       "            0.1797,  0.2175, -0.3282, -0.1101,  0.1272, -0.2016, -0.5726,  0.1317,\n",
       "            0.1555,  0.2927,  0.3706,  0.0216, -0.3342,  0.1854,  0.3219,  0.2819,\n",
       "            0.4591, -0.1348, -0.0577, -0.4263,  0.5047, -0.4663, -0.2182, -0.2534,\n",
       "            0.0902, -0.4327, -0.0656,  0.1431, -0.0078,  0.0132,  0.0618,  0.1839,\n",
       "            0.1083,  0.2072,  0.1488,  0.0037, -0.5064, -0.3665, -0.3643,  0.4910,\n",
       "            0.2713,  0.2905,  0.1206, -0.2921, -0.0514, -0.0713, -0.1544, -0.3374,\n",
       "            0.1011, -0.0483, -0.2578,  0.4059, -0.1063,  0.1665, -0.1409, -0.0530,\n",
       "           -0.1180, -0.0228,  0.4862,  0.3159,  0.2619,  0.0591, -0.1329, -0.1088,\n",
       "           -0.1323,  0.1406, -0.0030, -0.4481,  0.5765, -0.0507, -0.3167,  0.2488,\n",
       "            0.0278,  0.0073,  0.2939,  0.4557, -0.0116, -0.2669,  0.0046,  0.1305,\n",
       "           -0.2176,  0.5835, -0.3798, -0.2174, -0.3578,  0.4938, -0.3740,  0.1419,\n",
       "            0.1968,  0.0363,  0.0611, -0.0173, -0.3386,  0.1992, -0.0905,  0.0583,\n",
       "            0.0758, -0.0118, -0.0226,  0.1087, -0.0148, -0.3598,  0.0098,  0.0875,\n",
       "           -0.0887,  0.3732, -0.1956, -0.3436, -0.0867, -0.5943, -0.4708,  0.2534,\n",
       "           -0.0135,  0.1961, -0.1480, -0.0594,  0.2945, -0.1588,  0.1309, -0.1241,\n",
       "            0.1263, -0.2240, -0.1811,  0.2331,  0.0543,  0.1664, -0.6172,  0.2885,\n",
       "           -0.2593,  0.0071,  0.4290,  0.0430,  0.1029,  0.4552, -0.1236, -0.1348,\n",
       "           -0.0691, -0.0047,  0.1568,  0.1525,  0.0667,  0.0286, -0.1025,  0.1991,\n",
       "           -0.0615,  0.4266, -0.0394,  0.0687, -0.2311,  0.5940, -0.5144,  0.2736,\n",
       "           -0.2378,  0.1756,  0.3055, -0.0864,  0.4035,  0.0945, -0.2430, -0.0670,\n",
       "           -0.1263, -0.0972, -0.4637,  0.3774, -0.1901,  0.1657, -0.3555,  0.5297,\n",
       "            0.3930,  0.2216, -0.6017,  0.0415, -0.0403, -0.5993, -0.2853,  0.1198,\n",
       "           -0.1921, -0.1254,  0.0652, -0.2178, -0.1120, -0.2373,  0.0763,  0.5544],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 6.4327e-01,  6.6815e-01, -5.4863e-01, -5.0997e-01,  4.5391e-01,\n",
       "           -5.0183e-01, -5.5701e-01, -1.2287e-01, -4.3396e-01,  5.8693e-01,\n",
       "            5.2511e-01, -2.1066e-01,  6.9805e-01,  3.2469e-02,  6.4833e-01,\n",
       "            5.4482e-01,  3.8963e-01,  3.6612e-01, -4.5268e-01, -6.4280e-02,\n",
       "            6.5131e-01,  2.1481e-01,  6.2392e-02, -2.8691e-01,  8.2896e-01,\n",
       "           -3.7645e-01, -4.0647e-01,  5.6643e-01, -4.3817e-01, -3.7928e-01,\n",
       "           -1.8461e-01, -5.8216e-01,  2.1453e-01,  6.8936e-01, -6.6467e-02,\n",
       "            5.4138e-01,  5.7435e-01,  6.1861e-01, -3.3517e-01, -1.8757e-02,\n",
       "            7.1508e-01, -4.5884e-01,  5.8978e-01,  5.0351e-01, -6.0553e-01,\n",
       "            7.6046e-01, -3.3452e-01, -4.3843e-01,  3.1067e-01,  5.6085e-01,\n",
       "            3.7936e-01,  6.5054e-01,  3.2293e-01, -4.9957e-01,  5.3552e-01,\n",
       "           -3.7342e-01, -4.1754e-01, -1.6394e-01,  3.1711e-01, -2.4711e-01,\n",
       "            6.5919e-01, -2.8067e-01, -5.7890e-01,  5.0854e-01,  8.4323e-02,\n",
       "            6.1748e-01,  7.3558e-01, -5.3768e-01,  6.8348e-01,  5.4083e-01,\n",
       "            2.7683e-01,  4.9375e-01,  7.0353e-01,  5.9975e-01,  1.8957e-01,\n",
       "            7.2393e-01,  5.5803e-01,  4.9328e-02,  6.3553e-01,  6.6044e-01,\n",
       "           -3.3013e-02,  5.7802e-01,  5.5991e-01, -2.6444e-01,  5.6080e-01,\n",
       "           -1.2857e-01,  4.4142e-01, -2.0025e-01, -4.6733e-01,  5.6371e-01,\n",
       "            8.0960e-04,  5.4674e-01,  5.4694e-01,  8.1982e-01,  4.1715e-01,\n",
       "            3.4417e-01,  5.5412e-01, -5.4258e-01,  4.1709e-01,  6.1059e-01,\n",
       "            6.8872e-01,  6.9210e-01, -4.1549e-01,  6.0348e-01, -3.2078e-01,\n",
       "            1.2520e-01,  4.1418e-01, -1.1031e-01,  5.3661e-02, -3.2066e-01,\n",
       "            6.2576e-01,  5.9480e-01,  3.4907e-01, -5.1723e-01,  4.6630e-01,\n",
       "           -3.8982e-01, -4.7619e-01, -4.7877e-01, -1.4874e-01, -5.1830e-01,\n",
       "           -3.7981e-02,  6.1037e-01,  6.6638e-01,  5.9609e-01, -4.6201e-01,\n",
       "           -1.7678e-01, -5.1547e-01, -4.5282e-01,  6.8586e-01, -3.9247e-01,\n",
       "            6.4393e-01,  5.0130e-01, -3.1588e-01,  6.4643e-01,  7.7045e-01,\n",
       "            7.4207e-01,  6.7081e-01,  5.6985e-01, -5.1243e-01, -2.1449e-01,\n",
       "            4.5485e-01, -5.2280e-01, -5.2065e-01, -3.3867e-01,  1.6424e-01,\n",
       "            6.3510e-01,  5.8190e-01, -2.1706e-01,  6.7848e-01,  5.2371e-01,\n",
       "            6.9632e-01,  5.7363e-01,  4.2046e-01, -1.0187e-01, -4.7517e-01,\n",
       "           -5.2428e-01, -1.0521e-01, -4.0771e-01, -7.1145e-02, -1.8496e-01,\n",
       "           -6.1143e-02, -5.2436e-01,  5.8353e-01,  4.6803e-01,  3.7121e-01,\n",
       "            5.4687e-01,  7.6579e-01, -5.0375e-01,  4.5002e-01,  5.4678e-01,\n",
       "            5.2401e-01, -4.9967e-01,  5.6712e-01,  6.8291e-01,  6.6678e-01,\n",
       "           -5.4007e-01, -5.1180e-01, -5.2834e-01, -3.4190e-01,  5.6225e-01,\n",
       "           -4.9020e-01,  6.3229e-01, -4.3091e-01,  4.5187e-01, -1.2891e-01,\n",
       "           -5.0947e-01,  5.5349e-01,  7.0373e-01,  4.5372e-01,  5.8586e-01,\n",
       "            3.5981e-01,  7.5705e-01, -5.0676e-01, -5.0765e-01, -3.1427e-01,\n",
       "           -4.0831e-01, -3.4652e-02,  4.1086e-01,  5.3205e-01,  7.0267e-01,\n",
       "           -7.2905e-02,  7.0147e-01,  7.6683e-03,  6.9773e-01,  5.6397e-01,\n",
       "            5.8533e-01,  5.4181e-01,  6.5081e-01,  6.4672e-01, -4.0277e-01,\n",
       "            6.1156e-01, -5.3753e-01,  6.9111e-01, -4.6511e-01,  3.2852e-01,\n",
       "            3.8226e-01, -4.4445e-01,  5.6879e-02,  1.1982e-01,  3.4544e-02,\n",
       "           -5.2170e-01,  1.1973e-01, -4.1045e-01, -5.1584e-01,  5.3351e-01,\n",
       "            7.1839e-01,  3.6567e-01,  7.7955e-02, -3.2144e-01, -5.2950e-01,\n",
       "            1.0588e-01, -3.0296e-02, -3.6017e-01, -4.8284e-01, -5.0421e-01,\n",
       "            5.0550e-01, -4.5594e-01,  4.5286e-01,  1.6369e-01, -5.3436e-01,\n",
       "            2.5506e-01,  4.0541e-01, -3.2820e-01, -3.3326e-01, -4.4146e-01,\n",
       "            6.8827e-01, -1.0173e-01, -4.1079e-01,  5.6535e-01,  6.7822e-01,\n",
       "            2.8344e-01, -2.8976e-01,  3.8852e-01, -3.5046e-01,  7.3226e-01,\n",
       "            2.6018e-01,  6.4436e-01,  5.4896e-01, -5.3752e-01,  5.4328e-01,\n",
       "            3.6089e-01, -5.3700e-01,  5.7302e-01,  8.6206e-01, -4.5787e-01,\n",
       "           -1.5222e-02, -4.3603e-01,  3.7165e-01,  1.1206e-01, -4.0463e-01,\n",
       "            5.2313e-01, -3.8068e-01, -4.3992e-01,  1.6719e-01,  3.8670e-01,\n",
       "           -5.7052e-01,  5.2403e-01,  7.2509e-01,  4.6151e-01, -5.3174e-01,\n",
       "           -4.3141e-01,  4.7960e-01,  1.5744e-01, -5.2717e-01, -4.5963e-01,\n",
       "            5.6500e-02,  6.7732e-01,  4.9106e-01, -4.8737e-01,  9.8895e-02,\n",
       "            2.7213e-02, -3.4010e-01,  1.3572e-01,  3.7973e-01, -3.2189e-01,\n",
       "            4.7869e-01,  5.7592e-01,  4.5485e-01,  5.8941e-01,  2.4587e-02,\n",
       "           -4.2256e-01, -4.1879e-01, -1.7086e-01, -4.6023e-01,  2.4738e-01,\n",
       "            5.3510e-01, -4.0884e-01, -4.9939e-01, -6.1195e-01,  5.8405e-01,\n",
       "            6.4415e-01,  6.6490e-01,  5.5180e-01, -2.5602e-01, -4.1876e-01,\n",
       "            2.4421e-01,  5.5281e-01, -4.2766e-01,  4.3966e-01, -3.8329e-01,\n",
       "            4.6736e-01, -3.9404e-01,  6.6191e-01, -5.2747e-01, -4.3195e-01,\n",
       "            5.2513e-01,  3.3739e-01, -5.1650e-01,  7.0119e-01,  7.0635e-01,\n",
       "            8.8288e-02,  5.9714e-01, -6.3259e-01,  6.8553e-01,  7.5320e-01,\n",
       "           -1.1263e-01,  5.4908e-01, -4.9900e-01,  5.9843e-01, -1.0833e-01,\n",
       "            5.4358e-01, -5.2056e-01,  6.9793e-01,  1.9456e-01, -5.2164e-01,\n",
       "           -5.4164e-01, -2.3338e-01, -5.5807e-01, -4.3099e-01,  5.7759e-01,\n",
       "           -3.7361e-01, -5.0848e-01, -3.4831e-01, -5.6665e-01, -4.2880e-01,\n",
       "            7.3242e-01,  5.5656e-01,  4.6602e-01, -4.0664e-01, -4.9196e-01,\n",
       "           -4.6202e-01,  4.9139e-01, -4.7907e-01, -5.2862e-01,  5.8852e-01,\n",
       "           -5.3655e-01,  3.4598e-01, -4.7980e-01, -3.6416e-01,  5.8952e-02,\n",
       "           -1.0651e-01,  5.8603e-02,  6.8956e-01, -5.4720e-01,  5.1063e-01,\n",
       "            6.9282e-01, -5.0421e-01,  1.6533e-01,  3.8798e-01,  5.0229e-01,\n",
       "            6.4018e-01,  5.4832e-01,  5.9012e-02, -4.4132e-01,  7.2152e-01,\n",
       "            5.5677e-01, -3.9362e-01, -5.3187e-01,  5.9693e-01,  7.1485e-01,\n",
       "            1.2845e-01, -5.1655e-01,  2.8494e-01,  4.1956e-01,  2.3851e-01,\n",
       "            7.3382e-01,  6.3724e-01,  3.4684e-01,  6.0878e-01,  7.1390e-01,\n",
       "           -2.9907e-01,  7.4192e-01, -5.2402e-01, -3.6020e-01,  7.0339e-01,\n",
       "           -5.5372e-01, -6.4315e-01, -3.9296e-01, -4.0877e-01,  5.8947e-01,\n",
       "           -4.7265e-01,  5.7032e-01, -1.6825e-01,  3.4181e-01, -5.3070e-01,\n",
       "            5.1206e-01,  6.8524e-01, -4.7489e-01,  5.8090e-01, -2.6396e-01,\n",
       "           -4.0384e-01, -5.4193e-01, -3.3222e-01,  6.4964e-01,  6.8126e-01,\n",
       "           -4.2577e-01,  4.1772e-01, -3.9434e-01, -5.3151e-01,  5.7089e-01,\n",
       "           -5.2737e-01,  5.6329e-01, -2.4744e-01,  3.0182e-01,  7.3345e-01,\n",
       "           -3.6564e-01, -5.3504e-01, -9.1230e-02,  6.6714e-01,  6.5039e-01,\n",
       "            5.5941e-01,  6.2897e-01, -4.3173e-01, -3.6014e-01,  4.5580e-01,\n",
       "           -3.0136e-01,  5.3142e-01,  5.8727e-01,  6.8979e-01,  6.0224e-01,\n",
       "            3.4423e-01, -3.5306e-01, -4.9097e-01, -5.5245e-01,  6.2061e-01,\n",
       "            4.1872e-01,  9.3470e-01,  5.7829e-01,  3.3778e-01, -1.1514e-01,\n",
       "           -4.2852e-01, -3.9343e-01, -5.0477e-01, -4.1658e-01,  5.1353e-01,\n",
       "            9.0199e-01,  6.7782e-01, -3.1375e-01,  1.0450e-01, -5.2278e-01,\n",
       "            6.2732e-01, -4.6317e-01, -5.0183e-01,  4.7422e-01,  2.9063e-01,\n",
       "           -1.0514e-01, -1.3776e-01, -4.0112e-01,  6.8314e-01,  4.6641e-01,\n",
       "            5.5376e-01, -4.0700e-01, -4.4315e-01,  3.6594e-01,  5.6126e-01,\n",
       "            7.1008e-01,  6.7480e-03, -3.3548e-01,  6.5369e-01, -4.2010e-01,\n",
       "            3.6985e-01,  6.6017e-01, -3.9985e-01,  2.5196e-01,  6.8155e-01,\n",
       "           -5.5977e-02,  5.4202e-01,  2.4050e-01,  4.5067e-01,  6.8252e-01,\n",
       "            3.7800e-01, -4.1779e-01, -5.1351e-01,  6.7148e-01, -2.2234e-01,\n",
       "            4.7924e-01, -3.7815e-01,  6.8425e-01,  4.2565e-01, -5.3492e-01,\n",
       "           -4.6237e-01,  6.7403e-01], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-8.5656e-02, -1.2439e-01, -5.7061e-03,  6.5074e-02,  1.8447e-01,\n",
       "            2.8257e-02, -5.4045e-02, -7.5162e-02,  1.3835e-01, -6.4170e-02,\n",
       "            1.2604e-01, -2.4993e-01,  1.8943e-01, -1.7483e-02,  1.1462e-01,\n",
       "            6.0181e-02, -3.8437e-02,  2.9414e-02,  9.4716e-02,  3.4087e-02,\n",
       "            8.5714e-02, -1.6154e-02, -2.3161e-01, -1.7060e-01,  5.0982e-02,\n",
       "           -6.7293e-02, -2.8176e-02,  2.0477e-03, -4.3311e-02, -1.3226e-01,\n",
       "            8.8156e-02, -2.5250e-02,  5.5846e-02, -2.3669e-01,  8.2573e-02,\n",
       "            5.7310e-02,  3.1761e-02, -1.7588e-01, -1.9017e-01,  1.5054e-01,\n",
       "           -5.3598e-02,  9.9853e-02,  7.1490e-02,  3.9951e-02, -2.5823e-01,\n",
       "           -3.0061e-01,  5.4906e-02, -1.5106e-01, -1.1117e-01,  1.3437e-01,\n",
       "           -4.3538e-02, -6.8406e-02,  5.0085e-02,  8.8186e-02,  4.0243e-02,\n",
       "            6.1645e-02,  1.5429e-01, -4.1154e-02, -1.0435e-01,  4.0620e-02,\n",
       "            7.6385e-02, -2.5179e-01, -4.8591e-03, -1.2271e-02,  2.9998e-02,\n",
       "           -4.1958e-02,  9.5108e-02, -1.5116e-01,  1.1548e-01,  7.0039e-02,\n",
       "           -6.0777e-03, -1.8231e-01,  1.1214e-01,  5.2142e-02, -4.4396e-02,\n",
       "           -9.4596e-02, -8.8029e-03,  5.7261e-02, -5.8772e-02, -6.7022e-02,\n",
       "           -1.2596e-01, -2.2825e-01,  1.5792e-02, -9.1302e-02,  6.6183e-02,\n",
       "            7.9063e-02,  1.9510e-01, -5.0918e-02, -1.0033e-02,  7.7884e-02,\n",
       "            9.0215e-02, -2.8091e-01, -1.2706e-01,  5.1505e-03,  6.9223e-02,\n",
       "            4.6820e-03,  1.4145e-02,  6.9569e-03,  1.1705e-01, -3.6798e-02,\n",
       "            8.8261e-02,  2.6024e-01,  5.0698e-02,  9.6210e-02,  1.0292e-01,\n",
       "           -1.3652e-01,  6.5310e-02,  5.6612e-02,  9.1397e-02,  8.4599e-02,\n",
       "            1.6000e-01,  2.5302e-02, -1.2103e-02,  9.5217e-02,  1.5154e-02,\n",
       "           -3.8162e-02, -1.0737e-01, -8.2444e-02, -2.2345e-02,  6.0811e-03,\n",
       "           -9.2776e-02,  1.3254e-01, -7.3014e-02,  6.5254e-02,  1.3327e-01,\n",
       "           -1.0100e-01,  9.7228e-02, -1.8637e-01,  5.5664e-02,  2.8823e-01,\n",
       "            5.9395e-02,  2.1887e-01, -6.4329e-02, -1.1123e-01,  5.4974e-01,\n",
       "           -1.9267e-01, -1.8462e-02, -6.2546e-01, -1.4991e-04,  5.2774e-01,\n",
       "            3.7071e-01,  6.5121e-02, -1.1773e-01,  9.3586e-02, -7.9719e-02,\n",
       "           -6.7084e-02,  6.7031e-02, -1.2754e-02,  1.8852e-01,  1.4009e-01,\n",
       "            7.6547e-02,  9.5801e-02,  7.5980e-02,  7.1949e-02, -1.6525e-01,\n",
       "           -6.9297e-02, -6.9918e-02,  3.1998e-02, -4.2044e-02, -1.3904e-01,\n",
       "            1.7699e-02, -8.7821e-02,  8.8972e-02, -5.7704e-02, -6.3092e-03,\n",
       "            1.2757e-01, -1.9524e-01,  5.9973e-02,  6.1324e-02, -7.4167e-02,\n",
       "           -6.8206e-03,  9.4511e-03,  5.5835e-02,  1.2130e-01, -7.9860e-02,\n",
       "            3.4206e-02,  1.2613e-01,  1.1312e-01,  6.1374e-02,  3.6349e-02,\n",
       "            7.9878e-01, -7.4748e-03,  5.2192e-02, -5.6709e-03,  5.4874e-02,\n",
       "            4.7218e-02,  9.8944e-03,  9.2878e-02,  1.6329e-01,  2.0177e-01,\n",
       "           -6.9306e-02, -2.7693e-02,  7.5670e-03,  1.9185e-01,  1.4275e-01,\n",
       "           -1.4313e-01,  1.0381e-02, -5.7009e-03,  1.3938e-01,  1.0383e-01,\n",
       "            6.6044e-02,  8.2468e-02,  6.5611e-01,  5.0278e-02,  2.9651e-02,\n",
       "           -7.2236e-03,  1.9059e-01,  2.0862e-02,  3.5496e-01, -1.4315e-01,\n",
       "            6.9293e-02, -7.5143e-02, -3.2249e-01,  2.4273e-01,  6.5807e-02,\n",
       "            6.5352e-02,  1.1820e-01,  5.1540e-02, -2.9904e-02,  3.2219e-02,\n",
       "            7.9008e-02, -2.7286e-02, -9.3117e-02, -1.8643e-01,  2.4449e-01,\n",
       "            2.4681e-01, -1.0408e-01,  7.6668e-02,  1.4400e-01, -2.0369e-01,\n",
       "            1.9946e-02, -2.6063e-02, -1.9424e-01,  1.4807e-01,  4.1850e-02,\n",
       "            6.2027e-02, -4.6418e-02, -6.9653e-02,  4.4846e-02, -7.5481e-02,\n",
       "            5.0598e-02, -5.1223e-02,  7.0482e-02,  4.6552e-02,  2.9147e-02,\n",
       "           -8.0077e-02, -4.7063e-02, -2.3465e-01,  1.0687e-01, -3.6385e-02,\n",
       "            4.5558e-02,  2.3328e-02, -7.3103e-02, -1.8400e-01,  9.7748e-02,\n",
       "            1.5987e-01,  5.6343e-02, -9.1293e-02,  5.4252e-03,  1.5400e-02,\n",
       "            2.8393e-02, -3.7567e-02, -1.6054e-01, -8.9343e-02, -2.3108e-02,\n",
       "            2.1024e-03,  1.2255e-01, -2.4814e-02,  5.9769e-02,  1.1093e-01,\n",
       "            5.8919e-03, -1.0896e-01, -4.8235e-02, -3.3880e-01, -1.5816e-01,\n",
       "            2.5207e-02, -4.2968e-02, -4.1948e-02,  1.1186e-01, -5.5945e-02,\n",
       "           -1.8470e-02,  2.6010e-01,  8.2956e-02,  4.6856e-02, -5.6476e-02,\n",
       "            1.9055e-01, -4.2906e-02,  1.4346e-01,  2.0187e-02, -4.7896e-02,\n",
       "           -1.7148e-01,  6.0515e-01,  6.0982e-02,  9.7317e-02,  5.8064e-02,\n",
       "            2.1652e-02,  1.2917e-01,  1.8335e-01, -3.1830e-01,  5.0757e-02,\n",
       "           -6.0134e-02, -3.9901e-02,  6.6078e-02,  2.1988e-02, -3.1409e-02,\n",
       "           -2.4175e-01, -2.6144e-02, -1.2340e-01, -2.2204e-03,  2.1265e-01,\n",
       "           -8.2282e-02, -8.6653e-02,  1.1825e-01, -7.7344e-02, -1.0660e-01,\n",
       "           -2.6939e-02,  1.2608e-01, -8.0547e-02, -8.3600e-02,  5.0413e-02,\n",
       "            1.0366e-01,  2.4573e-02,  2.4821e-02, -1.3840e-01, -4.7426e-02,\n",
       "            1.0732e-01,  6.1954e-02,  7.7577e-02, -1.1953e-02, -5.9215e-02,\n",
       "            1.1597e-01,  2.2196e-02, -9.1811e-02, -7.4042e-02, -2.5058e-01,\n",
       "           -4.8805e-02, -2.5099e-03,  1.5706e-01, -8.3990e-02,  6.0216e-02,\n",
       "            7.1172e-03,  8.9032e-03,  1.4621e-01,  4.7844e-03,  9.7593e-02,\n",
       "            5.7019e-02,  1.1654e-01,  2.1289e-01,  4.9826e-01,  3.5616e-02,\n",
       "           -8.5363e-02, -1.6558e-01, -1.3617e-01, -1.2919e-01,  2.1186e-02,\n",
       "            5.5928e-02, -6.4242e-02, -6.1277e-02, -1.7017e-01, -4.4074e-02,\n",
       "            1.7102e-02, -8.9268e-02, -9.3718e-02,  4.7604e-02,  2.7573e-01,\n",
       "           -1.3353e-01,  5.6673e-01,  7.1571e-02,  2.6692e-02, -3.5446e-02,\n",
       "           -1.0126e-01, -1.3539e-01, -5.8789e-02, -1.4284e-02, -1.0486e-02,\n",
       "            1.0381e-01,  3.0885e-02,  6.4154e-02, -4.1916e-02, -6.6140e-02,\n",
       "           -6.3448e-01,  6.1514e-02,  8.7239e-02,  6.7007e-02, -8.2864e-02,\n",
       "           -3.2023e-01, -1.7006e-01, -5.8925e-02,  1.4777e-01,  8.2558e-02,\n",
       "           -9.2149e-02, -2.3750e-02, -7.6906e-02, -7.9439e-02, -5.8553e-02,\n",
       "           -3.0407e-02, -5.5511e-03, -6.3579e-02,  1.8707e-01,  1.0154e-01,\n",
       "           -6.6987e-02,  2.7505e-01, -1.3401e-02,  1.0360e-01, -1.1933e-01,\n",
       "            1.2338e-01, -1.6812e-02, -5.0066e-02,  1.2996e-01,  5.3394e-01,\n",
       "            2.5898e-01, -9.7480e-04,  2.0167e-01, -2.0993e-02,  2.0050e-01,\n",
       "            1.5685e-01, -5.9919e-01, -4.6724e-02, -1.5938e-02, -1.9273e-01,\n",
       "           -9.0963e-02, -2.1511e-02,  2.6431e-02,  5.8145e-03, -7.5835e-02,\n",
       "           -2.5493e-01,  4.5606e-02,  3.3710e-02,  3.9853e-02,  1.4268e-01,\n",
       "            6.1353e-02, -9.3158e-02,  8.2837e-02,  3.3432e-02, -6.4924e-02,\n",
       "            6.9160e-02,  7.1075e-02,  3.2997e-02, -3.0872e-02,  4.6299e-03,\n",
       "            1.9386e-01, -1.1384e-01, -7.3120e-03, -4.6328e-02,  3.2218e-03,\n",
       "           -8.0383e-02,  2.6044e-02,  7.0462e-02, -4.8367e-02, -1.7049e-01,\n",
       "           -4.4971e-02,  1.0685e-01,  2.7099e-02, -3.1784e-02, -4.1211e-01,\n",
       "            1.2273e-01,  4.5035e-02, -7.7422e-02,  1.5048e-01,  5.9432e-02,\n",
       "            8.5430e-02, -4.2621e-02, -8.0569e-02,  8.2822e-02,  9.0613e-02,\n",
       "           -7.0757e-02,  4.7488e-02,  9.4290e-02,  9.5255e-03, -1.4520e-01,\n",
       "           -3.5578e-02, -1.3386e-01,  6.8343e-02, -3.8789e-01, -7.7643e-02,\n",
       "           -7.2783e-03, -1.1117e-01, -1.4427e-02, -4.1645e-01,  5.5494e-02,\n",
       "            6.7279e-02, -2.1936e-01,  8.8629e-02,  7.1651e-02,  5.0943e-02,\n",
       "           -7.9260e-02,  5.7927e-02,  1.4368e-01, -1.4876e-01,  9.8404e-02,\n",
       "           -7.4064e-02,  8.3343e-02, -6.1145e-02, -3.9829e-02, -7.7885e-02,\n",
       "            1.5020e-01, -1.3519e-01,  3.6925e-02,  1.1068e-01,  1.9604e-02,\n",
       "           -7.2170e-02,  2.0070e-01, -3.2566e-01,  1.6995e-02, -6.6775e-02,\n",
       "           -7.5195e-02, -1.7780e-02, -6.6938e-04, -8.1573e-02,  1.6857e-01,\n",
       "           -1.0292e-02,  3.0629e-02], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0059,  0.0470, -0.0711,  ..., -0.0379,  0.0437, -0.0661],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0483, -0.0464, -0.0524,  0.0499,  0.0460,  0.0491, -0.0490, -0.0492,\n",
       "            0.0475, -0.0502,  0.0488,  0.0500,  0.0470,  0.0506,  0.0472,  0.0511,\n",
       "           -0.0491,  0.0498,  0.0445, -0.0509,  0.0485,  0.0485, -0.0416, -0.0522,\n",
       "            0.0478,  0.0468, -0.0429,  0.0497, -0.0476,  0.0262,  0.0467, -0.0486,\n",
       "            0.0489, -0.0518,  0.0495,  0.0450,  0.0494, -0.0440, -0.0454,  0.0497,\n",
       "           -0.0478,  0.0582,  0.0672,  0.0505,  0.0480, -0.2011,  0.0499, -0.0465,\n",
       "           -0.0461,  0.0457,  0.0626, -0.0509,  0.0483,  0.0643, -0.0492,  0.0510,\n",
       "            0.0558, -0.0494,  0.0776, -0.0610,  0.0469, -0.0505,  0.0499, -0.0596,\n",
       "           -0.0489, -0.0499,  0.0539, -0.0520,  0.0500,  0.0572,  0.0483,  0.0518,\n",
       "            0.0532,  0.0453, -0.0491, -0.0490, -0.0486,  0.0486, -0.0482, -0.0497,\n",
       "           -0.0515, -0.0495, -0.0504, -0.0499, -0.0511,  0.0506,  0.0465, -0.0501,\n",
       "           -0.0482,  0.0489,  0.0481,  0.0487,  0.0624,  0.0501, -0.0485,  0.0499,\n",
       "           -0.0424,  0.0466,  0.0552, -0.0284,  0.0517,  0.0375,  0.0485,  0.0373,\n",
       "           -0.0568, -0.0503,  0.0610,  0.0504,  0.0499,  0.0492,  0.0428, -0.0477,\n",
       "           -0.0505,  0.0451,  0.0475,  0.0566,  0.0497, -0.0510, -0.0512, -0.0496,\n",
       "           -0.0481,  0.0483, -0.0496, -0.0505, -0.0510, -0.0481,  0.0505, -0.0507,\n",
       "            0.0492,  0.0532,  0.0535,  0.0482, -0.0495, -0.0497, -0.0523, -0.0462,\n",
       "            0.0457, -0.0492,  0.0477, -0.0444,  0.0531,  0.0488, -0.0482, -0.0462,\n",
       "           -0.0497, -0.0517,  0.0500, -0.0500,  0.0491, -0.0535, -0.0132,  0.0527,\n",
       "            0.0507,  0.0463, -0.1040,  0.0539, -0.0484,  0.0495, -0.0496, -0.0482,\n",
       "            0.0481, -0.0512,  0.0522, -0.0497, -0.0508, -0.0432, -0.0517,  0.0495,\n",
       "            0.0497, -0.0494, -0.0494, -0.0509, -0.0491,  0.0514, -0.0490, -0.1019,\n",
       "            0.0507,  0.0497,  0.0495,  0.0504, -0.0830, -0.0484,  0.0501, -0.0474,\n",
       "           -0.0542,  0.0531,  0.0522,  0.0478,  0.0482, -0.2336, -0.0500, -0.0479,\n",
       "            0.0478, -0.0266,  0.0499, -0.0500,  0.0500, -0.0808,  0.0518,  0.0494,\n",
       "            0.0493,  0.0508,  0.0655,  0.0484,  0.0500,  0.0511, -0.0589,  0.0465,\n",
       "            0.0318,  0.0459,  0.0530, -0.0493, -0.0535,  0.0468,  0.0513, -0.0476,\n",
       "            0.0525,  0.0506, -0.0499,  0.0490,  0.0496, -0.0495, -0.0500, -0.0577,\n",
       "           -0.0790,  0.0466, -0.0481,  0.0487, -0.0677, -0.0511,  0.0519, -0.0501,\n",
       "            0.0456,  0.0468,  0.0498,  0.0492, -0.0518, -0.0502, -0.0494, -0.0514,\n",
       "            0.0479, -0.0483,  0.0494,  0.0457,  0.0513, -0.0482, -0.0495,  0.0618,\n",
       "            0.0495, -0.0537,  0.0493,  0.0615, -0.0501,  0.0373,  0.0500,  0.0502,\n",
       "            0.0499, -0.0535,  0.0493,  0.0498,  0.0892, -0.0464, -0.0511, -0.0542,\n",
       "           -0.0500, -0.0494,  0.0480,  0.0440,  0.0493,  0.0490,  0.0505, -0.0482,\n",
       "           -0.0476,  0.0406, -0.0534,  0.0490,  0.0521, -0.0502,  0.0478, -0.0472,\n",
       "            0.0480, -0.0469,  0.0517,  0.0475, -0.0470,  0.0547, -0.0517, -0.0490,\n",
       "            0.0482, -0.0496,  0.0475,  0.0391,  0.0500,  0.0485,  0.0487,  0.0489,\n",
       "            0.0525,  0.0409, -0.0485,  0.0497, -0.0502, -0.0502,  0.0473, -0.0560,\n",
       "           -0.0509,  0.0510,  0.0242, -0.0536, -0.0614, -0.0537, -0.0501,  0.0483,\n",
       "           -0.0549, -0.0511, -0.0491, -0.0507, -0.0730, -0.0500, -0.0485,  0.0505,\n",
       "           -0.0865,  0.0409,  0.0437, -0.0744, -0.0443,  0.0549, -0.0475,  0.0506,\n",
       "            0.0588,  0.0524,  0.0499,  0.0493, -0.0548, -0.0277, -0.0698, -0.0485,\n",
       "            0.0494,  0.0432,  0.0513,  0.0496,  0.0472, -0.0486,  0.0513, -0.0497,\n",
       "           -0.0508,  0.0518,  0.0535,  0.0438,  0.0441, -0.0448, -0.0493,  0.0491,\n",
       "           -0.0488, -0.0443,  0.0556,  0.0495, -0.0485, -0.0483,  0.0507, -0.0449,\n",
       "           -0.0506, -0.0519, -0.0483, -0.0497, -0.0460, -0.0470,  0.0567,  0.0476,\n",
       "            0.0506,  0.0487, -0.0498,  0.0628, -0.0496, -0.0522,  0.0455,  0.0549,\n",
       "           -0.0542,  0.0485, -0.0491, -0.0435,  0.0681,  0.0501,  0.0011,  0.0195,\n",
       "           -0.0525,  0.0458, -0.0270, -0.0495, -0.0476,  0.0512, -0.0507, -0.0512,\n",
       "           -0.0520, -0.0496, -0.0500, -0.0513,  0.0536, -0.0495,  0.0405,  0.0460,\n",
       "           -0.0495,  0.0519,  0.0554,  0.0530, -0.0493,  0.0495, -0.0506, -0.0517,\n",
       "            0.0504,  0.0486, -0.0527,  0.0504, -0.0072, -0.0499,  0.0488,  0.0496,\n",
       "            0.0504, -0.0529, -0.0502, -0.0482, -0.0494, -0.0513, -0.0477,  0.0513,\n",
       "           -0.0565, -0.0411,  0.0486,  0.0494,  0.0496, -0.0541,  0.0492, -0.0492,\n",
       "           -0.0551, -0.0465, -0.0505,  0.0452,  0.0556, -0.0475, -0.0488,  0.0478,\n",
       "            0.0494, -0.0475,  0.0500, -0.0501,  0.0471, -0.0505,  0.0588,  0.0495,\n",
       "           -0.0493, -0.0517, -0.0497,  0.0483,  0.0499, -0.0503, -0.0410,  0.0551,\n",
       "           -0.0487, -0.0502,  0.0667,  0.0490,  0.0500,  0.0541, -0.0248,  0.0501,\n",
       "            0.0494, -0.0496,  0.0503,  0.0504,  0.0453, -0.0487, -0.0502, -0.0511,\n",
       "            0.0508,  0.0676, -0.0520, -0.0296, -0.0526, -0.0504, -0.0476,  0.0493,\n",
       "           -0.0471, -0.0453,  0.0493,  0.0572,  0.0448, -0.0495,  0.0536,  0.0495,\n",
       "           -0.0459,  0.0500, -0.0479,  0.0467, -0.0487, -0.0498, -0.0387,  0.0463,\n",
       "           -0.0576,  0.0499, -0.0498,  0.0533, -0.0500, -0.0488,  0.0577,  0.0475,\n",
       "           -0.0475, -0.0516,  0.0453, -0.0505, -0.0494,  0.0544, -0.0487,  0.0537],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-8.0688e-02, -4.7302e-02,  3.9687e-02,  4.0077e-02, -5.1685e-02,\n",
       "           -6.9735e-02, -4.4114e-02, -4.0365e-02, -2.1393e-02, -2.0475e-01,\n",
       "           -7.3893e-02,  4.2328e-01,  2.4195e-02, -5.6158e-02, -1.6091e-01,\n",
       "           -1.4495e-01,  6.0527e-01, -4.6204e-01, -2.0353e-02, -6.1421e-02,\n",
       "           -6.3625e-01, -2.0411e-01,  8.0917e-01, -6.7612e-02, -4.5637e-02,\n",
       "            2.5505e-03, -5.6645e-02, -4.7305e-02,  7.9690e-01, -2.2548e-01,\n",
       "            4.6956e-02, -1.9898e-01, -4.1050e-01, -2.0877e-01, -4.3254e-02,\n",
       "            3.6066e-02, -2.9983e-04, -6.2317e-02, -4.1280e-01, -1.7516e-01,\n",
       "           -5.2148e-02,  1.3775e-02, -4.5981e-02, -6.0921e-02, -2.3961e-02,\n",
       "           -3.4671e-01, -8.2042e-03,  3.0891e-01,  6.1628e-03, -6.5105e-02,\n",
       "           -4.3070e-02,  1.3572e-02,  2.9946e-02, -6.7387e-02, -5.4173e-01,\n",
       "           -4.4298e-02, -3.9147e-01, -4.8178e-02, -6.9420e-02, -3.2726e-02,\n",
       "            2.7457e-02,  4.4940e-02, -4.5032e-02, -5.6367e-02, -4.5911e-02,\n",
       "            4.7119e-02, -1.8057e-01,  1.3902e-01, -5.4884e-02,  2.2797e-02,\n",
       "            2.7053e-02, -4.1190e-01, -2.6492e-01,  7.8569e-01,  3.4568e-02,\n",
       "           -2.5758e-01,  8.7822e-03, -4.5920e-02,  4.8149e-01,  3.3504e-01,\n",
       "           -6.9208e-02, -6.8407e-02, -2.2450e-01,  4.9781e-01,  4.2625e-02,\n",
       "            8.0794e-03, -4.0104e-02,  8.9671e-02,  8.5661e-01, -1.5906e-02,\n",
       "           -3.1331e-02, -7.3945e-02, -7.3576e-02, -3.5776e-03, -7.2579e-02,\n",
       "            5.2194e-01,  3.8680e-02, -4.8871e-02, -3.6118e-01, -1.9287e-02],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-5.6173e-02, -6.9980e-02, -4.1216e-02,  4.0890e-02,  8.0131e-02,\n",
       "            4.8396e-02, -8.0523e-03, -4.4977e-02,  4.6549e-02, -4.4919e-02,\n",
       "            1.1109e-01,  2.4675e-02,  1.7418e-02,  5.6615e-02,  3.4575e-02,\n",
       "            5.4868e-02, -2.4653e-02, -2.6995e-02,  4.1602e-01, -7.6860e-03,\n",
       "           -6.2504e-02,  4.1125e-02,  5.0324e-02, -5.4058e-02,  1.5157e-02,\n",
       "            1.6778e-01,  3.4052e-02,  4.5986e-02,  7.4269e-02,  2.8730e-02,\n",
       "            5.5307e-02, -4.3698e-02, -2.4410e-03, -6.9711e-02,  4.6136e-02,\n",
       "            3.5087e-02,  4.1632e-02, -4.0418e-02,  1.4974e-01,  5.9464e-02,\n",
       "           -6.3246e-02,  6.8304e-02, -3.2464e-01,  4.1020e-02,  2.7903e-02,\n",
       "            2.0710e-01,  4.0248e-02, -7.9956e-02, -4.4222e-02,  4.0978e-02,\n",
       "            1.2924e-01, -4.0129e-02,  5.1227e-02,  4.6615e-02, -5.1906e-02,\n",
       "            5.7050e-02,  7.6933e-01, -5.8855e-02,  8.5276e-02, -6.2054e-02,\n",
       "            6.0794e-02, -5.0646e-02,  2.4453e-02, -4.5781e-02, -3.6367e-02,\n",
       "           -4.4992e-02,  5.2597e-02,  1.1833e-01, -1.2311e-03,  3.0940e-02,\n",
       "            4.2443e-02,  1.8286e-01,  1.8317e-02,  2.5687e-02, -5.0602e-02,\n",
       "           -4.7020e-02, -2.2127e-01,  4.1344e-02,  3.1507e-01, -8.2882e-02,\n",
       "            5.6393e-01, -1.1061e-02, -4.2798e-02, -6.6488e-02, -2.8869e-02,\n",
       "            1.3596e-02,  6.7179e-02, -5.1623e-02, -4.8884e-02,  2.9329e-02,\n",
       "           -2.3380e-02,  4.3894e-02,  2.7713e-02,  6.6251e-02, -7.5245e-03,\n",
       "            2.5340e-02, -6.0265e-02,  4.0724e-02,  3.9173e-02,  6.4419e-02,\n",
       "            4.2985e-02, -3.9489e-03,  3.4489e-02, -6.6476e-02, -1.5037e-01,\n",
       "           -1.2811e-01,  2.9575e-02, -1.8270e-02,  5.7805e-02,  1.0913e-01,\n",
       "            5.3557e-02, -3.6848e-03, -5.9456e-02, -1.1887e-01, -3.7334e-01,\n",
       "           -4.6118e-02, -1.0885e-01,  1.0911e-03, -3.1891e-02, -1.3850e-02,\n",
       "           -8.4957e-02,  6.4802e-04, -6.8945e-02, -5.1298e-02, -1.1915e-02,\n",
       "           -3.0455e-02,  4.0742e-02, -6.0570e-02,  2.6408e-02,  8.8017e-03,\n",
       "            2.2380e-01,  2.5368e-02, -5.8158e-02, -5.3227e-02, -4.3346e-02,\n",
       "           -3.1504e-03,  2.7348e-03, -9.8331e-02,  2.1344e-02, -1.2749e-01,\n",
       "            9.7784e-02,  3.5058e-02, -9.2198e-02,  2.1640e-02, -6.1832e-02,\n",
       "           -1.9855e-02,  1.0837e-01, -4.7460e-02,  1.4958e-01, -5.4979e-02,\n",
       "           -2.6042e-01,  1.5805e-01,  6.6646e-02,  9.6732e-02, -1.0558e-02,\n",
       "            6.6706e-02, -1.0632e-02,  2.6815e-02, -5.6022e-02, -2.6574e-02,\n",
       "           -3.9110e-02, -5.0685e-02,  5.7139e-02,  3.9173e-04, -4.5616e-02,\n",
       "            4.5290e-03, -1.8797e-02,  3.9524e-02,  4.1761e-02, -4.7216e-02,\n",
       "           -6.4646e-02, -6.2723e-02, -4.3835e-02,  4.4073e-02, -4.9335e-02,\n",
       "            1.6153e-01,  3.4051e-02,  6.5348e-02,  2.9855e-02,  1.4711e-01,\n",
       "            8.2641e-02,  2.5587e-02,  4.9904e-02, -3.9564e-02, -1.0351e-01,\n",
       "            3.3849e-02,  4.1266e-02,  3.2274e-02, -4.4174e-02,  7.0083e-02,\n",
       "           -5.1306e-02, -2.9147e-03,  7.2100e-02,  3.8582e-02,  2.3614e-02,\n",
       "           -2.1168e-02,  8.2960e-02,  5.0361e-02,  4.1311e-02,  4.9942e-02,\n",
       "            5.0046e-02,  6.5043e-02,  5.9288e-02,  9.3514e-02,  5.6388e-02,\n",
       "            3.9261e-02, -6.1666e-02,  2.3896e-02, -1.3601e-02,  9.4515e-02,\n",
       "            4.2274e-02, -4.0837e-02, -1.3925e-01,  1.3930e-02,  4.0224e-02,\n",
       "            2.2754e-01, -1.5072e-02,  3.5494e-02, -5.2365e-02,  5.8178e-02,\n",
       "            4.4243e-02, -4.0871e-02, -4.1509e-03, -3.9827e-02, -1.3097e-01,\n",
       "           -1.9171e-01,  2.8843e-02,  8.8128e-02, -2.4150e-01, -5.6548e-02,\n",
       "            2.1974e-01, -4.5056e-02, -4.2929e-02,  2.7279e-01,  2.5804e-03,\n",
       "           -2.1646e-01, -2.6986e-01, -4.8763e-02, -2.6427e-02,  2.6658e-02,\n",
       "            2.6977e-02, -4.8256e-02,  4.3014e-02, -1.2002e-01,  5.3788e-02,\n",
       "           -3.7709e-02, -6.9841e-02,  6.1446e-02,  7.0427e-02, -2.1651e-02,\n",
       "            1.1732e-01, -2.3853e-01, -2.9383e-02, -5.1554e-02,  3.7533e-02,\n",
       "            6.5082e-02,  5.1007e-02, -2.9579e-02,  3.6570e-02,  5.0491e-02,\n",
       "            5.2363e-02,  2.1651e-02, -8.7828e-02, -1.9473e-01, -3.6202e-02,\n",
       "           -3.7511e-02,  1.2950e-02, -1.6947e-02,  7.0428e-02,  3.4806e-02,\n",
       "            4.3324e-02, -4.1035e-02, -3.3172e-02, -1.2811e-01, -8.6719e-02,\n",
       "            2.9229e-02,  5.2363e-02,  3.0968e-02,  2.3227e-02,  1.4637e-01,\n",
       "           -5.8168e-02, -4.4822e-02,  4.5387e-02,  2.7381e-02, -2.4467e-02,\n",
       "            1.1791e-01, -1.3509e-01, -5.0880e-02,  4.7057e-02, -4.8267e-02,\n",
       "            6.5615e-01, -1.9166e-02,  5.1031e-02,  3.7759e-02,  5.5496e-01,\n",
       "            1.7146e-01,  1.1488e-01, -2.5977e-01, -2.4240e-02,  5.9207e-02,\n",
       "           -7.6654e-02, -6.5549e-02, -8.3515e-02, -5.3006e-02,  1.0281e-01,\n",
       "            7.7955e-02,  1.0060e-01,  1.6202e-01,  1.7066e-01, -1.5263e-02,\n",
       "           -4.9963e-02,  7.5027e-02, -6.6404e-02, -4.6554e-02, -1.9742e-01,\n",
       "           -4.1727e-03, -4.5985e-02, -5.0577e-02, -4.6404e-02,  8.5138e-02,\n",
       "            3.1749e-02, -2.6707e-05,  1.1790e-02, -9.4987e-02, -5.5095e-02,\n",
       "            5.2071e-02,  4.7611e-01,  3.8348e-02,  1.0135e-01,  1.9837e-01,\n",
       "            5.2653e-02,  4.2327e-02, -3.6665e-02,  1.6328e-02,  2.3949e-01,\n",
       "           -1.1898e-02,  4.4611e-02,  4.4068e-02,  4.2368e-02,  5.0896e-02,\n",
       "            8.1329e-03, -1.8444e-02, -1.1210e-01, -4.9029e-02, -4.9280e-02,\n",
       "            1.7363e-02, -1.4684e-03,  1.5436e-04,  7.0414e-03, -1.5200e-02,\n",
       "           -7.1081e-02, -7.1595e-03, -2.7705e-02,  4.6598e-02,  3.2328e-02,\n",
       "            1.5729e-01, -6.4198e-02, -5.1057e-02,  3.9751e-02, -1.1860e-01,\n",
       "           -5.2188e-02,  2.8115e-02, -2.8208e-02, -4.8098e-02, -1.9765e-01,\n",
       "           -2.2158e-02,  5.5514e-02,  4.0711e-02,  4.7558e-02,  5.2150e-02,\n",
       "           -1.3915e-02, -5.6077e-02, -4.6736e-02, -1.3625e-01,  1.0387e-01,\n",
       "            4.6663e-03, -3.9010e-02,  1.3040e-02,  2.6183e-03, -6.8839e-02,\n",
       "           -2.3510e-03,  7.0963e-02, -3.9007e-02,  7.3884e-02, -6.1624e-02,\n",
       "            9.4296e-03, -3.4705e-01, -1.0196e-01,  5.1898e-02,  7.7799e-02,\n",
       "           -6.8367e-02, -4.3440e-02, -3.5064e-02,  1.6054e-01, -5.0607e-02,\n",
       "           -7.4840e-02,  7.2741e-02, -4.5387e-02, -3.6610e-01,  9.7637e-03,\n",
       "           -3.3404e-02,  3.0511e-02,  8.2040e-02,  5.1015e-02, -4.1027e-02,\n",
       "            2.0860e-02, -4.5070e-02, -4.7737e-02,  8.2662e-02,  5.9505e-02,\n",
       "           -5.6811e-02,  4.3514e-02, -1.3342e-02, -4.4702e-02,  5.4534e-02,\n",
       "           -8.4251e-02,  3.0195e-02, -4.4161e-02, -4.9184e-02, -5.0546e-03,\n",
       "           -4.9687e-01, -4.7036e-02, -1.9963e-02,  4.0778e-02, -1.4147e-01,\n",
       "           -1.5241e-01,  2.8812e-02,  5.0926e-02,  4.4555e-02, -7.0503e-02,\n",
       "            4.9638e-02, -4.6364e-02, -7.2447e-02, -8.9658e-03, -1.0273e-01,\n",
       "           -1.7583e-01,  7.4664e-02, -5.0985e-02,  3.0245e-02,  7.1211e-02,\n",
       "            5.0451e-02, -6.8233e-02,  2.1776e-02, -3.4754e-02, -2.9572e-02,\n",
       "           -5.3912e-02, -1.9349e-01,  7.4888e-02, -8.0976e-02,  8.6501e-03,\n",
       "           -7.0933e-02,  5.1168e-02,  2.2898e-02, -5.1203e-02, -6.2281e-02,\n",
       "            6.0605e-03, -3.9190e-02, -7.6251e-02, -2.9839e-03,  1.4566e-02,\n",
       "            5.3064e-03,  1.3384e-01,  2.6558e-01,  4.7461e-02,  3.7933e-02,\n",
       "           -5.2428e-02,  4.7926e-02,  3.4915e-02, -9.6058e-03, -1.0664e-02,\n",
       "           -4.1254e-02,  5.4879e-04,  4.4445e-02,  2.4961e-02, -4.9110e-02,\n",
       "            6.9962e-02,  1.4456e-02, -1.5775e-02, -7.4851e-02,  4.2814e-02,\n",
       "           -8.5265e-02,  1.2366e-02,  8.7233e-02,  7.3929e-03, -1.1270e-02,\n",
       "           -1.7555e-01,  8.3716e-03,  8.4276e-02, -2.2401e-02,  5.2730e-02,\n",
       "           -1.6713e-02,  6.8273e-02, -2.7525e-02, -4.3784e-02, -8.0759e-02,\n",
       "            2.4282e-02,  6.0492e-01,  7.7846e-02, -3.6900e-02, -8.0522e-03,\n",
       "           -6.0477e-02, -2.5497e-02, -1.6372e-01,  6.3106e-02, -5.3692e-02,\n",
       "           -9.3976e-04,  4.9182e-02, -2.9918e-02, -2.8580e-02,  6.5637e-02,\n",
       "           -4.2124e-02,  2.1766e-01], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 3.8750e-01,  5.7169e-01, -5.1649e-01,  4.3595e-01,  2.2830e-02,\n",
       "           -5.0278e-01, -5.5323e-02,  3.1553e-01, -6.3976e-01, -2.5532e-01,\n",
       "            1.9431e-01, -4.5440e-01, -2.5611e-01, -4.6343e-01,  3.5732e-01,\n",
       "            1.8960e-01, -1.6451e-01,  9.6825e-02,  1.5151e-01,  6.0627e-01,\n",
       "            1.0421e-01,  5.3560e-01, -2.0350e-01, -4.4776e-01, -1.8174e-01,\n",
       "            1.3733e-01, -5.3848e-01,  2.7526e-01,  1.5973e-01,  3.7255e-01,\n",
       "           -7.2661e-01, -1.1605e-01,  6.8405e-01,  1.8313e-01,  1.0356e-01,\n",
       "            7.9946e-01,  2.1921e-01,  9.7979e-02,  8.2292e-02,  1.8805e-01,\n",
       "           -9.5171e-03,  6.4058e-01,  8.7528e-01,  5.5594e-01, -4.8489e-01,\n",
       "            5.3611e-01, -7.7462e-02, -5.8110e-02, -6.5865e-01, -2.6571e-02,\n",
       "            5.5156e-02, -2.2841e-01,  1.4378e-01,  9.3972e-01, -3.9215e-01,\n",
       "            1.8066e-01,  5.6661e-01,  6.9374e-02, -6.8474e-01,  5.4848e-01,\n",
       "           -8.4631e-02,  1.5977e-01,  3.0492e-01, -6.5422e-01,  2.5070e-02,\n",
       "           -6.3921e-01,  3.7426e-01,  2.7017e-01, -4.1137e-01,  8.5415e-01,\n",
       "           -1.6138e-01, -4.2361e-01,  6.8064e-01, -3.9816e-01,  6.1601e-02,\n",
       "            6.5399e-01,  5.1429e-01,  3.5846e-01, -1.0015e-01, -2.0426e-01,\n",
       "            4.9672e-01, -2.8201e-01, -3.9378e-01,  2.0066e-01,  2.5620e-01,\n",
       "            4.6450e-01, -4.6102e-01,  3.5615e-01, -3.3787e-01, -1.4197e-01,\n",
       "           -1.2267e-01,  7.4373e-02, -2.9599e-01,  2.1560e-01, -2.4761e-01,\n",
       "           -1.1054e-01, -8.6029e-01,  9.9742e-02, -5.2352e-01,  1.6868e-01,\n",
       "            2.4466e-01,  2.7603e-01, -2.1495e-01,  6.3016e-01,  7.0476e-02,\n",
       "           -1.9913e-01,  6.3505e-01,  3.1366e-01,  7.0211e-02, -2.1495e-02,\n",
       "           -5.9934e-01,  3.1070e-02,  3.5677e-01, -1.7645e-01, -1.7737e-03,\n",
       "           -1.9242e-01, -2.4946e-01,  6.9783e-01, -5.5421e-01, -3.9196e-01,\n",
       "           -6.0775e-01, -2.5119e-01,  1.5225e-01, -4.6303e-02, -6.6726e-01,\n",
       "            9.3280e-02,  3.7210e-01, -1.8034e-01, -4.6163e-01,  8.8302e-01,\n",
       "           -3.5646e-01,  1.5083e-01, -4.8994e-01,  6.0371e-02,  6.7764e-01,\n",
       "           -1.2166e-01, -2.1519e-01,  2.2205e-01, -1.0877e-01,  1.7238e-01,\n",
       "            4.2478e-01,  1.5304e-01,  1.5062e-01,  3.3588e-01,  3.8081e-01,\n",
       "           -4.3651e-01,  1.1102e-01, -3.5487e-01, -5.8111e-02, -5.0562e-01,\n",
       "            7.0590e-01, -1.1373e-01,  2.6326e-01, -5.5427e-01,  1.9137e-02,\n",
       "           -4.9961e-01, -9.8538e-02,  1.4418e-01, -4.4169e-02,  7.3693e-02,\n",
       "           -1.3799e-01,  3.0356e-01,  2.8151e-02,  2.4922e-01, -1.3629e-01,\n",
       "           -4.4114e-01,  3.8010e-01,  1.4960e-01, -1.2482e-01, -6.0032e-01,\n",
       "            5.4819e-01, -2.8397e-01,  6.4399e-01, -5.0023e-01, -5.4249e-01,\n",
       "            7.7594e-01,  7.4207e-01, -1.8993e-01, -2.9684e-01, -3.6062e-01,\n",
       "           -5.5435e-01,  3.7427e-01, -6.6636e-01, -6.0101e-01, -2.5330e-01,\n",
       "            6.7633e-01, -4.9339e-01, -2.0627e-02, -1.3184e-01,  5.1495e-01,\n",
       "            2.4604e-01, -3.2630e-01,  3.2298e-01,  3.8245e-01, -1.3346e-01,\n",
       "            7.1493e-02,  5.5829e-01,  7.2101e-01,  6.7705e-01,  1.6765e-01,\n",
       "            3.6482e-01,  2.2395e-02,  4.1899e-01, -5.5140e-01, -1.9073e-01,\n",
       "            3.4277e-01, -4.6356e-01,  6.0486e-01, -2.6007e-01, -1.1756e-01,\n",
       "            9.5719e-01, -2.9950e-02,  3.1629e-01, -7.7834e-02,  5.4216e-01,\n",
       "            3.0534e-01,  6.9477e-01,  7.1198e-02,  2.1126e-01, -4.5063e-02,\n",
       "            4.1543e-01,  3.7659e-03, -2.5885e-01,  6.7587e-01,  5.8214e-01,\n",
       "           -8.5702e-02,  1.0961e-01,  7.9362e-01, -1.7582e-01,  3.3768e-01,\n",
       "           -4.2890e-01,  3.5951e-01, -7.0592e-02, -1.2939e-01, -1.3909e-01,\n",
       "            4.0352e-01, -7.1978e-01,  2.8203e-01, -7.5979e-02,  6.5330e-01,\n",
       "           -1.0728e-01, -9.1330e-02,  3.5895e-01, -7.9734e-02, -6.6570e-01,\n",
       "            1.8429e-02, -1.1765e-01,  5.7662e-01,  3.1193e-01,  6.3526e-01,\n",
       "            4.9515e-01,  3.9657e-01,  7.2606e-01, -1.0021e-02,  2.7616e-02,\n",
       "            3.6281e-01, -5.0959e-01,  6.7726e-01,  1.0619e-01,  1.6165e-01,\n",
       "            7.1463e-01,  2.1377e-02, -2.6405e-01,  5.4631e-01, -5.6651e-01,\n",
       "           -4.9097e-01,  3.3171e-02,  7.9504e-01,  3.0775e-01,  6.0131e-01,\n",
       "           -3.5886e-02,  5.0885e-01,  1.4650e-02, -4.2643e-01, -1.6141e-02,\n",
       "           -3.1336e-01,  1.7360e-01,  5.9304e-01, -1.2471e-01, -7.7990e-04,\n",
       "           -4.1233e-01, -2.6939e-03,  2.0084e-01, -2.9618e-01, -3.5828e-01,\n",
       "            1.5268e-01,  1.7749e-02,  1.2811e-01,  8.2336e-02,  5.1777e-01,\n",
       "            3.5661e-01, -3.4763e-01,  3.2256e-01,  3.8160e-01, -3.8614e-01,\n",
       "            4.5973e-03, -2.0868e-01, -7.9809e-02,  6.9989e-01, -7.9495e-02,\n",
       "            5.2815e-01, -1.2387e-01, -2.8621e-01, -5.5234e-01,  3.6818e-01,\n",
       "            3.4873e-01,  2.2766e-01,  7.2820e-01,  7.2378e-01,  7.4880e-01,\n",
       "           -5.7760e-01, -3.0131e-01, -4.5288e-01,  3.6495e-01,  1.4104e-01,\n",
       "           -5.3919e-01, -1.5720e-01,  4.9568e-01,  4.4356e-01, -2.2130e-01,\n",
       "            1.7137e-01, -3.3503e-01, -5.8427e-01,  9.5558e-01,  1.2590e-02,\n",
       "            7.6069e-01, -1.6365e-02,  3.0562e-01,  1.0076e+00, -5.3810e-01,\n",
       "            6.6539e-01, -1.8055e-01,  6.6336e-01,  6.5723e-01, -4.1536e-01,\n",
       "           -4.9006e-02,  3.4021e-02,  2.8345e-01,  6.8383e-01,  6.4714e-01,\n",
       "            1.1758e-01,  4.3490e-02,  6.5201e-01, -1.3702e-02,  2.3129e-01,\n",
       "            4.1589e-01, -8.4404e-02, -1.2438e-01,  1.0662e-01, -4.6385e-02,\n",
       "            4.3506e-01,  9.9960e-02,  4.6929e-01,  3.3266e-02,  8.0582e-01,\n",
       "           -1.2348e-01,  5.6370e-01,  4.6863e-01, -2.9459e-01,  3.9680e-03,\n",
       "            7.4634e-01,  6.9562e-01, -7.6605e-01,  1.6097e-01, -5.7451e-01,\n",
       "           -3.9059e-01,  7.2285e-01,  4.9494e-03, -6.3012e-01, -2.3572e-01,\n",
       "           -4.5713e-01,  5.0178e-01,  3.5652e-01, -4.0494e-01, -8.1291e-02,\n",
       "            2.4978e-01,  6.4419e-01,  1.6118e-03, -3.4787e-01, -5.4538e-01,\n",
       "            3.6740e-01, -3.2055e-01, -2.7073e-01, -4.4862e-01,  1.3965e-01,\n",
       "           -5.7085e-01,  1.1792e+00,  2.3281e-01, -2.4698e-01, -6.3200e-01,\n",
       "            3.5464e-02, -6.2193e-01,  1.3242e-01, -6.7813e-01,  3.3443e-01,\n",
       "            2.0271e-01, -1.1092e-01,  3.1436e-01,  4.3800e-03, -1.9390e-01,\n",
       "           -1.6486e-02, -2.8260e-01,  7.3573e-03, -1.2025e-01,  1.8139e-02,\n",
       "            7.5378e-01,  1.8699e-01, -6.3783e-02, -1.7566e-01, -4.1142e-01,\n",
       "           -5.4069e-01,  5.0242e-01,  4.0349e-01, -3.0026e-01, -2.0812e-02,\n",
       "            5.0393e-01,  3.5558e-01,  7.1493e-01,  6.0616e-01,  1.5437e-01,\n",
       "           -2.6141e-01,  6.7779e-01,  5.5994e-01, -2.4548e-01,  2.7973e-01,\n",
       "            9.5145e-01,  2.2106e-02, -5.9431e-01,  1.2016e-02,  4.1033e-01,\n",
       "            5.1749e-02, -6.2371e-01, -2.8514e-01, -4.9167e-02, -6.6267e-01,\n",
       "           -2.6883e-01,  2.9542e-01, -3.0984e-01, -3.8192e-01,  1.5935e-01,\n",
       "           -3.3370e-01,  1.2131e-01,  2.7436e-01,  8.8581e-01,  1.1614e-02,\n",
       "           -4.4165e-01, -5.7938e-01,  4.3084e-01, -1.9279e-01,  1.5428e-01,\n",
       "           -1.8096e-01, -1.9261e-01, -5.2991e-01,  7.3344e-01,  6.8542e-01,\n",
       "            3.7662e-01, -4.4524e-01,  9.3023e-02, -6.1511e-01, -2.3991e-01,\n",
       "            2.4669e-01, -1.8084e-01, -2.0094e-01,  6.7059e-01,  3.1708e-01,\n",
       "           -2.9385e-01, -5.8315e-01,  6.9328e-01,  1.5006e-01,  5.5298e-01,\n",
       "            5.0917e-01,  2.9140e-01,  4.4642e-01,  2.6226e-01, -2.6976e-01,\n",
       "            8.9453e-02, -1.0383e-02,  4.5339e-01, -5.5632e-01,  1.1836e-01,\n",
       "           -1.2755e-01, -1.5780e-02, -5.1623e-01,  8.5460e-01, -2.9023e-01,\n",
       "           -3.3925e-01,  1.1071e-01, -3.5480e-01,  7.5992e-03,  1.7852e-01,\n",
       "           -4.7090e-01,  6.8870e-02, -6.5584e-01,  8.7457e-02,  5.8775e-01,\n",
       "            2.6010e-02,  7.5810e-01, -2.4608e-01,  9.6679e-02,  5.3101e-02,\n",
       "           -2.7686e-01,  7.5491e-02,  1.3626e+00, -1.4188e-01,  7.5763e-01,\n",
       "            6.8648e-01,  7.4971e-01, -1.3823e-01,  2.0250e-01,  4.0466e-01,\n",
       "           -4.6196e-01,  1.8646e-02], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-1.1415e-01, -6.0516e-01,  3.5358e-01,  4.6566e-01, -5.2929e-01,\n",
       "           -4.8882e-01,  3.7962e-02, -2.7812e-01, -4.2107e-01, -3.4278e-02,\n",
       "            3.5302e-01, -4.1179e-01, -1.6722e-01,  8.3795e-02,  3.7371e-01,\n",
       "            1.9443e-01,  3.5829e-01,  1.5217e-01,  5.0759e-02, -5.8812e-01,\n",
       "            2.2241e-01,  2.3265e-01, -1.9624e-01,  4.4920e-01, -2.1039e-01,\n",
       "            5.8453e-02,  7.1287e-01,  5.9014e-01, -4.6290e-01, -5.4524e-01,\n",
       "           -6.0304e-01,  3.7788e-01,  6.7351e-01, -2.5136e-01,  2.9748e-01,\n",
       "            6.4890e-01,  4.1211e-01,  4.5071e-01,  3.3782e-01,  4.0054e-01,\n",
       "            2.3885e-01,  6.5990e-01,  7.0850e-01,  4.4181e-01, -5.6329e-01,\n",
       "           -3.5558e-01,  4.3467e-02, -2.9670e-01,  4.8018e-01,  2.8141e-01,\n",
       "           -4.5506e-01,  2.3749e-01, -2.1074e-01,  5.2403e-01,  2.4588e-01,\n",
       "            7.4683e-02,  5.1596e-01, -1.5731e-01,  8.3068e-01, -6.5034e-01,\n",
       "           -8.3907e-02, -3.1976e-01,  3.5940e-01,  1.7822e-01,  9.8952e-03,\n",
       "            5.2702e-01,  3.2941e-01, -6.0017e-01, -3.6688e-01,  7.5382e-01,\n",
       "           -4.2036e-01, -5.3635e-01,  5.4724e-01,  4.6327e-01, -2.0480e-01,\n",
       "           -6.3811e-01, -5.5040e-01,  3.4592e-01,  6.1889e-01,  2.3697e-01,\n",
       "           -5.4838e-01,  5.2776e-01,  2.3759e-01, -1.2605e-01, -2.5600e-01,\n",
       "            3.1650e-01, -4.6606e-01, -3.8375e-01,  4.5493e-01, -1.2110e-01,\n",
       "           -7.0115e-01,  7.8764e-01, -5.1604e-01,  3.4747e-01,  5.6171e-01,\n",
       "           -1.2450e-01,  8.0204e-01, -6.3727e-01, -3.2430e-01,  4.1424e-01,\n",
       "            2.1669e-01, -3.5954e-01, -2.8186e-01, -7.1283e-01,  2.8116e-01,\n",
       "            1.7890e-01,  6.9399e-01, -1.9604e-02,  1.5958e-01,  2.0094e-01,\n",
       "           -6.6030e-01,  6.5509e-02, -4.7356e-01,  3.0563e-01, -2.7021e-01,\n",
       "           -2.9228e-01, -2.7502e-01, -7.6142e-01,  4.3570e-01,  6.3249e-01,\n",
       "            8.9552e-02, -4.8891e-01,  6.5846e-02,  2.5203e-01,  5.5604e-01,\n",
       "           -3.7361e-01,  4.9672e-01,  4.1561e-01, -3.1332e-01,  7.8825e-01,\n",
       "           -3.5140e-01,  4.7974e-01,  1.8958e-01,  9.2934e-03, -7.3098e-01,\n",
       "            4.6938e-01, -1.5853e-01, -1.9304e-01, -3.9265e-01,  5.5165e-01,\n",
       "            1.1092e-01,  3.1597e-01, -4.3241e-01, -1.9205e-01, -3.0109e-01,\n",
       "            1.4630e-01,  2.5484e-01,  3.9750e-01,  1.5147e-01,  2.2975e-01,\n",
       "            6.6855e-01,  1.0645e-01,  1.1342e-01, -6.6870e-01,  7.7497e-01,\n",
       "           -2.8048e-01, -9.7055e-02, -1.1053e-01,  1.1645e-02, -4.9689e-01,\n",
       "           -2.7448e-01, -6.0781e-01, -6.4443e-02, -6.4904e-02,  9.2625e-04,\n",
       "            5.3927e-01, -3.9963e-01,  4.0190e-01,  2.1413e-01,  4.3011e-01,\n",
       "           -5.6118e-01,  3.3005e-01, -7.2049e-01, -2.4357e-01,  3.1343e-01,\n",
       "           -6.9090e-01,  5.3888e-01, -8.7371e-02, -5.0979e-01, -2.1912e-01,\n",
       "            2.2522e-01, -1.7276e-01, -5.4268e-01,  5.2007e-01,  4.2174e-01,\n",
       "            6.1401e-01, -3.2612e-01, -3.6497e-01, -1.6799e-01,  8.8109e-01,\n",
       "           -6.0773e-02,  5.4947e-01,  7.0319e-01, -4.7897e-01, -3.1246e-01,\n",
       "           -3.2434e-01,  5.0289e-01, -4.4921e-01,  2.3948e-01,  2.1316e-01,\n",
       "            4.5526e-01, -2.5668e-01,  5.2536e-01, -4.4721e-01,  9.8764e-02,\n",
       "            2.2694e-01,  6.1196e-01,  3.4024e-01,  4.9597e-01, -5.4057e-01,\n",
       "            5.3212e-01, -2.9146e-01, -4.4477e-01,  3.6637e-01,  6.3333e-01,\n",
       "           -4.9329e-01,  6.7236e-01, -8.6725e-04, -2.8258e-01, -3.8894e-01,\n",
       "            6.6078e-01, -3.6601e-02, -1.2768e-01, -6.1195e-01, -6.0708e-01,\n",
       "            4.7261e-01, -5.8504e-02,  5.3426e-01,  3.5755e-01, -5.6842e-01,\n",
       "           -5.4367e-01, -3.6612e-01, -5.2466e-01, -7.3719e-01, -2.5196e-02,\n",
       "            4.2613e-01,  5.4513e-01, -5.6829e-01, -2.6943e-01, -6.0083e-01,\n",
       "            1.3823e-01,  1.7744e-01,  1.7917e-01, -3.6708e-01, -5.6953e-01,\n",
       "            2.3043e-01,  3.3448e-01,  5.7735e-01,  3.9630e-01, -5.2551e-01,\n",
       "            4.8114e-01,  2.5672e-01, -5.4001e-01, -2.9570e-01,  1.3815e-01,\n",
       "            4.3607e-01, -4.3549e-01, -6.5341e-01,  1.7465e-02,  6.9013e-02,\n",
       "            5.4009e-01,  8.3225e-03,  3.2730e-01, -2.3281e-01,  4.4459e-01,\n",
       "            5.7792e-01,  1.2527e-01, -7.1533e-01,  4.3749e-01,  1.5414e-01,\n",
       "            1.0216e-01, -4.8899e-01,  1.2579e-01, -6.7746e-01, -2.6040e-01,\n",
       "           -1.6747e-01,  6.1293e-02, -3.8463e-01, -8.9207e-02,  2.6723e-01,\n",
       "           -7.7044e-01,  5.5310e-01, -1.0230e-01, -4.3636e-01,  5.9955e-01,\n",
       "            2.5816e-01,  2.4597e-01,  8.9497e-02,  2.2964e-01, -1.9155e-01,\n",
       "            6.3966e-01, -2.4036e-01,  2.5743e-01,  2.7994e-01, -4.7417e-01,\n",
       "           -5.3863e-01, -1.9023e-01, -1.9278e-01, -4.7853e-01, -1.6003e-01,\n",
       "           -6.4758e-01,  1.0521e-01, -5.8757e-01,  5.5157e-01, -7.1046e-01,\n",
       "            7.2623e-01,  3.0083e-02, -5.7255e-01, -7.8006e-01, -6.6080e-01,\n",
       "            6.3838e-01, -2.2160e-01,  6.1520e-01, -5.4085e-01, -2.2050e-01,\n",
       "            4.5677e-01,  9.6892e-02, -1.8658e-01, -1.5601e-01, -2.5947e-01,\n",
       "            2.0844e-01,  4.0559e-02, -5.5601e-01, -6.5373e-01,  2.5604e-01,\n",
       "            5.7373e-01, -4.4239e-02,  3.6789e-01,  8.9401e-01, -4.4162e-01,\n",
       "            7.0293e-01, -1.5248e-02, -7.0542e-01,  5.5271e-01,  4.4647e-01,\n",
       "            3.7730e-01, -1.4092e-01,  6.2953e-02,  2.8239e-01,  4.3772e-01,\n",
       "            3.9691e-01,  1.3060e-01,  6.9285e-01,  3.7632e-02, -5.1892e-01,\n",
       "            4.5968e-02, -4.9591e-02,  2.8038e-01, -2.6963e-01,  4.3055e-01,\n",
       "           -5.0766e-01,  6.9728e-01, -3.0242e-01,  4.6583e-01,  5.0310e-01,\n",
       "           -4.0261e-01, -2.7145e-01, -6.4572e-01, -3.1401e-01, -8.3041e-02,\n",
       "           -4.5617e-01, -6.2186e-01,  5.7145e-01, -1.9490e-01,  5.0421e-01,\n",
       "            3.0482e-01,  7.1692e-01, -1.6796e-01, -4.9030e-01, -4.9547e-01,\n",
       "            5.0758e-01,  4.4263e-01, -2.7140e-01,  5.0210e-01,  6.6353e-02,\n",
       "            4.3081e-01, -5.1253e-01, -6.6640e-02,  6.5460e-01,  3.2797e-01,\n",
       "            3.0156e-01, -2.6065e-01,  6.3407e-01, -4.8031e-01, -2.2264e-01,\n",
       "           -4.0401e-01, -9.1946e-01, -4.0953e-01, -2.1441e-01, -6.8440e-01,\n",
       "            3.1138e-01,  5.8761e-01, -2.0688e-02,  4.9518e-01, -1.5819e-01,\n",
       "           -2.0203e-01, -3.4848e-01, -4.9833e-01, -1.3166e-01, -6.4707e-01,\n",
       "            9.7121e-02,  2.1477e-01,  2.6130e-01, -3.6130e-01, -9.3106e-02,\n",
       "            4.3881e-01, -2.5241e-01, -1.4861e-01, -5.8173e-02, -6.8325e-01,\n",
       "            7.2145e-01,  6.7591e-01,  8.4615e-02,  2.7822e-01,  6.0650e-01,\n",
       "            4.8161e-01,  4.3400e-01, -5.9216e-01, -5.2458e-01, -3.5376e-01,\n",
       "           -9.5947e-02, -4.0382e-01, -4.5542e-01, -1.2664e-01, -4.2665e-01,\n",
       "           -7.1701e-01, -2.7923e-02, -4.5946e-02,  4.8553e-02, -7.1520e-01,\n",
       "            1.5952e-01,  3.2408e-01, -1.6458e-02,  5.5035e-01,  4.7340e-01,\n",
       "           -2.5757e-01,  2.6672e-01,  4.5104e-01,  2.4601e-01,  5.7133e-03,\n",
       "           -2.5458e-01, -8.8129e-02,  2.3699e-01, -5.5722e-01, -5.6573e-01,\n",
       "            4.0526e-01,  3.7584e-01,  3.2211e-01,  4.3472e-01, -1.3059e-01,\n",
       "            5.1888e-01, -1.6539e-01, -4.5948e-01, -7.3432e-01, -6.0246e-01,\n",
       "            4.6263e-01,  4.1038e-01, -3.1693e-01, -6.7068e-01, -3.2558e-01,\n",
       "           -7.1593e-03, -3.4976e-01, -5.1133e-01,  2.7110e-01,  2.6357e-01,\n",
       "            5.7008e-02, -4.9296e-01,  4.0198e-01, -3.4564e-01, -5.9882e-01,\n",
       "           -4.2602e-01, -6.2064e-01,  4.6745e-01,  4.6289e-01,  1.2474e-01,\n",
       "           -4.6442e-01, -4.4026e-01, -7.5152e-01,  4.8216e-01,  2.2097e-01,\n",
       "            4.3977e-01,  6.4091e-02, -5.8184e-01,  6.9109e-01, -2.7923e-01,\n",
       "            3.3763e-02,  2.4029e-01, -3.8814e-01,  3.6010e-01,  2.1262e-01,\n",
       "            6.9149e-01, -3.7068e-01,  4.0192e-01, -7.0313e-02,  5.4782e-01,\n",
       "           -4.2882e-02, -8.0853e-01, -5.2225e-01,  2.9970e-02, -7.2012e-02,\n",
       "            2.0104e-02,  2.8936e-01,  1.0028e+00,  2.5937e-01, -2.7803e-01,\n",
       "           -5.2525e-01,  8.4688e-01, -5.4470e-02, -1.9551e-01,  4.0824e-01,\n",
       "            1.4382e-01, -4.7953e-01], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-9.6264e-02,  6.7049e-01,  3.7997e-01, -3.0021e-02, -3.8576e-01,\n",
       "           -8.2668e-02,  8.9500e-01, -4.3938e-01, -1.0197e-01,  8.7692e-03,\n",
       "           -8.5349e-01,  3.0281e-01, -5.0397e-01, -2.7227e-01, -7.7426e-01,\n",
       "           -2.1833e-01, -5.6806e-01, -6.7942e-01,  7.5492e-01,  8.7334e-01,\n",
       "            8.7521e-01,  1.0811e-01, -2.6884e-01, -2.2627e-01,  1.3295e-01,\n",
       "            4.3116e-01, -2.2169e-01, -5.9904e-01,  9.2912e-01, -6.9047e-01,\n",
       "           -2.6188e-01,  4.7786e-01,  3.6307e-01,  2.0986e-01, -3.7176e-01,\n",
       "           -6.4589e-01, -5.1509e-02,  1.1090e-01, -2.3653e-01, -3.9460e-01,\n",
       "            1.1543e-01, -9.2292e-03,  9.8364e-01,  8.4130e-02, -6.5948e-01,\n",
       "           -2.2502e-01, -5.9676e-01, -2.3982e-01, -5.1991e-01, -3.6981e-01,\n",
       "            8.0262e-01,  3.7670e-01, -5.4285e-01,  5.7006e-01, -3.7373e-01,\n",
       "            4.3164e-01, -2.4092e-01,  8.1467e-03, -1.6728e-01,  1.0460e-01,\n",
       "           -4.5109e-01, -4.2443e-01, -3.8090e-01, -5.5188e-01,  2.3074e-01,\n",
       "            7.4529e-03,  5.6379e-01,  7.5676e-01, -2.5089e-01,  1.8681e-01,\n",
       "            4.4693e-01,  8.6286e-01, -5.7069e-01, -1.5766e-01, -6.0579e-01,\n",
       "           -6.7437e-01, -2.3312e-01, -6.4095e-01,  9.0122e-01,  1.7373e-01,\n",
       "            9.2547e-01, -5.8247e-01, -3.0554e-02,  2.4831e-01, -5.7670e-01,\n",
       "           -2.5839e-01, -6.0112e-01, -7.9151e-01, -2.3837e-01, -5.5831e-01,\n",
       "            6.0566e-01, -2.6952e-01, -1.3195e-01,  4.0986e-01, -3.3048e-01,\n",
       "            5.9106e-01, -2.5203e-01,  8.0451e-01,  6.7113e-01, -4.2937e-01,\n",
       "           -3.7285e-01, -7.1990e-01,  2.0585e-01, -7.2440e-01,  7.2927e-01,\n",
       "            7.2357e-01,  3.2088e-01,  3.0946e-01, -4.1878e-02, -3.3266e-01,\n",
       "           -5.0470e-01, -3.6631e-01, -1.6576e-01, -2.4635e-01, -1.7258e-01,\n",
       "           -9.9022e-02,  9.1629e-01,  1.5540e-01, -6.1258e-01, -5.0425e-01,\n",
       "            5.1080e-01, -5.7620e-01,  3.6164e-01, -3.9235e-01, -7.8168e-01,\n",
       "           -4.5402e-01,  6.3024e-01, -6.5553e-01, -5.9842e-01, -5.4217e-01,\n",
       "            5.8953e-01, -4.9585e-01,  1.6886e-01, -6.5816e-01, -4.3730e-01,\n",
       "           -6.6703e-01,  7.5845e-02, -1.4789e-01,  6.0059e-01, -5.5343e-03,\n",
       "           -1.8217e-01, -1.3886e-01, -6.9463e-01,  4.7628e-01,  4.2152e-01,\n",
       "           -2.9027e-01, -6.2679e-01,  4.6841e-01, -9.8836e-01, -4.1920e-01,\n",
       "            7.0667e-01, -6.6611e-01,  2.8505e-01,  3.8995e-01, -6.4170e-01,\n",
       "           -2.8678e-01,  3.5602e-01, -6.5097e-01,  1.0758e-02,  1.1873e-01,\n",
       "            6.3451e-01,  6.1202e-01, -4.8790e-01,  8.3600e-01, -5.5133e-01,\n",
       "            3.5809e-01, -1.1053e-01,  7.1296e-01,  4.8341e-01,  2.4209e-01,\n",
       "           -8.5032e-01, -4.6668e-01,  3.7853e-01, -3.9231e-01, -3.9622e-01,\n",
       "            7.2053e-01,  2.7334e-01, -6.1398e-02, -3.8425e-01, -3.1906e-01,\n",
       "           -2.4194e-01,  8.7330e-01, -6.2393e-01,  1.2257e-01,  4.1986e-01,\n",
       "            6.4272e-01, -8.2086e-01, -7.1998e-01,  9.5117e-01, -3.4010e-01,\n",
       "           -4.7145e-01,  3.1842e-01, -1.1213e+00, -3.9579e-01, -6.2863e-01,\n",
       "           -9.4094e-01,  9.0512e-01,  5.8031e-01, -6.9366e-01, -1.9739e-01,\n",
       "           -2.0389e-01,  2.4787e-01, -1.2473e-02,  4.8244e-01, -7.8524e-01,\n",
       "            7.5658e-02, -4.9479e-02,  7.1796e-01, -7.9601e-01,  9.9663e-02,\n",
       "           -5.4119e-01, -1.0215e-01,  3.7168e-01, -6.4020e-01,  2.3663e-01,\n",
       "            1.0851e+00,  9.3777e-01,  4.2084e-01, -3.6848e-01, -1.5038e-01,\n",
       "           -5.4142e-01, -4.2902e-01, -5.0423e-01,  7.4829e-01, -6.7115e-01,\n",
       "            9.0703e-01,  6.4872e-02,  7.6664e-01,  8.5774e-01, -9.2104e-01,\n",
       "            7.3078e-01,  2.9094e-01, -7.1230e-01,  6.3456e-01,  9.0404e-01,\n",
       "            8.5567e-01,  8.4833e-01,  7.6922e-01,  1.4636e-01,  4.3856e-01,\n",
       "            4.1280e-01, -5.0431e-01, -6.1349e-01,  4.0262e-01, -1.5555e-01,\n",
       "            3.3822e-01, -4.8400e-01, -6.0517e-01, -6.1705e-01, -5.9424e-01,\n",
       "           -3.4967e-01,  5.8763e-02, -7.7940e-01,  5.8252e-01, -3.3384e-01,\n",
       "            5.3511e-01, -2.5805e-01, -5.4991e-01,  4.9812e-04,  2.9712e-01,\n",
       "           -2.9269e-01,  1.5678e-02, -5.1813e-01,  2.2206e-01, -1.1129e+00,\n",
       "           -2.8191e-01,  4.5379e-01, -5.6518e-01, -6.6224e-01, -1.7770e-01,\n",
       "            4.9805e-01, -5.3442e-01, -7.5767e-01,  6.0868e-01, -3.8008e-01,\n",
       "            2.6502e-01, -2.1661e-01, -5.7298e-01, -2.3635e-01,  8.5046e-01,\n",
       "            9.5977e-01, -4.2712e-02, -5.8246e-01,  4.1151e-01, -8.4920e-01,\n",
       "           -1.8117e-01, -4.1652e-01, -1.4370e-01, -3.3999e-01, -5.2603e-01,\n",
       "            8.0135e-01,  3.5907e-01, -6.7192e-01, -6.9369e-01,  1.0501e+00,\n",
       "            7.6655e-01, -4.4542e-01,  8.5881e-01, -6.1402e-02, -1.2737e-01,\n",
       "           -4.5149e-01, -5.8506e-01,  7.7846e-01, -7.6197e-01,  3.7455e-01,\n",
       "            4.1145e-01, -2.3471e-01,  8.4827e-01,  8.7306e-01,  1.3892e-01,\n",
       "           -4.4399e-01, -4.6625e-01, -4.5162e-01, -3.9944e-01,  8.8116e-01,\n",
       "            3.4945e-01,  1.3815e-01, -6.4322e-01, -4.5492e-01,  4.5524e-01,\n",
       "           -1.6284e-01, -7.1342e-01,  3.0666e-01, -4.7460e-01, -4.0748e-01,\n",
       "           -3.7214e-01,  8.5561e-01,  2.4550e-01, -2.4037e-01,  8.1361e-01,\n",
       "           -6.5682e-01,  1.1506e-01, -5.5205e-01,  3.5550e-01,  4.8603e-01,\n",
       "           -1.8040e-01, -1.3608e-01, -5.3253e-01,  4.6772e-02,  2.4492e-01,\n",
       "            8.4560e-01, -1.1265e+00,  1.0172e+00,  4.1255e-01, -1.7406e-01,\n",
       "           -4.5477e-01,  1.7927e-01,  4.8695e-01, -7.2098e-01, -4.3709e-02,\n",
       "           -9.5708e-02,  7.6829e-02, -7.0248e-01, -6.8753e-01,  4.9464e-01,\n",
       "           -3.6210e-01, -6.7744e-01, -6.3083e-01,  2.3431e-02, -4.0231e-01,\n",
       "           -1.8653e-01,  6.6858e-01, -6.6025e-01, -7.7307e-01, -5.4272e-01,\n",
       "           -3.5553e-01, -1.6117e-01, -7.0284e-02, -9.3592e-02, -4.1845e-01,\n",
       "            1.1976e-01,  7.9119e-01, -6.9352e-01, -6.5890e-01, -8.6844e-01,\n",
       "           -6.5843e-01, -1.6554e-01, -4.3228e-01,  3.3315e-01, -1.4971e-01,\n",
       "           -1.6733e-02,  3.1891e-01,  1.9091e-01, -4.4924e-01, -3.3413e-01,\n",
       "            1.5091e-01,  9.7622e-01, -2.9365e-01,  1.1556e-01,  2.2465e-01,\n",
       "            2.2579e-01, -7.8391e-02, -6.4510e-01,  8.4914e-01, -6.1900e-01,\n",
       "            4.5399e-01, -4.7719e-01, -2.5122e-01,  1.0107e+00, -6.3902e-01,\n",
       "           -6.9276e-01, -5.8639e-01,  6.0376e-01, -4.3774e-02, -3.1239e-01,\n",
       "           -5.9465e-01, -8.6084e-01,  2.6768e-01, -2.8809e-01,  4.1394e-01,\n",
       "           -1.8284e-02,  6.6955e-01, -2.9444e-01,  2.2816e-01, -5.8540e-01,\n",
       "           -2.4705e-01, -4.5511e-01, -5.6435e-01, -4.9448e-01, -3.6001e-01,\n",
       "            1.0268e+00,  4.7329e-02,  7.0642e-01,  2.8539e-01, -4.5644e-01,\n",
       "            3.9161e-01,  7.7626e-01, -5.7511e-01, -6.7091e-01,  5.2078e-01,\n",
       "           -5.4501e-01,  3.9086e-01,  2.9515e-01, -6.2005e-01,  3.1589e-01,\n",
       "            9.3660e-01, -7.6868e-01, -5.1688e-01, -4.4135e-01,  3.1788e-01,\n",
       "           -5.1006e-01,  4.1173e-01, -6.6913e-01, -7.5833e-01, -2.8934e-03,\n",
       "           -4.6145e-01,  4.4125e-01, -2.6789e-01, -5.2419e-01,  7.6967e-01,\n",
       "            3.8827e-01, -1.8461e-01, -4.7974e-01, -5.1290e-01, -4.7060e-01,\n",
       "            2.3426e-01, -6.8130e-01,  4.5750e-01, -8.7419e-01, -5.5553e-01,\n",
       "           -5.1271e-01,  6.7410e-01,  9.0342e-01, -6.2279e-01,  3.8992e-01,\n",
       "            3.6910e-02, -8.8032e-02,  6.6397e-01,  6.1578e-01,  9.3581e-01,\n",
       "           -3.0105e-01,  7.5853e-01, -5.5391e-01,  6.9093e-01,  4.0211e-01,\n",
       "            5.6007e-03, -6.3625e-02,  4.9427e-02,  4.9694e-02,  4.3172e-02,\n",
       "            2.7785e-01, -7.2591e-01,  2.3055e-01, -1.1308e-01, -1.4942e-01,\n",
       "            8.9728e-01, -6.3512e-01,  3.5563e-01, -4.5364e-01, -7.1491e-01,\n",
       "            4.9435e-01, -3.3623e-01, -7.9757e-01, -3.8361e-01, -3.6804e-01,\n",
       "            1.7107e-01,  2.0939e-01, -6.3039e-01, -7.2453e-01, -2.6758e-01,\n",
       "            3.2639e-01, -4.1925e-01,  5.2397e-01,  3.6049e-01, -1.3817e-01,\n",
       "            6.7303e-01,  5.2146e-01, -2.2104e-01, -4.4644e-01, -5.8594e-01,\n",
       "           -6.3820e-01,  5.6211e-01], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-1.8114e-01, -1.3252e-01,  5.5662e-01, -6.7961e-01,  1.6819e-01,\n",
       "           -2.6937e-01,  6.3410e-01, -1.8218e-01,  2.8627e-01,  3.1552e-01,\n",
       "           -7.8900e-01,  2.3302e-02,  4.7575e-02, -2.2362e-01,  1.1928e-01,\n",
       "           -4.7457e-01, -1.8513e-01, -3.7784e-01,  9.2789e-01,  3.7101e-01,\n",
       "           -9.2061e-01, -3.7151e-01,  9.2136e-01,  4.3354e-02,  2.8743e-01,\n",
       "            5.0288e-01,  3.8030e-01, -4.9196e-01,  6.2056e-01,  5.9703e-01,\n",
       "            2.0852e-01,  5.5422e-01, -6.9516e-01, -1.4584e-01, -6.3059e-01,\n",
       "            5.3093e-03, -6.6390e-01, -6.0306e-02, -9.7716e-02, -5.3643e-01,\n",
       "           -1.0043e-01, -6.8074e-01, -6.8089e-01, -5.6124e-01,  8.1972e-02,\n",
       "           -9.3758e-01,  1.0879e-01,  6.1730e-01, -4.0865e-01,  1.5014e-01,\n",
       "            5.8173e-01, -6.6274e-02,  3.2240e-01, -8.7858e-01,  4.8158e-01,\n",
       "            2.2352e-01,  4.1020e-01,  5.3703e-01, -6.2364e-01,  3.8467e-01,\n",
       "           -1.5740e-01,  5.5628e-01, -2.6077e-01,  1.8672e-01,  6.3079e-01,\n",
       "           -5.7603e-02, -3.4538e-02,  8.7137e-01,  2.5246e-01, -6.3161e-01,\n",
       "           -6.1738e-01,  8.6648e-01,  7.2644e-02,  1.4444e-01,  6.1194e-01,\n",
       "           -5.4790e-02,  2.7782e-01,  1.5227e-01,  7.5406e-01, -2.7820e-01,\n",
       "            8.3410e-01, -1.8436e-01,  2.6071e-01, -1.5314e-01,  2.6148e-01,\n",
       "            2.3309e-01,  2.7004e-01,  5.0136e-01,  5.0876e-02,  1.6543e-01,\n",
       "           -6.7967e-01, -7.1848e-01, -4.0631e-01,  2.2001e-01,  1.9709e-01,\n",
       "           -1.0198e-01,  4.0261e-01, -3.6609e-01, -6.9943e-01,  1.1099e-01,\n",
       "            4.2377e-01,  1.0181e-02,  3.3909e-01,  1.4424e-01, -4.8245e-01,\n",
       "           -1.8358e-01, -5.1847e-01, -4.5901e-01, -1.0769e-01,  1.8426e-02,\n",
       "            3.1848e-02, -1.9861e-02, -1.0811e-01, -4.3855e-01,  6.2206e-02,\n",
       "            7.7659e-01, -4.1129e-01,  6.6144e-01,  2.5659e-01,  2.7780e-01,\n",
       "           -1.9240e-01,  1.2078e-01, -2.5734e-01,  4.1328e-01,  4.4387e-01,\n",
       "           -1.8150e-01, -7.9917e-01, -2.3375e-01,  1.2297e-01,  7.1135e-02,\n",
       "            5.4315e-01,  8.8986e-02, -2.7154e-01, -1.2258e-01,  4.3794e-01,\n",
       "           -9.9557e-02, -7.1747e-01, -3.4695e-01, -6.3134e-01, -4.1042e-01,\n",
       "            2.2924e-01, -4.1793e-01,  4.8500e-01,  2.2162e-01, -1.9624e-01,\n",
       "           -1.0914e-01, -3.7504e-01,  6.0187e-01, -7.7466e-01,  3.4477e-01,\n",
       "           -7.9882e-01, -7.8048e-01,  2.5214e-01,  4.4151e-01,  3.9126e-01,\n",
       "           -2.9133e-01, -3.2787e-01,  1.9685e-01, -1.4141e-01,  7.9660e-01,\n",
       "           -6.0140e-01,  6.6384e-01,  3.9702e-01,  4.7700e-01,  3.2294e-01,\n",
       "            1.4450e-01,  9.3478e-01, -6.6742e-01, -7.2267e-01,  3.8278e-01,\n",
       "            4.3884e-01,  5.2598e-01,  2.5688e-01,  1.2985e-01, -9.0624e-02,\n",
       "            5.6791e-01, -6.5025e-01, -6.5495e-01,  1.7526e-01,  3.6059e-02,\n",
       "            7.5415e-02,  5.9567e-01, -2.4279e-01,  5.3267e-01, -4.4971e-01,\n",
       "           -5.7943e-01, -1.2963e-01,  9.7404e-02, -6.5938e-01,  2.5547e-01,\n",
       "           -3.0152e-01,  3.9604e-01, -8.8123e-01, -6.4091e-02,  2.2540e-01,\n",
       "            7.1248e-02, -3.4454e-01,  3.2674e-01,  1.2569e-01,  6.4321e-02,\n",
       "           -5.6034e-01,  2.6368e-01,  1.9680e-01,  3.0997e-01, -5.3370e-01,\n",
       "            1.3305e-01, -3.1376e-01, -8.0084e-01,  3.6562e-03, -5.0028e-01,\n",
       "            3.8317e-02,  6.7591e-01, -6.0117e-01,  5.3690e-02, -6.7031e-01,\n",
       "            9.1631e-01, -6.8247e-01, -5.9881e-01,  5.9785e-01,  2.6437e-01,\n",
       "           -7.9284e-01,  5.4760e-01, -1.5807e-01,  6.1987e-01,  8.7835e-01,\n",
       "           -8.5824e-01, -7.4203e-02,  1.9783e-01, -8.9437e-01,  8.3737e-01,\n",
       "            3.0585e-01,  4.3264e-01, -1.6056e-01,  3.6465e-01, -4.7898e-01,\n",
       "           -7.4428e-01, -3.5439e-01,  7.8005e-01,  5.9299e-01, -3.4928e-01,\n",
       "           -6.1803e-01,  3.3974e-01,  3.3725e-03,  3.9350e-01, -4.8366e-01,\n",
       "           -9.6163e-02, -3.7773e-01,  4.0282e-01, -5.4274e-01, -1.8204e-01,\n",
       "           -3.0644e-01, -5.6010e-01,  2.0832e-01, -9.5863e-01,  1.7779e-01,\n",
       "            1.0530e-01,  6.6175e-02,  8.0124e-01, -5.8503e-01, -4.8146e-01,\n",
       "           -5.7602e-01,  2.8332e-01, -4.7269e-01, -3.6429e-01,  2.3973e-01,\n",
       "            5.2943e-01, -6.4239e-01, -7.6511e-02, -6.3810e-01,  6.6136e-02,\n",
       "           -5.2591e-01,  7.1283e-01, -1.5042e-01, -5.1771e-01, -5.8683e-01,\n",
       "           -5.2796e-01, -4.5446e-02, -2.2091e-01,  1.4154e-01,  7.3090e-01,\n",
       "           -5.8557e-01, -4.3667e-01, -3.9652e-01,  4.9511e-01, -2.9911e-01,\n",
       "           -1.7923e-02, -3.8575e-01,  9.5303e-02, -5.5287e-01,  3.1831e-01,\n",
       "            7.6678e-01,  2.6523e-02,  2.4562e-01,  1.8077e-01,  9.5114e-01,\n",
       "            4.3323e-01,  5.2598e-01, -8.5429e-01, -5.9681e-02,  3.3414e-01,\n",
       "            1.3799e-02,  1.3576e-01, -6.7915e-01,  3.3143e-01,  3.6840e-01,\n",
       "           -3.2965e-01,  1.9921e-01,  8.9823e-01,  6.2906e-01,  1.3732e-01,\n",
       "           -1.3936e-01, -4.4217e-01,  2.8421e-01,  5.6931e-01, -1.7791e-01,\n",
       "            2.9558e-01,  8.1384e-02, -6.9752e-02,  2.6614e-01,  3.0952e-01,\n",
       "           -8.4587e-01,  1.0675e-01,  1.8368e-01,  7.0978e-01, -7.6890e-02,\n",
       "           -7.6473e-01,  7.9400e-01, -6.8437e-01, -4.9654e-01,  5.5858e-01,\n",
       "           -6.4975e-01, -3.3859e-01,  6.6361e-01, -3.4108e-01, -3.0627e-01,\n",
       "           -2.9359e-01, -3.0400e-01,  1.1104e-01, -3.4385e-01,  5.9522e-02,\n",
       "           -4.1600e-01,  6.5622e-01, -8.0614e-01,  3.1354e-01,  2.6003e-01,\n",
       "           -4.5290e-01, -1.2577e-01, -3.3510e-02, -6.2639e-02,  8.0402e-02,\n",
       "           -7.7097e-02, -5.6104e-01, -7.0421e-02, -1.9314e-01, -2.3859e-01,\n",
       "            2.5312e-01,  5.5195e-01,  4.3351e-01, -5.3679e-01,  5.5325e-01,\n",
       "            3.2851e-01,  7.2503e-01, -1.3899e-01,  7.4697e-02, -3.0579e-01,\n",
       "            2.5895e-02, -3.9770e-02, -6.4231e-01, -5.8253e-01,  3.9299e-01,\n",
       "           -2.3621e-01, -4.3372e-01, -1.8648e-01, -2.8359e-01, -5.1201e-01,\n",
       "           -6.6073e-01,  6.1218e-01,  2.9811e-02,  2.4506e-01,  4.1294e-01,\n",
       "           -8.7367e-02,  2.6728e-01, -8.7917e-01,  3.0907e-01, -1.2091e-01,\n",
       "           -6.9571e-01, -2.7659e-01,  4.4817e-01,  3.6477e-01,  5.2749e-01,\n",
       "           -2.7787e-01,  5.0305e-01, -2.0611e-01,  3.9345e-01,  3.3416e-01,\n",
       "           -2.6089e-01,  3.5152e-01,  5.9009e-01, -8.8485e-01,  1.8636e-01,\n",
       "           -2.0759e-01,  1.8152e-01,  7.7314e-01,  1.3751e-01, -2.0142e-01,\n",
       "            4.8464e-02,  4.5443e-01,  2.9866e-01,  4.9034e-02, -2.7528e-01,\n",
       "           -8.6520e-01, -5.7100e-01,  6.4163e-01,  4.7969e-01, -9.2664e-01,\n",
       "            3.0454e-01, -5.7440e-01,  5.6395e-01,  6.0962e-01, -1.2910e-01,\n",
       "           -2.9378e-01,  4.0476e-01,  8.9266e-01, -2.1758e-01, -1.4405e-01,\n",
       "           -3.8393e-01, -5.2317e-01,  3.0653e-01, -4.9662e-01,  4.1548e-01,\n",
       "           -7.2202e-01, -1.9972e-01,  4.9709e-01,  4.3606e-02, -1.2425e-01,\n",
       "           -5.8875e-01, -2.5427e-01, -3.2526e-01, -2.4138e-01,  5.2730e-01,\n",
       "            1.8033e-01, -7.1451e-02, -2.3597e-01, -3.8437e-02, -3.7477e-01,\n",
       "           -1.5093e-01, -5.9872e-01,  1.1179e-01, -3.4182e-01,  3.6385e-01,\n",
       "           -3.6981e-01,  2.4508e-02, -3.1886e-01,  5.9239e-01, -1.8612e-01,\n",
       "           -7.0095e-01, -4.9337e-01,  4.1586e-01,  4.4420e-01,  2.8606e-01,\n",
       "            1.0553e-01,  5.2048e-01,  8.8069e-01,  1.8975e-01, -6.3898e-01,\n",
       "            1.6171e-02,  3.0401e-01,  1.7137e-01, -7.4976e-01,  7.3066e-01,\n",
       "            2.7547e-04,  7.9493e-01, -6.7581e-02, -3.8399e-01,  4.8890e-01,\n",
       "            4.5857e-01, -6.0174e-02,  5.3766e-01, -1.4732e-02, -3.8077e-01,\n",
       "           -1.0412e-01,  5.3617e-02,  3.0342e-01, -4.9286e-01, -5.6188e-01,\n",
       "           -2.6387e-01, -6.5488e-01,  2.7372e-01, -5.2038e-02, -2.5777e-01,\n",
       "            6.2092e-01,  1.0486e-01, -1.5948e-01, -1.5857e-02, -1.3515e-01,\n",
       "           -8.0355e-02,  9.5355e-01,  3.6304e-01, -2.6076e-01,  4.2312e-01,\n",
       "           -9.6762e-02, -2.1553e-01, -5.2056e-02,  3.7687e-01, -1.2838e-01,\n",
       "            6.0752e-01, -5.1245e-01,  1.9713e-02, -1.3537e-01,  2.1525e-01,\n",
       "            1.3728e-01,  3.7321e-01], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.6177, -0.5838, -0.3908,  ...,  0.2789, -0.2855, -0.2591],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-6.4713e-02, -1.2441e-02, -3.7536e-02,  5.6192e-02, -2.6660e-02,\n",
       "           -2.8116e-02, -5.5420e-02, -2.7706e-02,  2.4408e-02, -1.5941e-01,\n",
       "            8.9832e-02,  5.5890e-02, -3.1696e-02, -6.2711e-03,  5.2253e-02,\n",
       "            7.0894e-02, -1.8719e-02, -3.6097e-02,  2.3642e-02, -8.3723e-02,\n",
       "            9.5716e-02,  8.5793e-02, -1.1682e-01, -6.4362e-02,  2.8884e-02,\n",
       "           -3.0572e-02, -3.0522e-02,  1.3440e-01, -7.4577e-02, -5.7632e-02,\n",
       "            5.8856e-02,  1.2679e-01,  6.4340e-02, -1.1253e-01,  3.1931e-02,\n",
       "            4.5984e-03,  8.4546e-03,  4.0542e-03, -8.3696e-02, -3.6861e-02,\n",
       "           -1.9196e-01,  1.2154e-01,  3.3443e-02,  5.8907e-02, -2.6880e-03,\n",
       "           -7.6820e-02,  6.5266e-02,  2.0427e-01, -5.3115e-03, -2.6035e-03,\n",
       "            1.0991e-01, -2.4919e-02, -5.4671e-02,  4.6184e-02, -1.0393e-01,\n",
       "            4.7286e-02, -1.3815e-01, -7.0144e-03, -2.2777e-01,  2.8113e-02,\n",
       "           -2.0814e-01, -7.3680e-02,  9.3093e-03, -8.2473e-02, -6.2033e-02,\n",
       "           -6.9013e-02,  6.5578e-02,  4.5716e-01,  2.6717e-01,  5.6264e-02,\n",
       "            4.2842e-02,  8.4764e-02,  8.5310e-02, -2.1857e-02, -4.2128e-02,\n",
       "           -7.2290e-02,  1.1777e-01,  6.2624e-04,  1.2955e-03, -2.6874e-02,\n",
       "            1.1716e-01,  9.2007e-02, -5.5430e-02, -7.0849e-02, -6.2005e-02,\n",
       "            1.1189e-02, -2.2871e-02, -5.7009e-02, -2.3047e-02,  6.0301e-02,\n",
       "           -1.5166e-02, -1.1743e-02, -7.6814e-02,  5.2717e-03, -7.3105e-02,\n",
       "           -1.0730e-01, -3.1501e-01,  9.8517e-02,  2.5401e-02,  4.7687e-02,\n",
       "            8.5604e-02, -3.1260e-02,  8.8271e-03, -6.4499e-02,  5.7567e-03,\n",
       "           -7.4171e-02,  7.5370e-02,  1.3044e-02,  8.0802e-02,  3.8304e-01,\n",
       "            3.2412e-01, -4.2598e-03, -3.7492e-02,  5.8844e-02, -5.4062e-02,\n",
       "            4.1559e-02,  7.1390e-02, -1.2818e-02, -4.2274e-02,  4.9988e-02,\n",
       "           -6.6257e-02, -4.5673e-02, -3.6569e-02,  9.0465e-02, -8.9891e-02,\n",
       "           -2.3981e-02,  5.5134e-02, -4.0583e-02,  2.9819e-02, -1.2218e-02,\n",
       "            3.4622e-01,  1.9975e-02, -3.2515e-02, -6.6439e-02,  8.7641e-02,\n",
       "            8.8489e-02,  3.5796e-02,  2.3118e-02,  4.1455e-03,  1.3390e-01,\n",
       "            9.1318e-02,  6.1158e-02, -7.0011e-02, -3.6370e-02,  1.5301e-02,\n",
       "           -4.8506e-02,  8.9658e-02, -3.6035e-01,  1.0505e-01, -6.3028e-02,\n",
       "            6.6225e-02,  6.8862e-02,  4.3903e-02,  3.0918e-02,  6.0193e-02,\n",
       "            1.0844e-01,  3.9920e-02,  4.0579e-02, -4.1942e-02, -2.6133e-02,\n",
       "            1.5403e-01, -6.6288e-02,  8.3627e-02, -1.3854e-01, -2.3956e-03,\n",
       "            3.6374e-03, -1.8048e-02,  2.1833e-02,  4.3323e-02, -9.7892e-02,\n",
       "           -4.7270e-02, -5.4419e-02, -9.0270e-02,  8.1578e-02, -7.0660e-02,\n",
       "           -8.0884e-02,  3.8408e-02,  4.7489e-02, -2.4690e-02, -1.9067e-01,\n",
       "           -1.3955e-01,  7.6248e-03,  1.4932e-02, -1.4098e-02, -2.6903e-02,\n",
       "            3.9994e-02,  8.8033e-02,  6.0692e-02,  6.7347e-02,  6.8466e-02,\n",
       "           -3.1913e-02, -5.1846e-02,  6.0027e-02, -9.2448e-02, -6.7746e-03,\n",
       "           -5.6734e-02,  3.9128e-02, -6.5030e-02,  1.1903e-01,  6.4622e-02,\n",
       "            2.4084e-03, -6.2617e-03,  8.7541e-02,  5.2602e-02,  5.8316e-03,\n",
       "           -8.3698e-02, -1.1802e-02,  8.9678e-02, -7.3937e-02,  1.7388e-01,\n",
       "            9.7580e-02, -8.6093e-02,  4.0268e-01,  1.2280e-01,  5.1394e-02,\n",
       "           -2.7604e-02,  2.3509e-02,  1.0152e-01, -4.4634e-02, -4.8514e-03,\n",
       "            3.3955e-02, -3.2379e-02, -9.9771e-02, -6.8803e-02,  6.8295e-02,\n",
       "            5.3414e-02,  1.4523e-01,  7.1968e-02,  1.0538e-01, -3.7909e-02,\n",
       "            7.2715e-02, -2.5852e-02, -3.2362e-02, -3.6468e-02,  1.8437e-02,\n",
       "           -5.4869e-02, -3.6510e-02, -3.2305e-02, -2.6585e-02,  7.8742e-02,\n",
       "            3.6394e-02, -4.6948e-02,  1.6651e-01,  7.4101e-02, -8.7924e-02,\n",
       "           -7.0888e-03, -7.7742e-02,  6.1809e-02,  5.9440e-02, -2.4547e-02,\n",
       "            3.4826e-02,  6.6671e-02, -3.4493e-02, -1.6968e-01,  7.1739e-02,\n",
       "            3.1142e-02,  3.7141e-02, -3.7526e-02,  7.2517e-02,  1.7477e-01,\n",
       "            8.8815e-02,  8.1209e-02, -1.1370e-01, -2.9651e-02, -2.4809e-02,\n",
       "           -3.8681e-02,  3.9936e-02, -1.0670e-01,  1.2603e-01,  7.9957e-03,\n",
       "            2.1992e-03, -2.0014e-02,  2.5721e-02,  3.5291e-02, -3.3598e-03,\n",
       "            6.8043e-02,  1.2920e-01, -4.3952e-02, -3.3789e-02, -6.6129e-03,\n",
       "           -8.5754e-02, -2.0386e-02,  6.6035e-02, -1.7258e-02,  3.6634e-02,\n",
       "            9.8637e-02, -3.9971e-02,  1.1177e-02,  6.8185e-02, -6.8113e-02,\n",
       "            5.4067e-02,  8.3982e-02,  3.8587e-02,  2.0500e-02,  2.9377e-02,\n",
       "           -2.4003e-02,  1.7352e-02, -3.1023e-01, -4.4525e-02,  9.5837e-02,\n",
       "           -2.1315e-03, -6.8972e-02, -3.8645e-04,  7.5138e-02, -1.6330e-02,\n",
       "            1.8835e-01, -2.7635e-02,  7.8606e-02, -4.2445e-02, -7.1907e-02,\n",
       "           -1.8309e-01,  2.4471e-02, -1.8749e-01, -4.7945e-02, -6.1619e-02,\n",
       "           -6.4025e-02, -8.4509e-02, -5.5113e-02, -1.8166e-02,  7.5525e-02,\n",
       "            2.8849e-02, -7.6798e-02,  1.2123e-02, -1.3794e-01,  1.2094e-02,\n",
       "           -4.0395e-02,  9.5062e-02,  6.4279e-02, -6.8427e-02,  9.7816e-02,\n",
       "            3.5476e-02,  3.3369e-02,  1.7196e-02,  6.1953e-02,  6.7923e-02,\n",
       "            2.0749e-01,  4.3599e-02, -1.9656e-02,  1.3313e-01,  1.9291e-02,\n",
       "           -1.3675e-01,  7.5856e-02,  4.0346e-02, -2.6821e-02, -9.1417e-02,\n",
       "            2.1674e-02,  7.8752e-02,  6.7237e-02, -1.9973e-02,  4.7645e-02,\n",
       "           -6.8076e-02,  7.4150e-02, -8.8988e-02,  1.5835e-02,  1.1239e-01,\n",
       "           -6.1743e-02, -8.5638e-02, -5.2060e-02,  4.2293e-02,  9.2263e-02,\n",
       "           -7.3390e-02, -2.8657e-02, -5.8706e-02, -3.9666e-02,  1.2198e-02,\n",
       "           -6.6615e-02,  1.1450e-01,  3.8215e-02,  3.7894e-02,  7.3167e-03,\n",
       "           -8.5259e-02,  2.3410e-02,  1.3538e-03,  9.1346e-04,  2.9734e-01,\n",
       "            9.6506e-02, -1.4105e-01,  1.0754e-02,  2.2248e-01, -2.9282e-02,\n",
       "            9.1085e-02,  6.8823e-02, -9.8437e-02, -1.6963e-02, -1.2290e-04,\n",
       "           -8.7200e-02, -2.4468e-02, -5.5636e-02, -1.7724e-02, -5.5811e-02,\n",
       "           -8.8950e-02, -5.7453e-02,  3.1527e-02, -2.5678e-01, -8.2418e-02,\n",
       "           -7.8880e-02, -8.1342e-02, -4.2768e-02,  6.4990e-03,  4.6684e-02,\n",
       "           -4.2326e-02,  6.6563e-02,  4.6596e-02,  8.2761e-02, -3.5801e-02,\n",
       "            5.7424e-02, -6.2248e-02, -7.1855e-02,  7.8016e-02,  1.7619e-01,\n",
       "           -6.6624e-02,  3.2886e-02,  5.5053e-02, -7.8425e-02,  1.0383e-02,\n",
       "            2.2516e-01,  8.0553e-02, -4.7767e-02, -3.8040e-02, -1.1312e-01,\n",
       "           -2.1695e-02, -1.4931e-01, -7.1259e-02, -5.7922e-04, -7.0331e-02,\n",
       "           -8.3092e-02,  1.9435e-02,  7.7153e-02,  4.2622e-02, -3.9672e-02,\n",
       "            8.9359e-02, -3.3491e-02,  8.9488e-03, -9.4432e-02, -7.8098e-02,\n",
       "            1.7632e-01,  8.9551e-02,  1.6527e-02,  1.0171e-03, -9.5914e-03,\n",
       "            3.1617e-02, -2.9022e-02, -9.4012e-02, -2.1825e-02, -1.9314e-02,\n",
       "           -3.7474e-02, -6.9111e-02,  2.3483e-01, -3.3792e-02, -4.0497e-02,\n",
       "           -3.3211e-02,  1.0873e-02, -3.3977e-02, -3.5356e-02, -2.0714e-01,\n",
       "            6.3807e-02, -4.7059e-02,  2.2683e-02, -2.6705e-02,  3.8992e-02,\n",
       "            4.3116e-02,  5.0855e-04,  1.8449e-02,  6.5537e-02,  2.0009e-02,\n",
       "           -4.1247e-02,  3.7240e-02,  2.9049e-02,  6.1150e-02, -9.1261e-03,\n",
       "           -2.5997e-02,  4.7746e-02,  7.8980e-02,  7.8433e-02, -7.5035e-02,\n",
       "            8.0436e-02, -3.5189e-02, -6.8120e-02, -1.2567e-01,  1.5679e-01,\n",
       "            2.7322e-02, -1.6503e-01,  5.6563e-02,  1.1694e-01, -2.8386e-02,\n",
       "           -1.2097e-02,  5.9013e-02,  4.1754e-02,  1.0937e-02,  5.8010e-02,\n",
       "           -1.5755e-02, -2.3737e-02, -3.6827e-02, -2.7892e-01,  3.3325e-02,\n",
       "            1.3158e-01, -8.3686e-02,  5.6453e-02, -3.5612e-02,  1.0320e-01,\n",
       "           -3.3615e-02,  7.7620e-03, -2.0848e-01,  9.7153e-02, -3.8068e-02,\n",
       "           -1.1753e-01,  4.7080e-02,  6.5315e-02, -3.4810e-02,  2.7812e-01,\n",
       "           -7.1950e-02, -3.8713e-02], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-4.9286e-01, -9.0242e-01,  1.8291e-01,  2.0993e-02, -4.3838e-01,\n",
       "            4.6582e-01, -2.7642e-01,  4.1623e-01, -2.4517e-01, -1.7453e-03,\n",
       "            1.7097e-01, -1.3954e-01, -6.1467e-01,  1.6850e-02,  1.5203e-02,\n",
       "            1.8624e-01, -7.0722e-01, -1.2613e-01, -7.4551e-01, -8.2777e-01,\n",
       "           -6.4112e-01, -9.2087e-03,  2.3053e-01,  2.6720e-01, -7.8503e-01,\n",
       "            5.9737e-01, -7.2238e-01, -5.7108e-01,  7.5804e-02,  4.1106e-02,\n",
       "           -2.2888e-01, -4.0562e-02, -9.4621e-01, -3.2839e-01, -6.0573e-01,\n",
       "           -7.0423e-01, -7.4410e-02, -7.4471e-02, -2.2464e-02, -2.3189e-01,\n",
       "           -1.4178e-01, -3.0758e-02, -4.4857e-02, -1.5060e-01,  3.6060e-02,\n",
       "            2.8161e-01,  2.3624e-01, -3.6319e-01, -7.9849e-01, -3.7007e-01,\n",
       "           -6.4792e-01,  9.4958e-01,  1.6756e-02, -3.7643e-01, -7.6632e-02,\n",
       "           -7.1339e-02, -4.5531e-01, -3.4209e-01,  1.0430e+00, -1.0350e-03,\n",
       "           -1.1203e-01, -2.0399e-01,  7.0892e-01,  3.9990e-02, -7.4760e-02,\n",
       "           -2.3469e-02, -4.7513e-01, -2.1865e-01, -5.4450e-01, -4.1489e-02,\n",
       "           -1.5419e-01,  1.0357e+00, -6.7139e-01,  8.6179e-01, -1.3050e-02,\n",
       "           -7.3775e-02, -2.2614e-01, -4.0341e-03, -5.6880e-02,  1.9151e-01,\n",
       "           -7.8513e-01, -6.9554e-01,  3.7927e-02, -1.0186e-01, -7.6356e-02,\n",
       "            5.2310e-02, -8.1407e-01, -8.3670e-01, -2.6541e-01, -3.0677e-01,\n",
       "            5.6892e-01,  5.4815e-01, -6.5635e-01, -3.7362e-01,  1.0613e+00,\n",
       "           -9.3776e-02,  4.7022e-02,  9.8129e-01, -3.2023e-02,  8.1973e-01],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 4.6986e-02,  6.9441e-02, -7.1079e-02,  8.8934e-02,  9.1325e-02,\n",
       "           -1.1880e-01,  4.6362e-02,  2.8316e-04, -6.5624e-04,  7.0953e-03,\n",
       "            5.5568e-02, -2.5477e-02, -5.6237e-02,  8.1393e-02,  5.2356e-02,\n",
       "            1.6291e-01, -9.2121e-02,  5.5147e-02,  1.1397e-01, -5.4240e-02,\n",
       "            1.7225e-01,  2.5139e-02, -1.9426e-01, -2.0994e-01, -1.3699e-01,\n",
       "           -3.1951e-02, -3.9681e-01,  1.4964e-01, -7.4011e-02,  1.1930e-01,\n",
       "            2.5346e-02, -7.7561e-02,  2.6954e-01,  1.3857e-01, -7.6076e-02,\n",
       "           -3.4321e-03, -1.5258e-02,  1.8109e-03, -5.6556e-02, -8.8114e-02,\n",
       "            1.1544e-01,  9.5872e-02,  6.1949e-02,  4.8141e-02,  4.0171e-03,\n",
       "           -6.7343e-02,  5.1960e-02, -5.6476e-02, -2.0568e-02, -2.7554e-02,\n",
       "            3.2503e-02, -2.2412e-01, -1.4824e-01,  8.1549e-02, -7.1846e-02,\n",
       "           -3.0760e-02, -3.0241e-02,  1.5270e-02,  9.7663e-02,  2.2132e-02,\n",
       "            4.8297e-02, -9.4365e-02,  4.0698e-02, -6.3645e-02, -3.0767e-02,\n",
       "            1.5344e-01,  4.5544e-02, -1.8889e-01, -8.5605e-02,  1.0891e-01,\n",
       "            1.8182e-01, -6.5668e-02,  1.0243e-01,  3.3526e-02,  1.0028e-02,\n",
       "            1.5808e-03,  6.7236e-02, -8.8024e-03,  2.6643e-02,  4.8323e-02,\n",
       "            3.4911e-02,  2.8878e-02, -2.1880e-01,  5.4663e-02, -3.6120e-02,\n",
       "            1.7350e-01, -1.3845e-02,  2.6317e-02, -8.4042e-03, -8.9755e-02,\n",
       "            1.4316e-03,  9.7266e-02, -7.1965e-02,  7.0115e-02, -6.3592e-02,\n",
       "           -3.5450e-02, -1.7488e-01,  7.4165e-03,  3.7962e-02,  1.1202e-01,\n",
       "           -4.3354e-02, -1.4812e-02, -2.9964e-02, -1.9015e-01,  4.4207e-02,\n",
       "           -4.6683e-02,  1.2464e-02,  3.2035e-02, -8.0573e-03,  1.5469e-02,\n",
       "            8.0511e-02, -1.1482e-02, -5.5222e-02, -3.0194e-01, -1.3105e-01,\n",
       "           -2.0476e-02,  1.4449e-01,  1.5909e-02,  3.0109e-01,  9.0828e-02,\n",
       "            2.6874e-03,  3.9245e-01, -7.2035e-03,  3.8546e-01, -4.7782e-02,\n",
       "            2.1449e-01,  7.2786e-02,  4.2020e-02,  6.5396e-02,  1.4810e-02,\n",
       "           -7.9746e-02,  3.3740e-01, -8.3105e-02,  1.4118e-02, -6.7554e-02,\n",
       "            9.1373e-02,  1.2830e-01, -3.5892e-02,  7.9190e-02,  1.8125e-02,\n",
       "           -4.7198e-01,  9.9847e-02, -2.7981e-02,  1.2459e-03,  3.8579e-02,\n",
       "           -1.5438e-02,  3.3110e-02, -1.0081e-01, -7.4283e-02,  4.2944e-02,\n",
       "            7.0324e-02,  1.3453e-01,  3.6768e-02,  1.4291e-02, -1.6314e-01,\n",
       "           -1.6856e-01,  6.1114e-02,  2.4955e-02, -3.6733e-02,  8.5261e-02,\n",
       "            9.8671e-02, -9.5445e-02,  4.7387e-02, -6.8923e-02,  1.5651e-01,\n",
       "            1.9925e-02, -7.2098e-02,  4.1701e-02,  4.7963e-02,  4.9328e-02,\n",
       "           -3.6889e-02,  4.8499e-02, -8.6223e-02,  5.2646e-02, -8.2922e-03,\n",
       "           -9.8223e-02, -6.5950e-02,  5.2102e-02,  2.9914e-02, -6.4235e-02,\n",
       "           -4.8224e-02, -1.0039e-01,  3.0189e-02, -6.9483e-02,  5.1036e-02,\n",
       "            4.2693e-02,  2.1480e-01, -2.0777e-02,  2.7947e-02, -1.0130e-01,\n",
       "           -1.1069e-02,  3.2976e-02,  4.0325e-02, -4.1148e-02,  2.6432e-02,\n",
       "           -3.9128e-02,  9.8302e-02, -1.9729e-02,  8.4893e-04,  3.5441e-02,\n",
       "           -3.9359e-02, -1.5160e-01,  1.8949e-01, -4.3687e-02,  1.4685e-01,\n",
       "           -2.1698e-01,  5.4586e-02, -2.5905e-02, -1.0276e-02,  7.9879e-02,\n",
       "            6.9673e-02,  2.1824e-02,  5.8661e-02,  7.6736e-02,  1.0755e-01,\n",
       "           -2.9925e-02,  3.9470e-02,  6.2945e-02, -4.7175e-02, -2.1275e-02,\n",
       "            3.4310e-02, -1.1935e-02, -3.0850e-02, -9.4291e-02, -9.4832e-02,\n",
       "            5.2829e-02, -7.1812e-02,  4.8575e-03, -1.2654e-02, -1.5634e-01,\n",
       "            6.4524e-02, -6.9326e-02, -6.2004e-02, -3.9486e-02, -3.5630e-02,\n",
       "            1.6791e-01,  3.9063e-02, -1.8586e-01, -5.3495e-02,  5.2969e-02,\n",
       "            1.1057e-01, -4.4125e-02, -3.3714e-01, -1.3149e-01, -2.4510e-02,\n",
       "           -4.9432e-02, -1.4934e-02,  5.1914e-03,  1.2992e-01, -2.9703e-02,\n",
       "           -3.5015e-03, -3.1938e-02,  2.7202e-02,  5.7958e-02,  2.6104e-02,\n",
       "           -3.4117e-02, -6.7634e-04, -3.6127e-02,  1.2369e-01,  1.9181e-01,\n",
       "            2.8121e-02, -1.8939e-01, -5.7318e-01,  2.1553e-01,  2.3809e-02,\n",
       "            6.5991e-02, -3.0777e-02,  3.2896e-04, -2.7174e-02,  1.6670e-02,\n",
       "            1.7489e-01, -4.1353e-02, -4.8849e-03, -3.8416e-03,  1.2984e-02,\n",
       "            1.0981e-01, -1.7616e-01,  4.6049e-02,  3.1772e-02,  2.5056e-02,\n",
       "            1.1271e-02, -1.7764e-01,  7.8232e-02, -4.8843e-02, -6.5494e-04,\n",
       "            3.1931e-01,  3.1686e-02, -4.5093e-02,  8.5954e-02, -1.0759e-01,\n",
       "            5.4277e-02, -9.2520e-02, -3.2734e-02, -1.0775e-02, -4.3364e-02,\n",
       "           -3.5814e-02, -5.7870e-02,  3.7859e-01, -1.5367e-01,  3.1274e-02,\n",
       "            5.1879e-02, -1.1269e-01,  1.0596e-01, -1.5126e-01, -8.8782e-02,\n",
       "            2.5419e-02, -2.5931e-02, -1.0047e-01, -8.8077e-02, -3.1716e-02,\n",
       "            8.6840e-03,  2.6561e-02, -6.1546e-02, -8.3192e-02, -5.0731e-02,\n",
       "            1.0936e-01, -1.4819e-01,  3.3052e-02, -1.9959e-01,  2.3522e-02,\n",
       "            3.1455e-01,  1.2866e-01, -2.6070e-02, -1.4416e-01, -2.2602e-02,\n",
       "            5.9694e-02, -5.1963e-02,  8.7201e-02, -2.5595e-02, -1.4492e-01,\n",
       "            5.1061e-02,  6.9853e-02, -5.7153e-02,  1.4056e-02,  8.3387e-02,\n",
       "            1.4392e-01,  1.4502e-01, -3.8894e-02,  6.4533e-02,  2.1148e-01,\n",
       "           -6.2320e-02, -5.1509e-02, -2.2753e-02, -3.0882e-02, -2.9782e-01,\n",
       "            6.6687e-02,  1.0918e-01,  1.0522e-01,  4.0571e-03, -1.0221e-02,\n",
       "           -2.2972e-03,  9.8678e-02, -1.5960e-01,  1.0269e-01,  1.0897e-01,\n",
       "           -7.8589e-02, -9.8156e-02,  1.3672e-01,  9.7769e-02, -5.9734e-02,\n",
       "            3.4118e-02, -8.3441e-02, -1.2560e-01,  3.9510e-02,  1.7053e-02,\n",
       "            3.5948e-02,  2.3310e-01,  6.5483e-03,  1.3040e-01, -4.8677e-02,\n",
       "            2.2571e-02,  2.3715e-02, -4.0935e-02,  4.2699e-01,  1.6092e-02,\n",
       "            1.4125e-01, -4.1135e-02, -2.7784e-02,  2.2705e-01, -1.8415e-01,\n",
       "            3.8223e-02, -9.7728e-03,  4.7806e-01, -8.8101e-02,  1.4040e-01,\n",
       "            1.1236e-01,  1.2484e-02, -5.6173e-02, -8.7034e-02, -4.3227e-02,\n",
       "            3.1473e-01, -7.3732e-02,  8.5960e-02, -7.8549e-02, -1.3886e-01,\n",
       "           -9.0604e-02, -8.9311e-02, -8.8662e-02,  2.4273e-02, -1.1828e-01,\n",
       "           -1.8870e-02,  5.9760e-02, -5.6424e-02, -1.0354e-03, -3.3926e-02,\n",
       "            1.8346e-02,  4.7990e-02, -6.1508e-02,  3.7453e-02, -7.2315e-02,\n",
       "           -1.2269e-01,  3.8316e-02, -1.8789e-01, -1.3419e-02,  3.7244e-01,\n",
       "           -4.7083e-02,  2.0867e-02,  4.2907e-02, -9.1230e-02, -1.5228e-01,\n",
       "            9.8376e-02, -4.2657e-02, -8.8173e-02, -4.7577e-02, -1.6263e-02,\n",
       "            4.8235e-01,  5.9507e-02, -1.3031e-01,  2.8269e-02, -3.8902e-02,\n",
       "            5.5138e-02, -1.6917e-03, -2.0433e-01, -1.0937e-01,  3.4228e-02,\n",
       "            2.1589e-01,  2.5208e-01, -2.4832e-01, -5.6262e-02,  9.5280e-02,\n",
       "            4.0821e-02,  2.0062e-02,  8.5973e-02,  2.4463e-02, -5.4390e-02,\n",
       "            3.1693e-02, -7.5550e-02,  1.0375e-01, -2.4539e-02,  1.0315e-01,\n",
       "            9.9514e-02, -2.9586e-02,  2.2811e-01, -4.6667e-02,  8.9336e-02,\n",
       "            1.0993e-01, -1.2467e-01,  2.8125e-04, -7.9727e-03, -2.6906e-04,\n",
       "           -4.7176e-02, -8.3732e-02, -7.0391e-02, -1.4118e-02, -1.4578e-02,\n",
       "           -1.5425e-01,  4.9907e-03, -1.7586e-02,  1.5546e-01, -1.0958e-01,\n",
       "           -6.6692e-02, -8.2806e-02, -3.2096e-01,  1.4802e-01, -1.7237e-01,\n",
       "            2.4396e-01,  2.1006e-01, -1.1313e-01, -7.4200e-02,  7.0202e-02,\n",
       "           -2.7940e-02, -6.6339e-02, -2.3733e-02,  3.2809e-02,  2.1452e-01,\n",
       "           -7.7118e-02,  1.0844e-01,  8.9672e-02, -6.6822e-03, -8.0274e-02,\n",
       "            1.2131e-01,  3.7957e-02, -6.2596e-02,  5.2024e-02, -5.0086e-02,\n",
       "            9.3813e-02, -3.1506e-01,  6.2144e-02, -2.3499e-02, -1.6222e-02,\n",
       "            4.5201e-03,  1.7085e-02, -2.2421e-01, -8.7049e-02, -2.3732e-02,\n",
       "           -1.1216e-01,  5.5161e-02,  1.8580e-02,  1.6843e-02,  2.0723e-01,\n",
       "           -2.7508e-01,  5.5094e-02], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.3466,  0.9335, -0.6727, -0.6083,  0.8565,  0.7009,  0.4123,  0.7843,\n",
       "            0.9318, -0.2960, -0.4443, -0.5662,  0.7054,  0.9205, -0.4862, -0.3842,\n",
       "            0.8116,  0.8001,  0.5339, -0.4045, -0.6891, -0.3866, -0.4695, -0.4503,\n",
       "            0.8185, -0.4922,  0.7565, -0.7051, -0.3207,  1.0021, -0.6303, -0.1987,\n",
       "           -0.4468, -0.3891, -0.6253,  0.7387, -0.6730,  0.9806, -0.2956,  0.8189,\n",
       "           -0.4395, -0.4979,  0.1973, -0.5506,  0.9874,  0.8676, -0.4629, -0.0283,\n",
       "            0.9559,  0.7970, -0.2446, -0.5420,  0.9480, -0.4943, -0.4066,  0.7075,\n",
       "            0.7378,  0.6228,  0.7924, -0.6710, -0.1791, -0.3727,  0.2666, -0.3914,\n",
       "           -0.5074, -0.4544, -0.3348, -0.2961, -0.1730, -0.4362, -0.7107, -0.4666,\n",
       "           -0.3010,  0.2574, -0.6460, -0.3477, -0.2949,  0.7937,  0.9126,  0.8346,\n",
       "           -0.2213, -0.2038, -0.6816, -0.5598, -0.1716, -0.4064,  0.9140, -0.7453,\n",
       "            0.9023, -0.6126,  0.9216,  1.0288,  1.1638,  0.9823,  0.1570,  0.9704,\n",
       "           -0.2496, -0.2398,  0.2561,  0.7410, -0.3840,  0.7308,  0.8365,  0.9818,\n",
       "            0.8577, -0.3924, -0.4519, -0.5033, -0.3231,  0.2594, -0.3625,  0.7804,\n",
       "            0.6743, -0.4064, -0.1336,  0.9752, -0.3719,  1.1779,  0.8636,  1.0548,\n",
       "           -0.4477,  1.0817,  0.5905, -0.2846,  0.7633, -0.4834, -0.6955,  0.3166,\n",
       "            0.6801,  0.9278, -0.4238,  0.9427,  0.8203, -0.6334,  0.6623, -0.3394,\n",
       "            0.8574,  0.7401, -0.5142,  0.6045, -0.2437, -0.3150, -0.6050,  0.8641,\n",
       "            0.1554, -0.6481, -0.2784, -0.3688, -0.3574, -0.4968, -0.4901, -0.3353,\n",
       "            0.9332, -0.3976,  0.9896, -0.4331,  0.5950,  0.4383,  0.6491,  0.8359,\n",
       "            0.7958, -0.4512, -0.3341, -0.2974, -0.6141,  0.9919, -0.5236, -0.7015,\n",
       "           -0.5654, -0.2207, -0.5851, -0.8212, -0.5035, -0.3239, -0.5790, -0.3871,\n",
       "            0.7089, -0.5266,  0.6480,  1.0289, -0.3571,  0.9627,  0.8034, -0.1612,\n",
       "            0.7330, -0.5587, -0.3427, -0.8462, -0.4127,  0.8282,  0.8756, -0.6242,\n",
       "           -0.8509, -0.4051,  0.8512, -0.4576, -0.5317, -0.3164, -0.1377, -0.3523,\n",
       "           -0.9764,  1.0455, -0.3040,  0.7459, -0.5848,  0.1858,  0.9122, -0.2746,\n",
       "           -0.0987, -0.2816, -0.2812, -0.6999,  0.9130,  0.4357, -0.5420, -0.4939,\n",
       "           -0.6153, -0.6949, -0.7329,  0.9938, -0.5566,  0.4088, -0.1978, -0.4099,\n",
       "           -0.6086, -0.5772,  0.7293, -0.4032,  1.0526, -0.4655, -0.4205,  0.4529,\n",
       "            0.6659,  0.8633,  1.0616,  0.3495,  0.7066, -0.6394, -0.6749, -0.3753,\n",
       "            0.9682,  0.7068, -0.5660, -0.6321, -0.1097,  0.8107, -0.8348, -0.2662,\n",
       "           -0.8396,  0.8237,  0.8455,  0.3423,  0.8261,  0.6940, -0.3656,  0.1537,\n",
       "            0.7210, -0.2826, -0.4517, -0.3563, -0.2680,  0.4683, -0.2596,  0.9028,\n",
       "            0.9174, -0.7274, -0.6134,  0.7660, -0.2932,  0.7546, -0.5230, -0.6148,\n",
       "            0.9448,  0.8577,  0.9930, -0.2341, -0.5727,  0.8111,  0.9726,  0.8843,\n",
       "            1.1345,  0.8507, -0.2993,  0.1666,  0.9132,  0.1245,  0.8517, -0.5565,\n",
       "           -0.4341, -0.4219,  1.0510, -0.3421,  0.8534,  0.9354,  0.7585,  0.4945,\n",
       "           -0.3709, -0.5059,  0.0222, -0.4184,  0.9674, -0.4068,  0.2546,  1.0119,\n",
       "            1.0255, -0.2994, -0.5277, -0.5483,  1.0547, -0.3840, -0.2050,  0.6052,\n",
       "           -0.3590, -0.5305, -0.6216, -0.3658, -0.4510, -0.6608,  0.9166, -0.4995,\n",
       "            0.8788,  0.4631,  0.9455,  0.2915,  0.8605, -0.7837, -0.2362, -0.4573,\n",
       "            0.2935,  1.1074, -0.6424,  0.7036,  0.6466, -0.2672, -0.4998, -0.5030,\n",
       "           -0.3472,  1.0046, -0.4939, -0.1388,  0.8459,  1.0373, -0.5676,  0.0897,\n",
       "           -0.3275,  0.9097, -0.2175, -0.3395,  0.8218,  0.6742, -0.4000, -0.2585,\n",
       "           -0.3177,  0.8728, -0.2894, -0.8953, -0.4090, -0.4064, -0.0404, -0.5606,\n",
       "           -0.4648,  0.9412, -0.9329,  0.7897,  0.8989,  0.3542, -0.3298,  0.7179,\n",
       "            0.8183,  0.7303, -0.4199, -0.5800,  0.8607, -0.6133,  0.3169,  0.2317,\n",
       "           -0.0929,  0.8670, -0.3557,  0.9203,  0.9735, -0.3668, -0.4414,  0.9640,\n",
       "            1.0238, -0.6411, -0.1379, -0.4259, -0.4308, -0.5207, -0.4578, -0.3469,\n",
       "            0.8446, -0.4470, -0.4419, -0.3648,  1.0899,  0.1773,  0.5507, -0.4556,\n",
       "            0.7456, -0.3526,  0.9004, -0.4490,  0.5811, -0.7102, -0.5088, -0.3971,\n",
       "           -0.3621, -0.4516, -0.5171,  0.3088,  0.6539, -0.3975, -0.9542, -0.4992,\n",
       "           -0.4412, -0.5310,  0.2444, -0.4087,  0.9815, -0.4893, -0.4173, -0.6409,\n",
       "            0.3041, -0.4355,  0.8473, -0.4601,  0.9381,  0.7708,  1.0318,  0.5984,\n",
       "            0.9764, -0.4635, -0.3872, -0.3697, -0.3243,  0.8572,  0.8289,  0.9930,\n",
       "            0.8820,  0.0246,  0.5505,  0.5223,  0.8136,  0.7068, -0.4515, -0.4875,\n",
       "            0.8934,  0.8463,  0.8432,  0.8760,  1.0035, -0.6215,  0.3301, -0.6162,\n",
       "            0.6288, -0.4331, -0.4703, -0.0392,  0.8206,  0.0184,  0.6185, -0.5438,\n",
       "            0.4574,  0.7651,  0.7534,  0.9247, -0.4120,  0.5797,  0.8567, -0.7051,\n",
       "           -0.3900, -0.3672, -0.4159,  0.6354,  0.8846, -0.3801, -0.3117, -0.4281,\n",
       "            0.5309, -0.1520, -0.5682,  0.9518,  1.0231, -0.4119,  0.9163,  0.8956,\n",
       "            0.8037, -0.6434,  0.9039,  0.6818,  0.5753, -0.1946,  0.8644, -0.2480,\n",
       "            0.7179, -0.4988,  0.7174, -0.4354,  0.8623,  0.9124,  1.1242, -0.5826,\n",
       "            0.7913, -0.7361, -0.5617,  0.6566,  0.6363,  0.2389, -0.3690,  0.9623],\n",
       "          device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 1.1070e+00,  1.0704e+00,  5.2700e-01, -1.2630e-01, -9.4747e-01,\n",
       "           -7.9584e-01,  1.1538e+00,  1.0337e+00, -1.1147e+00, -3.9398e-04,\n",
       "            2.2298e-01, -5.6986e-01, -9.5105e-01, -1.0433e+00,  2.5248e-01,\n",
       "           -1.5171e-01,  1.0534e+00, -8.9554e-01, -6.0643e-01,  2.7911e-01,\n",
       "           -6.2112e-01, -2.7431e-01,  5.1170e-01,  3.9564e-01, -8.4709e-01,\n",
       "            5.2795e-01,  1.1156e+00, -2.0344e-02,  1.6677e-01, -1.0714e+00,\n",
       "           -3.6815e-01, -1.8817e-01, -2.9391e-01,  4.5079e-02, -4.1641e-01,\n",
       "           -1.1296e+00, -6.2559e-01,  1.2485e+00,  2.3240e-01, -1.0178e+00,\n",
       "            1.1381e-01, -5.4701e-01, -4.6758e-01, -3.7490e-01, -1.1302e+00,\n",
       "           -9.6696e-01, -2.5530e-01,  2.6484e-01,  9.8471e-01, -9.9663e-01,\n",
       "           -2.5735e-01,  5.1368e-01, -1.0155e+00, -3.2000e-01,  2.6940e-01,\n",
       "           -1.1397e+00, -7.5727e-01,  9.0547e-01, -8.9717e-01,  5.1236e-01,\n",
       "           -2.0371e-01,  1.4917e-01, -9.7696e-01,  2.5318e-02,  3.9129e-01,\n",
       "            4.0171e-01, -2.3281e-01,  6.2201e-01, -1.4648e-01, -4.4460e-01,\n",
       "           -6.6770e-01, -5.0090e-01, -1.6787e-01, -2.2241e-01,  5.3160e-01,\n",
       "            1.7762e-01, -1.5263e-01, -8.6441e-01,  1.1925e+00,  1.1419e+00,\n",
       "           -1.0633e+00, -8.0624e-02,  1.4758e-01,  6.0749e-01,  5.1859e-03,\n",
       "            2.1044e-01, -1.0646e+00,  6.4291e-01,  1.1190e+00,  4.6204e-02,\n",
       "           -1.1225e+00, -1.2936e+00, -1.2857e+00, -1.0940e+00,  1.1986e+00,\n",
       "           -1.0447e+00,  5.2713e-01, -1.9953e-02, -8.1353e-01,  9.8827e-01,\n",
       "           -2.4999e-01, -8.2090e-01, -9.4538e-01, -1.0130e+00, -1.0865e+00,\n",
       "            2.2097e-01, -3.0370e-01, -3.6660e-01, -1.2668e-01,  4.2121e-01,\n",
       "            2.1247e-01,  1.0347e+00,  1.1867e+00, -3.5781e-01, -2.7342e-01,\n",
       "            1.0883e+00, -4.8553e-01,  1.2102e+00,  1.0595e+00,  1.1508e+00,\n",
       "            2.1133e-01, -1.1198e+00,  1.2426e+00, -2.2277e-01, -7.3765e-01,\n",
       "           -3.4600e-01, -5.9266e-01,  7.6346e-01, -9.6734e-01, -1.0501e+00,\n",
       "            2.9301e-01, -1.0440e+00,  1.0741e+00,  3.0878e-01,  8.9644e-01,\n",
       "           -3.3122e-01, -1.0861e+00,  8.9333e-01, -5.2615e-01,  6.9663e-01,\n",
       "           -2.0847e-01, -7.4260e-02,  4.1201e-01,  1.2024e+00,  6.5508e-01,\n",
       "            3.8245e-01,  4.7836e-01, -3.2507e-01, -1.5175e-01,  4.3365e-01,\n",
       "           -5.6602e-01, -2.6119e-01, -1.1127e+00, -5.0018e-01,  1.2056e+00,\n",
       "           -3.9390e-01,  5.8723e-01, -5.9253e-01,  1.2187e+00,  1.1743e+00,\n",
       "            8.4609e-01,  3.5149e-01, -3.3372e-01,  8.4283e-02,  6.0002e-01,\n",
       "            1.1984e+00,  3.7074e-01, -4.7030e-01, -4.4736e-01,  3.8727e-02,\n",
       "            3.7066e-01,  6.3701e-01,  4.4514e-02, -1.4543e-01,  4.3355e-01,\n",
       "            4.0407e-01, -1.2592e+00, -4.0759e-01, -7.4636e-01, -1.0937e+00,\n",
       "            1.8843e-01,  1.1749e+00, -9.5727e-01,  3.4487e-01,  9.7557e-01,\n",
       "           -4.2227e-01, -1.0356e-01, -2.8667e-01, -1.7385e-01,  1.0010e+00,\n",
       "            1.0687e+00,  5.1009e-01, -7.0642e-01,  2.1547e-01, -9.7791e-01,\n",
       "            1.6770e-01,  1.7159e-01,  3.9110e-01, -3.4132e-02, -1.2556e-01,\n",
       "           -8.7163e-01, -1.1657e+00, -1.9130e-01, -1.1967e+00, -3.7862e-01,\n",
       "           -3.8617e-02,  1.1833e+00, -1.7828e-01,  3.8447e-02,  9.2756e-02,\n",
       "           -1.6225e-01,  6.7782e-01,  8.7432e-01,  5.3969e-01, -3.7229e-01,\n",
       "            3.2585e-01, -4.4345e-01, -5.4864e-01,  6.4541e-01, -1.0968e+00,\n",
       "           -7.1037e-01,  9.6157e-01, -2.0568e-02,  2.9372e-01,  6.4742e-01,\n",
       "           -5.3007e-01,  7.9479e-01, -8.6020e-02,  1.2421e+00,  2.9008e-01,\n",
       "           -3.0643e-01,  9.2389e-01, -9.1739e-01, -1.1361e+00, -1.1850e+00,\n",
       "            7.0900e-01,  8.9436e-01,  6.9270e-01,  6.0746e-01, -4.9282e-01,\n",
       "           -1.2318e+00,  1.0169e+00,  1.1240e-01,  6.4980e-01,  1.6157e-01,\n",
       "            9.7393e-01,  2.4734e-01, -3.7877e-01, -1.9540e-01,  1.0409e+00,\n",
       "           -1.2789e+00, -5.1312e-01,  1.1999e+00, -9.0201e-01, -1.7978e-01,\n",
       "           -4.4197e-01, -1.0478e+00,  1.5359e-01, -3.7910e-01,  3.1657e-01,\n",
       "           -2.1145e-01,  4.5568e-01,  1.0403e-01,  1.1902e+00,  1.2394e+00,\n",
       "            6.8533e-01, -3.6107e-01, -9.1197e-01,  4.0303e-01, -8.7429e-01,\n",
       "           -2.6943e-01,  5.6904e-01,  1.1244e+00, -1.2676e+00,  1.1364e+00,\n",
       "           -3.9429e-02, -6.7751e-01,  1.1114e+00, -1.0487e+00, -8.6788e-01,\n",
       "           -1.1819e+00,  9.2192e-01, -2.6041e-01, -4.8270e-01,  1.1488e+00,\n",
       "            2.6138e-01, -1.0219e+00, -1.2140e-01, -2.5440e-01,  6.1809e-02,\n",
       "            1.1520e+00, -4.6744e-01, -1.0633e+00, -1.0002e+00, -7.9635e-01,\n",
       "           -5.3271e-01, -5.9040e-01, -6.3423e-01,  2.3495e-02, -6.9910e-02,\n",
       "            1.2694e+00,  1.3836e-01, -8.5711e-01,  1.1665e+00, -1.0853e+00,\n",
       "            6.9214e-02, -6.1296e-01, -8.2664e-01, -1.1637e+00,  3.7772e-01,\n",
       "           -2.2924e-02, -8.8176e-01, -5.8566e-03,  4.0018e-01,  7.1178e-01,\n",
       "            2.9403e-01,  1.3527e-01,  1.5791e-01,  1.1489e+00, -5.4481e-01,\n",
       "            9.9128e-01, -3.1233e-01, -1.0703e+00, -4.4413e-01,  1.1407e+00,\n",
       "           -7.5459e-01, -2.4681e-01, -4.4838e-01, -4.1206e-01,  1.0472e+00,\n",
       "           -5.8101e-01, -1.2036e+00,  9.4374e-01, -2.1580e-01, -5.6628e-01,\n",
       "           -5.1538e-01,  3.2451e-01, -1.1114e+00,  2.0011e-01, -5.4861e-01,\n",
       "           -1.0059e+00,  1.2608e+00, -5.5897e-01,  6.5757e-01,  2.8938e-01,\n",
       "           -1.1704e+00, -2.3147e-01, -1.4305e-01, -9.0755e-01,  8.3456e-01,\n",
       "            2.3951e-01, -3.4979e-01,  7.3418e-02,  1.0913e+00, -2.3973e-01,\n",
       "            8.2658e-01,  5.7072e-02,  1.2976e-01, -3.4504e-01,  7.2638e-01,\n",
       "            4.6139e-01,  1.2671e+00,  1.0191e+00,  1.1675e+00,  1.0450e+00,\n",
       "            1.2695e+00, -1.2936e-01, -9.6701e-01, -1.2574e+00, -7.9395e-01,\n",
       "            4.2305e-01, -5.7874e-01,  1.0320e+00, -3.8392e-01, -5.3468e-01,\n",
       "            4.5030e-01, -8.8781e-02, -1.0111e+00,  1.7659e-01,  1.1863e+00,\n",
       "            1.0544e+00, -2.2023e-01,  4.8123e-01, -1.0772e+00,  1.1887e+00,\n",
       "           -6.4142e-01,  8.1929e-02,  3.9675e-01,  5.1921e-01, -1.5924e-01,\n",
       "            5.2387e-01,  4.5962e-01,  1.0541e+00, -1.1310e-01,  6.3497e-02,\n",
       "            1.6581e-01, -1.1605e+00,  8.8572e-01,  1.0720e+00, -1.0738e+00,\n",
       "            1.1916e+00, -1.5316e-01,  1.1221e+00, -4.9875e-01,  6.9489e-01,\n",
       "           -2.9603e-01,  4.2074e-01,  6.0860e-02, -1.9457e-01,  1.7216e-01,\n",
       "            6.0541e-01, -6.1804e-01,  8.1510e-01,  2.9424e-01, -9.8841e-01,\n",
       "           -6.6839e-01, -2.8346e-01,  4.8218e-01,  9.4579e-01,  3.3496e-01,\n",
       "            1.1796e+00, -2.0880e-01,  1.6811e-01, -5.8479e-01, -3.7480e-01,\n",
       "            4.0242e-01, -1.0913e+00, -6.9271e-01, -1.2135e+00,  1.2766e+00,\n",
       "           -1.2295e+00,  9.5091e-01, -1.1091e+00,  1.5266e-01,  1.7329e-01,\n",
       "            3.4650e-01, -1.9395e-01,  9.8794e-01,  9.6892e-01, -1.0182e+00,\n",
       "           -1.1236e+00,  4.3014e-01, -7.7780e-01,  9.6894e-01, -1.0551e+00,\n",
       "            1.2032e+00,  3.7288e-01, -2.1856e-02,  1.1091e+00,  1.3258e+00,\n",
       "            1.0900e+00, -1.0229e+00, -1.1997e+00,  2.4216e-01,  5.3718e-01,\n",
       "            9.4134e-02,  9.8327e-01, -3.6093e-01,  7.4281e-01, -8.0577e-01,\n",
       "           -1.2026e+00,  1.2330e-02,  1.1301e+00, -1.1643e-01, -8.2383e-01,\n",
       "            1.2053e+00, -1.0182e+00, -1.1166e+00, -5.8341e-02,  9.8283e-01,\n",
       "            1.2868e+00,  6.8493e-01, -3.6617e-01, -3.5737e-01,  3.1293e-01,\n",
       "            8.0685e-01, -1.0659e+00,  2.7247e-01,  2.5383e-02, -2.8685e-02,\n",
       "            6.3013e-01, -5.7716e-01, -6.3568e-01,  1.0379e+00, -1.1154e+00,\n",
       "            3.2336e-01,  9.3655e-01, -1.1111e+00,  9.2378e-01, -5.8080e-01,\n",
       "            1.1682e+00, -7.7521e-01,  1.2327e+00, -5.7897e-01,  1.0498e+00,\n",
       "           -6.0206e-02, -8.0298e-01, -6.9889e-01,  1.2208e+00, -1.4725e-01,\n",
       "            1.1638e+00,  1.0503e+00, -1.2131e+00,  4.8920e-01,  1.1887e+00,\n",
       "            1.8098e-02, -9.7940e-02,  6.7318e-01,  1.1686e+00,  4.3089e-01,\n",
       "            2.7463e-01, -1.0569e+00], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 3.5695e-03, -3.8734e-02,  1.0014e-02,  1.5511e-02, -6.5272e-03,\n",
       "           -6.1128e-03,  2.1388e-02,  4.2164e-03, -2.3342e-03,  2.4642e-03,\n",
       "           -9.4674e-03, -1.0325e-02,  9.5061e-04,  2.7769e-03,  3.7552e-03,\n",
       "            2.0667e-02, -7.9123e-03, -1.8387e-03,  1.1057e-02,  6.1321e-03,\n",
       "           -5.2951e-03,  7.9308e-04,  4.2171e-03, -1.3628e-03,  1.4264e-02,\n",
       "           -3.6558e-03, -7.5698e-03, -4.2550e-03, -2.7301e-03,  2.9297e-03,\n",
       "           -5.9896e-03,  4.2730e-03,  4.3862e-03,  4.9207e-03, -5.8845e-03,\n",
       "           -6.1672e-03, -2.4933e-03, -2.1318e-03, -3.6539e-03, -1.0337e-02,\n",
       "           -2.2568e-04,  3.9087e-03, -9.9474e-03, -5.4219e-04,  3.5153e-03,\n",
       "            5.8004e-03, -8.8303e-04, -5.0705e-03, -2.6667e-03, -8.2372e-03,\n",
       "           -3.6312e-03,  1.5663e-02,  5.7224e-03,  1.6600e-02, -3.3755e-03,\n",
       "            1.2737e-02, -7.2354e-03,  8.0215e-03,  1.5373e-03,  4.6786e-03,\n",
       "            1.9395e-03,  6.9695e-03, -7.0902e-03,  2.3411e-03,  4.5565e-03,\n",
       "            2.0837e-03, -2.3505e-03, -2.4166e-03,  2.1228e-03,  3.8724e-03,\n",
       "            1.1818e-03,  4.3340e-03,  5.6024e-03, -1.1713e-02,  5.4296e-03,\n",
       "            6.9537e-03, -9.7349e-04, -1.6000e-03, -5.0640e-03,  1.0358e-02,\n",
       "            8.2315e-03, -5.0844e-03, -8.2347e-03, -8.5345e-03,  8.6324e-03,\n",
       "            3.7625e-03,  2.0772e-03, -1.4787e-02,  5.9426e-03, -1.3079e-03,\n",
       "           -2.0241e-04,  1.2966e-03, -4.4094e-03, -5.2105e-03,  8.0152e-03,\n",
       "           -1.7645e-04, -6.9946e-03, -4.7371e-03, -5.3133e-03,  7.3915e-04,\n",
       "            1.8582e-02, -1.5248e-03,  5.3723e-03,  2.7918e-03,  1.7716e-03,\n",
       "            7.3572e-03,  2.3745e-03, -4.6510e-03,  1.2121e-03, -1.1948e-03,\n",
       "           -1.3119e-02, -6.9478e-03,  4.4165e-03,  4.2461e-03,  4.5786e-03,\n",
       "           -6.8139e-03, -2.3397e-03, -5.3472e-03,  7.1069e-03,  1.4492e-04,\n",
       "           -3.7255e-03, -7.1430e-03,  1.3392e-02,  6.0608e-03,  1.0832e-03,\n",
       "           -2.2431e-03,  1.9148e-03, -2.4640e-03, -2.8171e-04, -1.9706e-02,\n",
       "           -8.3023e-03, -5.6060e-03,  1.6502e-03, -4.2527e-04,  8.3432e-03,\n",
       "            2.6388e-03,  2.6647e-03, -1.3792e-03, -1.3183e-03, -4.5763e-03,\n",
       "            7.1921e-03, -1.0688e-03,  8.2479e-03,  5.4710e-03, -5.6973e-03,\n",
       "            1.9410e-03,  1.0262e-03,  5.5461e-03,  1.6537e-03,  2.2265e-03,\n",
       "            1.0734e-03,  3.5129e-03, -5.1010e-04,  3.1251e-03,  6.0298e-03,\n",
       "            2.8757e-03, -7.0415e-03,  6.3680e-03, -1.0043e-03, -1.5957e-02,\n",
       "           -2.4454e-03, -4.7213e-03,  5.0278e-05,  5.4420e-03,  2.6616e-03,\n",
       "           -1.2534e-03, -1.9096e-04, -4.5251e-03,  6.4646e-03, -3.8572e-03,\n",
       "            1.2620e-03, -5.5384e-03, -8.2622e-03,  4.4749e-04,  4.0870e-03,\n",
       "            7.2423e-03,  4.5310e-03, -4.7834e-03,  5.7074e-03, -2.4770e-03,\n",
       "            1.2497e-02,  1.2295e-02,  1.5867e-03,  8.6206e-03, -6.1664e-03,\n",
       "            1.0522e-02, -5.6104e-03, -7.2257e-03,  2.6930e-03, -1.9345e-03,\n",
       "            2.0031e-03,  5.6288e-04,  2.6482e-03,  1.1576e-02, -3.6461e-03,\n",
       "            5.7669e-03,  4.1114e-02,  8.7783e-04, -3.3343e-03, -5.2717e-03,\n",
       "           -3.5965e-03,  9.6809e-05, -2.5338e-03,  1.0902e-02,  3.2205e-03,\n",
       "            7.9679e-03, -1.2704e-02,  1.2558e-02,  3.2380e-03, -9.0577e-03,\n",
       "           -2.2535e-03,  1.4302e-02, -5.4022e-03,  6.3945e-04,  5.7866e-04,\n",
       "            3.7259e-03,  2.6789e-03,  3.7894e-03,  1.0659e-02,  9.5283e-04,\n",
       "           -4.5730e-03, -1.2161e-03,  2.5671e-03, -2.0537e-03, -7.6979e-03,\n",
       "           -8.6722e-03,  3.6907e-03, -3.4737e-03, -3.8980e-02,  8.3410e-03,\n",
       "           -5.8588e-04, -1.2241e-03, -7.6080e-04, -1.9952e-03, -1.7453e-04,\n",
       "            4.9203e-03,  8.1824e-03, -9.3640e-03, -3.4501e-03,  1.4017e-02,\n",
       "           -6.7127e-03,  1.4538e-02,  7.6631e-02,  4.6166e-03, -3.7002e-03,\n",
       "           -5.6850e-03, -3.7681e-03,  1.8204e-03, -4.8569e-03, -3.5440e-03,\n",
       "            5.5386e-03, -4.8328e-03, -1.9012e-04, -3.3142e-03, -1.7394e-02,\n",
       "           -6.1919e-03,  1.0237e-02,  3.7650e-04, -2.5889e-03,  4.1753e-03,\n",
       "           -1.6416e-03,  2.6507e-01, -9.0895e-03,  1.3249e-02, -5.4695e-03,\n",
       "            1.5043e-02, -1.6458e-02,  5.1186e-02, -1.7577e-03,  2.8445e-04,\n",
       "           -1.9771e-03, -4.9712e-03, -4.2896e-03, -1.3149e-02, -1.3303e-02,\n",
       "            2.7576e-03, -5.1838e-03,  5.1537e-03,  2.0159e-03,  1.9446e-03,\n",
       "           -1.3526e-02,  3.0784e-03, -2.1034e-02,  7.6777e-03, -9.6847e-03,\n",
       "           -1.2248e-02,  8.8223e-03, -2.3957e-03, -2.0371e-02,  8.5543e-03,\n",
       "            1.8194e-02, -1.2866e-02, -2.3440e-03,  1.7203e-03, -3.6999e-02,\n",
       "           -1.4031e-02,  1.5142e-03, -5.8521e-03, -1.1931e-02, -7.6345e-03,\n",
       "            1.7214e-03, -8.2849e-03, -7.8519e-03,  1.3068e-03,  1.6659e-02,\n",
       "            1.6997e-03,  3.6102e-03, -1.2469e-02, -6.1638e-03,  1.2352e-02,\n",
       "           -2.9277e-03,  8.6645e-04, -5.2522e-03,  3.6325e-03, -4.5556e-03,\n",
       "            1.6548e-03, -1.4563e-03,  6.8965e-03,  6.6133e-03, -1.7238e-03,\n",
       "           -5.1758e-04,  1.9674e-03,  7.9756e-03, -4.7145e-03, -3.2819e-02,\n",
       "            3.1867e-03, -2.1652e-03, -1.6479e-03,  2.5170e-04, -4.0552e-03,\n",
       "            3.8071e-03, -3.7447e-03,  8.5101e-04,  3.6238e-03,  1.1170e-03,\n",
       "            2.8997e-04, -2.3016e-03,  2.4250e-02, -1.0908e-03, -4.1612e-03,\n",
       "            6.0051e-03,  2.3335e-02, -9.8608e-03, -1.0624e-02, -2.7676e-02,\n",
       "            6.3222e-03,  6.6531e-04,  8.3797e-05,  2.1492e-04,  4.5878e-03,\n",
       "            8.0094e-04, -5.0129e-03,  8.3929e-03,  1.3258e-03, -2.0135e-03,\n",
       "            8.7875e-03,  1.5774e-04, -6.1005e-03, -1.6162e-02,  5.9868e-03,\n",
       "            5.3357e-03,  3.1024e-04,  7.5708e-03, -2.7800e-03,  1.0373e-04,\n",
       "            1.3737e-02, -2.0823e-03, -2.2763e-03,  1.0345e-02, -3.3547e-03,\n",
       "           -1.7707e-03, -1.0540e-03,  2.1064e-03,  1.0291e-02,  8.3146e-04,\n",
       "            4.8684e-03,  8.4745e-03, -1.1107e-02,  1.5897e-02,  1.6449e-03,\n",
       "           -2.7372e-03,  7.0603e-03, -2.6070e-03, -1.0801e-02,  3.5038e-03,\n",
       "           -1.4343e-02,  8.9254e-03,  1.1052e-02,  2.2470e-04, -1.5639e-03,\n",
       "            3.0199e-02, -2.3134e-03, -4.4187e-03, -2.9908e-03,  2.8210e-03,\n",
       "            2.7848e-03,  2.5615e-03, -6.5815e-03,  2.8389e-03, -9.6814e-04,\n",
       "            1.6174e-03, -4.9849e-03, -6.4922e-03,  7.9495e-04,  6.4156e-03,\n",
       "            2.9895e-03, -4.9825e-03,  1.3239e-02,  1.4983e-02, -9.7094e-03,\n",
       "            2.5049e-03,  2.5616e-03,  3.7853e-03, -1.5806e-02, -1.3717e-02,\n",
       "           -1.9892e-04, -1.1489e-02, -2.4856e-04, -1.6393e-03,  4.4918e-03,\n",
       "            2.1140e-03, -2.0354e-03,  1.1649e-03,  1.5155e-02,  4.7426e-03,\n",
       "           -5.2571e-03,  5.7640e-03,  4.2138e-03, -1.6762e-03, -1.0224e-02,\n",
       "           -2.1129e-03,  1.1829e-03,  1.5269e-02, -1.7197e-02,  3.8307e-03,\n",
       "           -8.9984e-03,  3.6867e-03, -7.9138e-03, -5.6123e-03,  1.0015e-03,\n",
       "            8.8076e-03, -1.4153e-02,  1.2712e-03,  3.7195e-03,  7.5744e-04,\n",
       "            2.5391e-03, -4.1044e-03, -8.3621e-04,  2.7667e-03,  1.2249e-02,\n",
       "           -1.6899e-03, -6.5106e-03,  3.0019e-03, -1.2593e-03,  1.6366e-02,\n",
       "           -4.7358e-03,  2.6625e-02,  2.0961e-03,  4.0305e-04, -4.4905e-03,\n",
       "            4.9502e-04, -2.3384e-03,  2.2398e-05, -8.2286e-03, -3.4913e-03,\n",
       "           -3.5526e-02,  5.0534e-05,  2.8360e-03,  8.5372e-03, -6.7725e-03,\n",
       "           -1.5978e-03, -8.3018e-03,  2.1758e-03, -6.8979e-04, -1.5754e-02,\n",
       "            7.1138e-04, -1.3349e-03, -5.6567e-03, -1.4483e-02, -4.1137e-03,\n",
       "           -1.4443e-04,  5.0502e-03, -2.0253e-04, -9.9077e-03,  7.8163e-04,\n",
       "           -4.3894e-03, -3.3006e-04, -5.3099e-04,  1.5907e-03, -9.3158e-03,\n",
       "           -5.6745e-03, -4.7410e-03, -1.2207e-03, -1.1815e-02, -8.8593e-03,\n",
       "            2.4364e-03,  4.3772e-03,  2.8070e-03,  8.0087e-04,  4.7689e-03,\n",
       "            4.4419e-03, -4.9546e-03,  5.1501e-03, -6.3038e-03, -4.4182e-03,\n",
       "           -1.9509e-03, -1.7772e-03,  2.4809e-03, -3.2603e-03, -2.0947e-02,\n",
       "           -1.7401e-02, -1.6296e-02], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-1.7688e-02, -9.6733e-02, -2.6071e-02, -9.7173e-03, -5.4175e-03,\n",
       "            9.9513e-04, -3.1691e-02,  1.9225e-03,  4.4463e-03,  1.3369e-02,\n",
       "           -3.8328e-03,  7.6703e-03,  6.6857e-03, -2.1728e-03, -1.1091e-02,\n",
       "           -2.4031e-03,  1.2764e-02, -4.6414e-03,  1.4830e-02,  8.0358e-03,\n",
       "            1.8109e-03,  1.2081e-02, -2.0937e-02, -1.6324e-03, -1.6160e-02,\n",
       "           -8.3007e-03, -1.4992e-02, -1.8692e-02,  4.0861e-03,  6.2234e-03,\n",
       "            6.8992e-03, -3.3643e-02,  1.4221e-02, -9.9734e-03,  3.4857e-02,\n",
       "            9.3308e-03, -1.4613e-02,  9.8382e-03, -1.0540e-02, -1.8656e-03,\n",
       "           -1.1157e-02, -1.1474e-02, -1.2294e-02, -4.8539e-03,  1.4719e-02,\n",
       "            1.0494e-02, -7.2901e-03,  2.3527e-02,  3.0080e-03,  2.2747e-02,\n",
       "            1.5986e-02, -4.2893e-02,  1.0505e-02, -1.1923e-02, -1.1531e-02,\n",
       "            4.5957e-03,  1.8610e-02, -2.4249e-02,  1.7873e-02, -9.5311e-04,\n",
       "           -9.5801e-03,  2.2970e-02, -1.3450e-02, -1.4702e-02, -7.6406e-03,\n",
       "           -1.8718e-02, -1.1377e-03,  1.6132e-02,  2.1507e-02, -5.3548e-03,\n",
       "            2.2885e-03, -8.1499e-03,  1.3576e-02,  7.2724e-03,  8.5212e-03,\n",
       "           -1.0595e-02,  2.2907e-02, -2.2322e-02, -8.4007e-03, -3.0522e-02,\n",
       "           -8.1668e-02,  1.0841e-02,  8.7392e-03, -2.2250e-03,  1.9116e-02,\n",
       "           -1.5675e-02,  7.0339e-03, -4.5560e-02,  3.1507e-03,  2.9937e-03,\n",
       "            4.6170e-03, -9.3212e-03,  7.8726e-03,  7.5781e-03, -1.6175e-02,\n",
       "            8.5917e-03, -3.5133e-03, -9.7266e-03, -7.3909e-03,  3.4587e-03,\n",
       "           -1.1262e-02, -4.6933e-03, -1.3035e-02, -1.5494e-02,  9.5083e-03,\n",
       "           -3.0724e-02, -1.9574e-02, -1.0404e-02,  6.6825e-02,  1.4849e-02,\n",
       "            1.2311e-02,  7.5421e-03,  1.0157e-02,  2.5025e-03, -3.9517e-03,\n",
       "           -7.2845e-03, -9.5460e-03, -5.1340e-03,  2.1736e-03, -2.9558e-02,\n",
       "           -4.9750e-03,  9.3563e-03, -7.9968e-03,  1.8935e-02,  1.4176e-02,\n",
       "            4.7818e-03, -1.8098e-02,  1.2077e-02,  2.5929e-02, -6.3718e-03,\n",
       "            4.7651e-05,  1.8569e-02,  1.1584e-02,  8.1210e-03,  2.5456e-03,\n",
       "           -1.4020e-02,  1.4635e-02, -2.2758e-02,  1.1141e-02, -1.1330e-02,\n",
       "           -4.2748e-02, -6.4689e-03, -3.0642e-02,  8.3283e-04,  2.6920e-03,\n",
       "           -7.7381e-03,  3.6488e-02, -1.1074e-02, -8.6829e-02,  6.0154e-03,\n",
       "            3.5507e-03, -6.1154e-03,  1.8568e-02, -2.0461e-02,  1.5263e-02,\n",
       "            1.1774e-02, -1.3887e-02,  1.0320e-03,  7.4214e-04,  2.6460e-03,\n",
       "            1.5961e-03, -1.0454e-02,  8.0911e-03,  4.5195e-03, -1.4929e-02,\n",
       "            1.8036e-02,  1.2329e-03,  2.0291e-03,  2.6238e-02, -5.9633e-03,\n",
       "           -1.2622e-03, -9.8985e-03,  2.4375e-02, -4.5081e-03, -3.6785e-04,\n",
       "            1.3873e-02, -5.9960e-03, -2.4350e-03, -2.5971e-03, -1.5452e-02,\n",
       "           -2.2686e-02, -2.0844e-03,  2.9623e-03, -2.0223e-02, -1.4626e-02,\n",
       "            1.5640e-02, -2.3584e-02,  5.2233e-03,  3.4607e-03, -2.1415e-03,\n",
       "           -3.7078e-03,  9.9115e-03, -1.2800e-02,  2.5269e-02,  5.9399e-03,\n",
       "           -4.8514e-02, -1.7078e-02, -2.5561e-02,  6.1975e-03, -2.9289e-03,\n",
       "           -1.0115e-02, -2.4491e-02, -1.0290e-03, -6.6438e-03,  1.5088e-02,\n",
       "            6.2987e-04, -1.3572e-02, -3.0519e-02,  4.6576e-03, -2.7997e-02,\n",
       "            2.0820e-02, -1.1434e-02, -2.1794e-03, -4.5584e-03, -1.4166e-02,\n",
       "           -9.6023e-03,  2.4237e-02, -3.3090e-04,  1.5355e-02, -1.8582e-02,\n",
       "            7.3974e-03, -5.8148e-04, -7.4424e-03,  1.0345e-02,  1.1204e-02,\n",
       "            1.9874e-02,  1.7265e-02,  1.5030e-02, -3.3108e-02,  6.3346e-04,\n",
       "            1.4017e-02, -4.0419e-03,  6.0580e-03, -8.0807e-03,  1.4481e-02,\n",
       "           -9.7043e-03, -1.4027e-02,  1.5602e-02, -1.7695e-02, -1.2703e-02,\n",
       "            1.2713e-02, -5.2107e-03, -2.1606e-02,  1.3180e-03,  4.5433e-02,\n",
       "           -4.0354e-02, -2.8294e-03, -1.5104e-02, -8.8703e-03, -1.2207e-02,\n",
       "            2.1323e-02,  6.9769e-03, -1.6728e-02, -7.9587e-03, -2.1654e-02,\n",
       "            3.9530e-02,  9.3153e-03,  5.3925e-02, -7.0066e-03, -6.2256e-05,\n",
       "            4.6931e-03,  7.7677e-03, -1.1618e-03, -2.3198e-02,  2.4047e-03,\n",
       "           -2.4454e-02, -1.0154e-02,  1.1079e-02, -2.3271e-02,  4.6089e-02,\n",
       "            1.7789e-02,  2.9132e-02, -1.6393e-03, -1.4556e-02,  7.5069e-03,\n",
       "           -1.1678e-02,  3.0073e-02,  5.6574e-03, -2.4906e-02, -6.1463e-03,\n",
       "           -2.0822e-02, -4.9429e-03, -4.2681e-02, -8.6725e-04, -1.3398e-02,\n",
       "           -2.8224e-02, -2.2147e-02,  7.4181e-04,  4.6916e-04,  3.7012e-06,\n",
       "            6.5550e-03,  1.9131e-02,  4.1094e-03, -2.2188e-02,  3.0664e-02,\n",
       "            1.4957e-03, -7.2293e-03,  3.1765e-02,  1.7553e-02,  3.0274e-03,\n",
       "           -3.1192e-03,  2.8503e-02, -1.1619e-03,  2.2977e-02, -1.1800e-02,\n",
       "           -8.5691e-03, -1.3015e-02,  4.1030e-02,  2.7640e-02, -2.7760e-02,\n",
       "            1.0736e-03, -1.2236e-02, -8.0704e-04, -2.8404e-03,  1.7496e-02,\n",
       "            2.4617e-02, -7.2684e-03,  1.7857e-02, -4.2223e-02, -7.9039e-03,\n",
       "           -4.4572e-03, -1.2761e-02, -1.9073e-02,  6.9314e-03, -2.0398e-02,\n",
       "            9.9897e-03,  1.1155e-02, -7.4083e-03, -1.1213e-02,  1.7925e-03,\n",
       "           -2.4073e-02,  8.1378e-03, -1.2918e-02,  8.7585e-03,  1.3665e-04,\n",
       "           -8.8397e-03, -3.6922e-03, -1.8071e-02,  9.2866e-03, -7.7409e-03,\n",
       "            1.2716e-03, -1.3361e-02,  2.9259e-03, -2.8158e-02, -4.3694e-03,\n",
       "            1.8742e-02, -1.1384e-02, -5.2452e-03, -1.1194e-02, -1.2535e-02,\n",
       "            2.4746e-03, -3.6908e-02, -8.2515e-03, -1.5716e-04,  8.6264e-03,\n",
       "            1.2086e-02, -2.3138e-03, -5.3831e-03, -2.8425e-02, -2.9809e-02,\n",
       "            6.7726e-03,  1.5052e-02,  1.0216e-02, -9.7243e-03,  1.9237e-02,\n",
       "           -2.0467e-03, -2.2383e-02,  2.4662e-02,  9.3816e-03, -1.1044e-03,\n",
       "            8.6993e-03, -7.6776e-03,  1.5129e-02, -4.3538e-03,  1.9357e-02,\n",
       "           -8.6174e-03, -1.1166e-02,  3.5362e-03,  1.2323e-03, -1.6064e-02,\n",
       "           -2.2369e-02, -1.3740e-02,  1.4143e-03,  7.1851e-03, -8.7449e-03,\n",
       "           -2.0023e-02, -2.0771e-02, -3.4839e-02, -6.6680e-03, -8.7543e-03,\n",
       "           -4.0969e-03,  1.3806e-02, -2.8944e-02,  1.9560e-03, -1.5032e-03,\n",
       "            8.1920e-03,  2.0915e-02, -4.0900e-02, -4.7753e-03,  1.5776e-02,\n",
       "            3.9464e-03,  1.1922e-02,  7.5626e-03, -2.8095e-02,  8.6316e-03,\n",
       "           -1.3338e-02, -1.6727e-03,  1.5356e-02, -1.3329e-02,  1.9085e-03,\n",
       "           -1.6601e-02, -1.6340e-02, -2.9587e-02, -1.3474e-02,  1.6692e-02,\n",
       "           -3.0994e-02,  1.1773e-02, -1.5565e-02,  2.4862e-02,  1.3559e-04,\n",
       "           -1.4153e-03, -4.7734e-03,  8.2372e-03, -1.2095e-02, -1.3159e-02,\n",
       "           -4.7523e-03, -1.8044e-02,  4.6373e-03, -5.8603e-04,  2.4738e-02,\n",
       "            8.8311e-03,  2.5737e-02, -1.2763e-02,  4.8227e-03,  1.4200e-02,\n",
       "            1.4273e-02, -1.1142e-02, -1.6345e-02, -1.2419e-02, -6.1769e-03,\n",
       "           -1.5914e-02, -1.8949e-02, -8.2940e-03, -1.7077e-02, -1.4164e-02,\n",
       "           -1.4171e-02, -6.9724e-02, -1.5599e-02, -1.1835e-03, -1.5307e-02,\n",
       "            2.9302e-03,  2.1978e-02, -7.4567e-03, -1.2431e-02,  2.0705e-02,\n",
       "           -2.6195e-02,  3.0058e-03,  2.7948e-02, -1.1742e-02, -4.8325e-03,\n",
       "            2.1430e-03,  1.1786e-02, -1.9958e-02,  4.1874e-02, -7.5107e-03,\n",
       "            3.9961e-02,  6.4522e-03, -5.5488e-03, -1.5355e-02,  1.3489e-02,\n",
       "           -9.0842e-03,  9.9531e-03, -3.6952e-03, -4.3662e-03,  3.2898e-03,\n",
       "            1.0005e-02, -6.2988e-03, -1.5081e-03, -1.0051e-02, -2.1366e-02,\n",
       "            1.1928e-02, -1.8520e-03,  1.7324e-02, -4.3486e-03, -4.1564e-02,\n",
       "           -1.7578e-02,  2.1000e-02, -9.9361e-03,  1.6694e-02,  1.2291e-02,\n",
       "           -6.1051e-03, -1.5395e-02, -4.4848e-02, -1.0956e-02, -1.8431e-03,\n",
       "            2.2085e-02,  8.8358e-03, -6.0485e-02, -5.5645e-03,  1.1745e-02,\n",
       "           -4.7176e-03, -2.0010e-02,  9.7395e-03, -2.1301e-03,  1.0959e-02,\n",
       "           -9.6823e-03,  3.4322e-02, -1.5040e-03, -2.5571e-02, -2.0301e-02,\n",
       "           -8.3088e-03,  7.7745e-03], device='mps:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 8.5663, -4.6746, -5.3331,  ..., -3.6905, -5.5852, -4.7827],\n",
       "          device='mps:0', requires_grad=True)],\n",
       "  'weight_decay': 0.0}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if n in decay_parameters],\n",
    "        # p is the actual parameter value (or tensor) associated with the parameter name n.\n",
    "        \"weight_decay\": training_args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if n not in decay_parameters],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "optimizer_grouped_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7213a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'betas': (0.9, 0.999), 'eps': 1e-08}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_kwargs = {\n",
    "    \"betas\": (training_args.adam_beta1, training_args.adam_beta2),\n",
    "    \"eps\": training_args.adam_epsilon,\n",
    "}\n",
    "optimizer_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f0746b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "# Bitsandbytes is a Python library that focuses on quantization of neural network models. \n",
    "# Quantization is a technique to reduce the precision of numerical representations \n",
    "# (e.g., from 32-bit floating-point to 8-bit integers) to decrease model size and accelerate computations.\n",
    "\n",
    "optimizer_kwargs[\"lr\"] = training_args.learning_rate\n",
    "\n",
    "adam_bnb_optim = bnb.optim.Adam8bit(\n",
    "    optimizer_grouped_parameters,\n",
    "    betas=(training_args.adam_beta1, training_args.adam_beta2),   \n",
    "    #  betas: a tuple of two values, (beta1, beta2), \n",
    "    #  that control the exponential moving averages of the gradient and squared gradient, respectively. \n",
    "    # Typical values are (0.9, 0.999).\n",
    "    eps=training_args.adam_epsilon,\n",
    "    lr=training_args.learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4b7c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "model, optimizer, dataloader = accelerator.prepare(model, adam_bnb_optim, dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
